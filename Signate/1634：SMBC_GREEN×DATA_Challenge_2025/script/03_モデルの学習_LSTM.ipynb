{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3f14dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import shap\n",
    "from pdpbox import pdp\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Attention, Multiply, Lambda, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ef38b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/iwasakitakahiro/github')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import common\n",
    "\n",
    "# モジュールの再読み込み\n",
    "importlib.reload(common)\n",
    "\n",
    "_common = common.Common()\n",
    "_common.BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64235bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'func' from '/Users/iwasakitakahiro/github/共通関数/func.py'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_func_path = _common.COMMON_FUNC_PATH\n",
    "sys.path.append(str(common_func_path))\n",
    "\n",
    "import func\n",
    "\n",
    "importlib.reload(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e76213f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../output/中間データ/学習用データ/train_preprocessed.csv')\n",
    "test_df = pd.read_csv('../output/中間データ/評価用データ/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "566c0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現性確保のための固定シード\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Optunaのシードも固定\n",
    "sampler = optuna.samplers.TPESampler(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b467a",
   "metadata": {},
   "source": [
    "## SEQ_LEN: 24時間前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a209d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "exclude_cols = ['time', 'price_actual']  # 目的変数＋timeは除外\n",
    "features = [col for col in train_df.columns if col not in exclude_cols]\n",
    "target_col = 'price_actual'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_features = scaler.fit_transform(train_df[features])\n",
    "test_features = scaler.transform(test_df[features])  \n",
    "\n",
    "# --- LSTM用の時系列ウィンドウデータ作成 ---\n",
    "SEQ_LEN = 24  # 1週間で試す場合は168\n",
    "X, y = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X.append(train_features[i:i+SEQ_LEN])\n",
    "    y.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# trainの最後SEQ_LEN行を取得\n",
    "tail_train = train_features[-SEQ_LEN:, :]   # shape: (SEQ_LEN, 特徴量数)\n",
    "\n",
    "# test_features（np.array）と連結\n",
    "concat_test = np.vstack([tail_train, test_features])   # shape: (SEQ_LEN + len(test), 特徴量数)\n",
    "concat_test_df = pd.DataFrame(concat_test, columns=features)\n",
    "concat_test_df.to_csv('../output/中間データ/評価用データ/test_features_for_lstm24.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd0948",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5b37bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 08:19:58,214] A new study created in memory with name: no-name-b89fb3b3-d5ae-44b4-ba03-7b10486ae9c9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 08:23:05,710] Trial 0 finished with value: 11.639486243544146 and parameters: {'units': 32, 'num_layers': 1, 'dropout': 0.47969988571194766, 'batch_size': 16, 'lr': 0.0028253324556877617, 'l2': 0.00024667420132580304}. Best is trial 0 with value: 11.639486243544146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 08:29:29,520] Trial 1 finished with value: 11.092526225482276 and parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.1539454389641445, 'batch_size': 32, 'lr': 0.009550065349802312, 'l2': 6.024760398544085e-06}. Best is trial 1 with value: 11.092526225482276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 08:34:30,169] Trial 2 finished with value: 12.296594126490488 and parameters: {'units': 32, 'num_layers': 2, 'dropout': 0.49144332359850107, 'batch_size': 32, 'lr': 0.00036853860338450335, 'l2': 1.754000779104593e-07}. Best is trial 1 with value: 11.092526225482276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 08:36:37,023] Trial 3 finished with value: 11.136953109624672 and parameters: {'units': 32, 'num_layers': 1, 'dropout': 0.1975081412305535, 'batch_size': 32, 'lr': 0.0010052254567426769, 'l2': 0.0005787808952297758}. Best is trial 1 with value: 11.092526225482276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 08:40:45,475] Trial 4 finished with value: 11.646605435025819 and parameters: {'units': 32, 'num_layers': 2, 'dropout': 0.2968152599791388, 'batch_size': 32, 'lr': 0.008376450094803027, 'l2': 0.00011898226863919709}. Best is trial 1 with value: 11.092526225482276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 08:57:30,351] Trial 5 finished with value: 11.820676557742644 and parameters: {'units': 128, 'num_layers': 2, 'dropout': 0.2983162490665209, 'batch_size': 32, 'lr': 0.0014981126793128972, 'l2': 0.0001951148745341462}. Best is trial 1 with value: 11.092526225482276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 09:07:57,560] Trial 6 finished with value: 10.617337285235687 and parameters: {'units': 32, 'num_layers': 1, 'dropout': 0.24161673050104493, 'batch_size': 16, 'lr': 0.006193813830401498, 'l2': 3.184526575236531e-05}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 09:10:36,789] Trial 7 finished with value: 11.470833102180132 and parameters: {'units': 64, 'num_layers': 1, 'dropout': 0.2819655955042638, 'batch_size': 32, 'lr': 0.0062433354982764895, 'l2': 7.846650255310074e-07}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 09:14:32,886] Trial 8 finished with value: 11.271942717983293 and parameters: {'units': 64, 'num_layers': 1, 'dropout': 0.45411941806497635, 'batch_size': 16, 'lr': 0.0013470776187956563, 'l2': 7.928505713092022e-07}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 09:17:53,960] Trial 9 finished with value: 12.017722560244906 and parameters: {'units': 64, 'num_layers': 1, 'dropout': 0.3693514729722358, 'batch_size': 32, 'lr': 0.009664698538136736, 'l2': 2.279306861902969e-07}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 09:22:51,487] Trial 10 finished with value: 11.335971820865042 and parameters: {'units': 128, 'num_layers': 1, 'dropout': 0.106570639532228, 'batch_size': 64, 'lr': 0.004656019691105849, 'l2': 2.630174649995615e-05}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 09:31:50,189] Trial 11 finished with value: 10.72705885054602 and parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.17834117563848212, 'batch_size': 16, 'lr': 0.007023997183065652, 'l2': 7.186209974029024e-06}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 09:40:28,738] Trial 12 finished with value: 11.031413612975873 and parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.21162570350727666, 'batch_size': 16, 'lr': 0.006358801605700484, 'l2': 1.169536872445087e-05}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 09:55:52,955] Trial 13 finished with value: 11.632222003322655 and parameters: {'units': 32, 'num_layers': 2, 'dropout': 0.1972782529193386, 'batch_size': 16, 'lr': 0.007317501225894581, 'l2': 2.873732531246455e-05}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 10:04:14,818] Trial 14 finished with value: 10.879541337517628 and parameters: {'units': 128, 'num_layers': 1, 'dropout': 0.23767955370241978, 'batch_size': 16, 'lr': 0.004453248735475966, 'l2': 2.993249342893494e-06}. Best is trial 6 with value: 10.617337285235687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'units': 32, 'num_layers': 1, 'dropout': 0.24161673050104493, 'batch_size': 16, 'lr': 0.006193813830401498, 'l2': 3.184526575236531e-05}\n",
      "Best CV RMSE: 10.617337285235687\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_attention_model(input_shape, units, num_layers, dropout, lr, l2_lambda, dense_units=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = LSTM(units, return_sequences=True, dropout=dropout,\n",
    "                 kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    # Attention (Self-Attention)\n",
    "    attention_output = Attention()([x, x])  # shape: [batch, time, units]\n",
    "    context_vector = GlobalAveragePooling1D()(attention_output)  # shape: [batch, units]\n",
    "\n",
    "    x = Dense(dense_units, activation='relu', kernel_regularizer=l2(l2_lambda))(context_vector)\n",
    "    output = Dense(1, activation='linear', kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer=RMSprop(learning_rate=lr), loss='mse')\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "    l2_lambda = trial.suggest_float('l2', 1e-7, 1e-3, log=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in tscv.split(X):  # あなたのX, yのウィンドウ化後配列を前提\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = create_lstm_attention_model((X.shape[1], X.shape[2]), units, num_layers, dropout, learning_rate, l2_lambda)\n",
    "        es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=200,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es, reduce_lr]\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val).flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)\n",
    "\n",
    "# --- Optunaでパラメータ探索 ---\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best CV RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d7c69",
   "metadata": {},
   "source": [
    "#### 全データで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e545207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "units = best_params['units']\n",
    "num_layers = best_params['num_layers']\n",
    "dropout = best_params['dropout']\n",
    "batch_size = best_params['batch_size']\n",
    "learning_rate = best_params['lr']\n",
    "l2_lambda = best_params['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f982f3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 294.4994 - learning_rate: 0.0062\n",
      "Epoch 2/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 139.4761 - learning_rate: 0.0062\n",
      "Epoch 3/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 125.3842 - learning_rate: 0.0062\n",
      "Epoch 4/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 115.7202 - learning_rate: 0.0062\n",
      "Epoch 5/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 113.3921 - learning_rate: 0.0062\n",
      "Epoch 6/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 111.6568 - learning_rate: 0.0062\n",
      "Epoch 7/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 108.3988 - learning_rate: 0.0062\n",
      "Epoch 8/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 101.9888 - learning_rate: 0.0062\n",
      "Epoch 9/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 105.1701 - learning_rate: 0.0062\n",
      "Epoch 10/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 101.6163 - learning_rate: 0.0062\n",
      "Epoch 11/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 97.9292 - learning_rate: 0.0062\n",
      "Epoch 12/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 97.6580 - learning_rate: 0.0062\n",
      "Epoch 13/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 96.8833 - learning_rate: 0.0062\n",
      "Epoch 14/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 95.8817 - learning_rate: 0.0062\n",
      "Epoch 15/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 94.1047 - learning_rate: 0.0062\n",
      "Epoch 16/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 93.5703 - learning_rate: 0.0062\n",
      "Epoch 17/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 92.4556 - learning_rate: 0.0062\n",
      "Epoch 18/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 90.6265 - learning_rate: 0.0062\n",
      "Epoch 19/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 92.0620 - learning_rate: 0.0062\n",
      "Epoch 20/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 89.7489 - learning_rate: 0.0062\n",
      "Epoch 21/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 87.6067 - learning_rate: 0.0062\n",
      "Epoch 22/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 89.6237 - learning_rate: 0.0062\n",
      "Epoch 23/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 86.4186 - learning_rate: 0.0062\n",
      "Epoch 24/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 87.3059 - learning_rate: 0.0062\n",
      "Epoch 25/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 84.5877 - learning_rate: 0.0062\n",
      "Epoch 26/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 84.1271 - learning_rate: 0.0062\n",
      "Epoch 27/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 85.2253 - learning_rate: 0.0062\n",
      "Epoch 28/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 84.8517 - learning_rate: 0.0062\n",
      "Epoch 29/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 85.6040 - learning_rate: 0.0062\n",
      "Epoch 30/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 82.9615 - learning_rate: 0.0062\n",
      "Epoch 31/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 82.2313 - learning_rate: 0.0062\n",
      "Epoch 32/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 82.3557 - learning_rate: 0.0062\n",
      "Epoch 33/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 81.1575 - learning_rate: 0.0062\n",
      "Epoch 34/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 81.9931 - learning_rate: 0.0062\n",
      "Epoch 35/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 83.6221 - learning_rate: 0.0062\n",
      "Epoch 36/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 83.2183 - learning_rate: 0.0062\n",
      "Epoch 37/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 82.1633 - learning_rate: 0.0062\n",
      "Epoch 38/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 80.7942 - learning_rate: 0.0062\n",
      "Epoch 39/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 80.9316 - learning_rate: 0.0062\n",
      "Epoch 40/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 78.8696 - learning_rate: 0.0062\n",
      "Epoch 41/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 78.4400 - learning_rate: 0.0062\n",
      "Epoch 42/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 77.6163 - learning_rate: 0.0062\n",
      "Epoch 43/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 80.0707 - learning_rate: 0.0062\n",
      "Epoch 44/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 77.3388 - learning_rate: 0.0062\n",
      "Epoch 45/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 80.4140 - learning_rate: 0.0062\n",
      "Epoch 46/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 77.9200 - learning_rate: 0.0062\n",
      "Epoch 47/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 78.3504 - learning_rate: 0.0062\n",
      "Epoch 48/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 76.8498 - learning_rate: 0.0062\n",
      "Epoch 49/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 77.6406 - learning_rate: 0.0062\n",
      "Epoch 50/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 75.5352 - learning_rate: 0.0062\n",
      "Epoch 51/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 75.4620 - learning_rate: 0.0062\n",
      "Epoch 52/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 76.7728 - learning_rate: 0.0062\n",
      "Epoch 53/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 77.6308 - learning_rate: 0.0062\n",
      "Epoch 54/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 76.1413 - learning_rate: 0.0062\n",
      "Epoch 55/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 78.1142 - learning_rate: 0.0062\n",
      "Epoch 56/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 75.8601 - learning_rate: 0.0062\n",
      "Epoch 57/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 75.7162 - learning_rate: 0.0062\n",
      "Epoch 58/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 75.2577 - learning_rate: 0.0062\n",
      "Epoch 59/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 74.8566 - learning_rate: 0.0062\n",
      "Epoch 60/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 76.0543 - learning_rate: 0.0062\n",
      "Epoch 61/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 76.2956 - learning_rate: 0.0062\n",
      "Epoch 62/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 70.7853 - learning_rate: 0.0031\n",
      "Epoch 63/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 70.5649 - learning_rate: 0.0031\n",
      "Epoch 64/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 68.5938 - learning_rate: 0.0031\n",
      "Epoch 65/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 69.2275 - learning_rate: 0.0031\n",
      "Epoch 66/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 68.7247 - learning_rate: 0.0031\n",
      "Epoch 67/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 67.8544 - learning_rate: 0.0031\n",
      "Epoch 68/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 68.5169 - learning_rate: 0.0031\n",
      "Epoch 69/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 69.2354 - learning_rate: 0.0031\n",
      "Epoch 70/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 66.0872 - learning_rate: 0.0031\n",
      "Epoch 71/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 66.1042 - learning_rate: 0.0031\n",
      "Epoch 72/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 66.6475 - learning_rate: 0.0031\n",
      "Epoch 73/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 66.6500 - learning_rate: 0.0031\n",
      "Epoch 74/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 66.1461 - learning_rate: 0.0031\n",
      "Epoch 75/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 66.1725 - learning_rate: 0.0031\n",
      "Epoch 76/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 67.1241 - learning_rate: 0.0031\n",
      "Epoch 77/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 66.8378 - learning_rate: 0.0031\n",
      "Epoch 78/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 66.6928 - learning_rate: 0.0031\n",
      "Epoch 79/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 64.8561 - learning_rate: 0.0031\n",
      "Epoch 80/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 63.5098 - learning_rate: 0.0031\n",
      "Epoch 81/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 65.0861 - learning_rate: 0.0031\n",
      "Epoch 82/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 64.5339 - learning_rate: 0.0031\n",
      "Epoch 83/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 65.2345 - learning_rate: 0.0015\n",
      "Epoch 84/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 64.2821 - learning_rate: 0.0015\n",
      "Epoch 85/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 62.4678 - learning_rate: 0.0015\n",
      "Epoch 86/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 61.5148 - learning_rate: 0.0015\n",
      "Epoch 87/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 60.3407 - learning_rate: 0.0015\n",
      "Epoch 88/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 62.2288 - learning_rate: 0.0015\n",
      "Epoch 89/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 58.8816 - learning_rate: 0.0015\n",
      "Epoch 90/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 60.9600 - learning_rate: 0.0015\n",
      "Epoch 91/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 60.6558 - learning_rate: 0.0015\n",
      "Epoch 92/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 62.2926 - learning_rate: 0.0015\n",
      "Epoch 93/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 60.9314 - learning_rate: 0.0015\n",
      "Epoch 94/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 60.0878 - learning_rate: 0.0015\n",
      "Epoch 95/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 59.0124 - learning_rate: 7.7423e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 60.7432 - learning_rate: 7.7423e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 59.1104 - learning_rate: 7.7423e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 59.4308 - learning_rate: 7.7423e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 58.4655 - learning_rate: 7.7423e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m1637/1637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 58.6728 - learning_rate: 7.7423e-04\n",
      "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Train RMSE: 10.421\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_all, y_all = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X_all.append(train_features[i:i+SEQ_LEN])\n",
    "    y_all.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "# --- Attention付きLSTMモデルの構築 ---\n",
    "model = create_lstm_attention_model(\n",
    "    input_shape=(SEQ_LEN, X_all.shape[2]),\n",
    "    units=units,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    lr=learning_rate,\n",
    "    l2_lambda=l2_lambda\n",
    ")\n",
    "\n",
    "# --- コールバックの設定 ---\n",
    "es = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# --- 学習 ---\n",
    "history = model.fit(\n",
    "    X_all, y_all,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[es, reduce_lr]\n",
    ")\n",
    "\n",
    "# --- 全データでの予測とRMSE計算 ---\n",
    "y_pred = model.predict(X_all).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(y_all, y_pred))\n",
    "print(f\"Train RMSE: {rmse:.3f}\")\n",
    "\n",
    "# --- 学習曲線の可視化 ---\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b33750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../output/モデル/lstm_model24.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf95cd",
   "metadata": {},
   "source": [
    "## SEQ_LEN: 1週間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6378905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "exclude_cols = ['time', 'price_actual']  # 目的変数＋timeは除外\n",
    "features = [col for col in train_df.columns if col not in exclude_cols]\n",
    "target_col = 'price_actual'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_features = scaler.fit_transform(train_df[features])\n",
    "test_features = scaler.transform(test_df[features])  \n",
    "\n",
    "# --- LSTM用の時系列ウィンドウデータ作成 ---\n",
    "SEQ_LEN = 168\n",
    "X, y = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X.append(train_features[i:i+SEQ_LEN])\n",
    "    y.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# trainの最後SEQ_LEN行を取得\n",
    "tail_train = train_features[-SEQ_LEN:, :]   # shape: (SEQ_LEN, 特徴量数)\n",
    "\n",
    "# test_features（np.array）と連結\n",
    "concat_test = np.vstack([tail_train, test_features])   # shape: (SEQ_LEN + len(test), 特徴量数)\n",
    "concat_test_df = pd.DataFrame(concat_test, columns=features)\n",
    "concat_test_df.to_csv('../output/中間データ/評価用データ/test_features_for_lstm168.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa667bd6",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61d95a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 10:11:10,001] A new study created in memory with name: no-name-f9f4c257-27c4-45b6-86a9-e8ce5f770edf\n",
      "[W 2025-06-11 10:11:40,634] Trial 0 failed with parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.2985807913397629, 'batch_size': 32, 'lr': 0.008091627020217134, 'l2': 6.51118212219688e-07} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/sb/t91v_nzj05sbsfnhcjb832xr0000gn/T/ipykernel_5924/1792540141.py\", line 38, in objective\n",
      "    model.fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
      "    results = tracing_compilation.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1500, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-11 10:11:40,644] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# --- Optunaでパラメータ探索 ---\u001b[39;00m\n\u001b[32m     54\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest CV RMSE:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    357\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    358\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    359\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    360\u001b[39m \n\u001b[32m    361\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    244\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    247\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    248\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    250\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    202\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    203\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     35\u001b[39m es = EarlyStopping(patience=\u001b[32m20\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     36\u001b[39m reduce_lr = ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m8\u001b[39m, min_lr=\u001b[32m1e-6\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m y_pred = model.predict(X_val).flatten()\n\u001b[32m     48\u001b[39m rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1498\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1509\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1510\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1514\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1515\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def create_lstm_attention_model(input_shape, units, num_layers, dropout, lr, l2_lambda, dense_units=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = LSTM(units, return_sequences=True, dropout=dropout,\n",
    "                 kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    # Attention (Self-Attention)\n",
    "    attention_output = Attention()([x, x])  # shape: [batch, time, units]\n",
    "    context_vector = GlobalAveragePooling1D()(attention_output)  # shape: [batch, units]\n",
    "\n",
    "    x = Dense(dense_units, activation='relu', kernel_regularizer=l2(l2_lambda))(context_vector)\n",
    "    output = Dense(1, activation='linear', kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer=RMSprop(learning_rate=lr), loss='mse')\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "    l2_lambda = trial.suggest_float('l2', 1e-7, 1e-3, log=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in tscv.split(X):  # あなたのX, yのウィンドウ化後配列を前提\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = create_lstm_attention_model((X.shape[1], X.shape[2]), units, num_layers, dropout, learning_rate, l2_lambda)\n",
    "        es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=200,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es, reduce_lr]\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val).flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)\n",
    "\n",
    "# --- Optunaでパラメータ探索 ---\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best CV RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569bde7c",
   "metadata": {},
   "source": [
    "#### 全データで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f46ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "units = best_params['units']\n",
    "num_layers = best_params['num_layers']\n",
    "dropout = best_params['dropout']\n",
    "batch_size = best_params['batch_size']\n",
    "learning_rate = best_params['lr']\n",
    "l2_lambda = best_params['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71242411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 46ms/step - loss: 1726.6941\n",
      "Epoch 2/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 249.2115\n",
      "Epoch 3/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 198.7570\n",
      "Epoch 4/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 124.8483\n",
      "Epoch 5/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - loss: 105.8403\n",
      "Epoch 6/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 95.3063\n",
      "Epoch 7/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 88.0377\n",
      "Epoch 8/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 85.3183\n",
      "Epoch 9/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 84.7468\n",
      "Epoch 10/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 80.5158\n",
      "Epoch 11/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 76.4179\n",
      "Epoch 12/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1032s\u001b[0m 3s/step - loss: 71.8479\n",
      "Epoch 13/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 73.5621\n",
      "Epoch 14/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 72.4995\n",
      "Epoch 15/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 71.8405\n",
      "Epoch 16/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 69.6505\n",
      "Epoch 17/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 68.0200\n",
      "Epoch 18/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 66.3726\n",
      "Epoch 19/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 66.0126\n",
      "Epoch 20/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 64.9808\n",
      "Epoch 21/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 62.8984\n",
      "Epoch 22/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 61.8864\n",
      "Epoch 23/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 63.6750\n",
      "Epoch 24/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 62.7459\n",
      "Epoch 25/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1025s\u001b[0m 3s/step - loss: 60.1563\n",
      "Epoch 26/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 60.2484\n",
      "Epoch 27/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 59.3820\n",
      "Epoch 28/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 58.1327\n",
      "Epoch 29/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1041s\u001b[0m 3s/step - loss: 56.7412\n",
      "Epoch 30/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 57.0022\n",
      "\u001b[1m814/814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step\n",
      "Train RMSE: 5.710\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X_all.append(train_features[i:i+SEQ_LEN])\n",
    "    y_all.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "# --- Attention付きLSTMモデルの構築 ---\n",
    "model = create_lstm_attention_model(\n",
    "    input_shape=(SEQ_LEN, X_all.shape[2]),\n",
    "    units=units,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    lr=learning_rate,\n",
    "    l2_lambda=l2_lambda\n",
    ")\n",
    "\n",
    "# --- コールバックの設定 ---\n",
    "es = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# --- 学習 ---\n",
    "history = model.fit(\n",
    "    X_all, y_all,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[es, reduce_lr]\n",
    ")\n",
    "\n",
    "# --- 全データでの予測とRMSE計算 ---\n",
    "y_pred = model.predict(X_all).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(y_all, y_pred))\n",
    "print(f\"Train RMSE: {rmse:.3f}\")\n",
    "\n",
    "# --- 学習曲線の可視化 ---\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../output/モデル/lstm_model168.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c60e47",
   "metadata": {},
   "source": [
    "## SEQ_LEN: 1ヶ月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee65b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "exclude_cols = ['time', 'price_actual']  # 目的変数＋timeは除外\n",
    "features = [col for col in train_df.columns if col not in exclude_cols]\n",
    "target_col = 'price_actual'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_features = scaler.fit_transform(train_df[features])\n",
    "test_features = scaler.transform(test_df[features])  \n",
    "\n",
    "# --- LSTM用の時系列ウィンドウデータ作成 ---\n",
    "SEQ_LEN = 720\n",
    "X, y = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X.append(train_features[i:i+SEQ_LEN])\n",
    "    y.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# trainの最後SEQ_LEN行を取得\n",
    "tail_train = train_features[-SEQ_LEN:, :]   # shape: (SEQ_LEN, 特徴量数)\n",
    "\n",
    "# test_features（np.array）と連結\n",
    "concat_test = np.vstack([tail_train, test_features])   # shape: (SEQ_LEN + len(test), 特徴量数)\n",
    "concat_test_df = pd.DataFrame(concat_test, columns=features)\n",
    "concat_test_df.to_csv('../output/中間データ/評価用データ/test_features_for_lstm720.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069fc31",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 07:29:29,594] A new study created in memory with name: no-name-97ac65c7-8ceb-4beb-b1e1-63043373cde5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 07:44:49,040] Trial 0 finished with value: 13.685517930485718 and parameters: {'units': 32, 'num_layers': 1, 'dropout': 0.3835501303239237, 'batch_size': 64, 'lr': 0.009183389122550368}. Best is trial 0 with value: 13.685517930485718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-09 09:22:07,411] Trial 1 failed with parameters: {'units': 32, 'num_layers': 2, 'dropout': 0.46850881206753436, 'batch_size': 64, 'lr': 0.0014355950712513347} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/sb/t91v_nzj05sbsfnhcjb832xr0000gn/T/ipykernel_80921/272806354.py\", line 29, in objective\n",
      "    model.fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
      "    results = tracing_compilation.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1500, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-09 09:22:07,514] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# --- Optunaでパラメータ探索 ---\u001b[39;00m\n\u001b[32m     45\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest CV RMSE:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    357\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    358\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    359\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    360\u001b[39m \n\u001b[32m    361\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    244\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    247\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    248\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    250\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    202\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    203\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     27\u001b[39m model = create_lstm_model((X.shape[\u001b[32m1\u001b[39m], X.shape[\u001b[32m2\u001b[39m]), units, num_layers, dropout, learning_rate)\n\u001b[32m     28\u001b[39m es = EarlyStopping(patience=\u001b[32m5\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m y_pred = model.predict(X_val).flatten()\n\u001b[32m     39\u001b[39m rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1498\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1509\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1510\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1514\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1515\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def create_lstm_attention_model(input_shape, units, num_layers, dropout, lr, l2_lambda, dense_units=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = LSTM(units, return_sequences=True, dropout=dropout,\n",
    "                 kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    # Attention (Self-Attention)\n",
    "    attention_output = Attention()([x, x])  # shape: [batch, time, units]\n",
    "    context_vector = GlobalAveragePooling1D()(attention_output)  # shape: [batch, units]\n",
    "\n",
    "    x = Dense(dense_units, activation='relu', kernel_regularizer=l2(l2_lambda))(context_vector)\n",
    "    output = Dense(1, activation='linear', kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer=RMSprop(learning_rate=lr), loss='mse')\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "    l2_lambda = trial.suggest_float('l2', 1e-7, 1e-3, log=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in tscv.split(X):  # あなたのX, yのウィンドウ化後配列を前提\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = create_lstm_attention_model((X.shape[1], X.shape[2]), units, num_layers, dropout, learning_rate, l2_lambda)\n",
    "        es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=200,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es, reduce_lr]\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val).flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)\n",
    "\n",
    "# --- Optunaでパラメータ探索 ---\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best CV RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ca460",
   "metadata": {},
   "source": [
    "#### 全データで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febdb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "units = best_params['units']\n",
    "num_layers = best_params['num_layers']\n",
    "dropout = best_params['dropout']\n",
    "batch_size = best_params['batch_size']\n",
    "learning_rate = best_params['lr']\n",
    "l2_lambda = best_params['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a72209",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X_all.append(train_features[i:i+SEQ_LEN])\n",
    "    y_all.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "# --- Attention付きLSTMモデルの構築 ---\n",
    "model = create_lstm_attention_model(\n",
    "    input_shape=(SEQ_LEN, X_all.shape[2]),\n",
    "    units=units,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    lr=learning_rate,\n",
    "    l2_lambda=l2_lambda\n",
    ")\n",
    "\n",
    "# --- コールバックの設定 ---\n",
    "es = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# --- 学習 ---\n",
    "history = model.fit(\n",
    "    X_all, y_all,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[es, reduce_lr]\n",
    ")\n",
    "\n",
    "# --- 全データでの予測とRMSE計算 ---\n",
    "y_pred = model.predict(X_all).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(y_all, y_pred))\n",
    "print(f\"Train RMSE: {rmse:.3f}\")\n",
    "\n",
    "# --- 学習曲線の可視化 ---\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeddafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../output/モデル/lstm_model720.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
