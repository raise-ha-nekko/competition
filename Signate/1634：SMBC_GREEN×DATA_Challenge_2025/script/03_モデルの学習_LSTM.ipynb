{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3f14dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import shap\n",
    "from pdpbox import pdp\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Attention, Multiply, Lambda, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef38b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/iwasakitakahiro/github')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import common\n",
    "\n",
    "# モジュールの再読み込み\n",
    "importlib.reload(common)\n",
    "\n",
    "_common = common.Common()\n",
    "_common.BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64235bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'func' from '/Users/iwasakitakahiro/github/共通関数/func.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_func_path = _common.COMMON_FUNC_PATH\n",
    "sys.path.append(str(common_func_path))\n",
    "\n",
    "import func\n",
    "\n",
    "importlib.reload(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e76213f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../output/中間データ/学習用データ/train_preprocessed.csv')\n",
    "test_df = pd.read_csv('../output/中間データ/評価用データ/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "566c0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現性確保のための固定シード\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Optunaのシードも固定\n",
    "sampler = optuna.samplers.TPESampler(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "568c4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "exclude_cols = ['time', 'price_actual']  # 目的変数＋timeは除外\n",
    "features = [col for col in train_df.columns if col not in exclude_cols]\n",
    "target_col = 'price_actual'\n",
    "\n",
    "bin_cols = ['is_holiday', 'tight_supply_flag']\n",
    "cont_cols = [c for c in features if c not in bin_cols]\n",
    "\n",
    "scaler = MinMaxScaler().fit(train_df[cont_cols])\n",
    "train_scaled = scaler.transform(train_df[cont_cols])\n",
    "test_scaled  = scaler.transform(test_df[cont_cols])\n",
    "\n",
    "# 動的入力：連続 + バイナリそのまま\n",
    "train_features = np.hstack([train_scaled, train_df[bin_cols].values])\n",
    "test_features  = np.hstack([test_scaled,  test_df[bin_cols].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b467a",
   "metadata": {},
   "source": [
    "## SEQ_LEN: 24時間前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a209d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LSTM用の時系列ウィンドウデータ作成 ---\n",
    "SEQ_LEN = 24\n",
    "X, y = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X.append(train_features[i:i+SEQ_LEN])\n",
    "    y.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X = np.array(X)\n",
    "y = np.array(np.log1p(y))\n",
    "\n",
    "# trainの最後SEQ_LEN行を取得\n",
    "tail_train = train_features[-SEQ_LEN:, :]   # shape: (SEQ_LEN, 特徴量数)\n",
    "\n",
    "# test_features（np.array）と連結\n",
    "concat_test = np.vstack([tail_train, test_features])   # shape: (SEQ_LEN + len(test), 特徴量数)\n",
    "concat_test_df = pd.DataFrame(concat_test, columns=features)\n",
    "concat_test_df.to_csv('../output/中間データ/評価用データ/test_features_for_lstm24.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd0948",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5b37bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 07:20:47,507] A new study created in memory with name: no-name-b3d8e4e0-5632-49f6-aca1-fcfe971aab66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 07:23:39,947] Trial 0 finished with value: 13.280151757703223 and parameters: {'units': 32, 'num_layers': 1, 'dropout': 0.2875027280294855, 'batch_size': 32, 'lr': 0.0012024271332481814, 'l2': 1.9100117696145977e-07}. Best is trial 0 with value: 13.280151757703223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 07:27:15,159] Trial 1 finished with value: 12.396381488124524 and parameters: {'units': 32, 'num_layers': 1, 'dropout': 0.19248363724104595, 'batch_size': 16, 'lr': 0.0064521514794948385, 'l2': 1.6682473114624767e-07}. Best is trial 1 with value: 12.396381488124524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 07:31:05,925] Trial 2 finished with value: 12.983086918593655 and parameters: {'units': 128, 'num_layers': 1, 'dropout': 0.2982870714821235, 'batch_size': 64, 'lr': 0.009972226141402994, 'l2': 7.766054870958582e-07}. Best is trial 1 with value: 12.396381488124524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 07:36:28,754] Trial 3 finished with value: 13.026582675602441 and parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.26765351006578, 'batch_size': 32, 'lr': 0.004695302098577037, 'l2': 1.414395685390351e-06}. Best is trial 1 with value: 12.396381488124524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 07:45:07,127] Trial 4 finished with value: 12.914668821098802 and parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.11173427819331212, 'batch_size': 32, 'lr': 0.009937356452926236, 'l2': 0.0005285072720874012}. Best is trial 1 with value: 12.396381488124524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 08:01:57,002] Trial 5 finished with value: 12.031897122249399 and parameters: {'units': 128, 'num_layers': 2, 'dropout': 0.2086256460377257, 'batch_size': 32, 'lr': 0.009489187343057233, 'l2': 3.7707799079880474e-05}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 08:08:02,823] Trial 6 finished with value: 12.37325029550665 and parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.27651881190432415, 'batch_size': 32, 'lr': 0.0039514633239483435, 'l2': 6.80119538842334e-07}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 08:18:38,542] Trial 7 finished with value: 12.547614074943867 and parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.3667324760435, 'batch_size': 16, 'lr': 0.002857818153984576, 'l2': 1.8516493005812156e-07}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 08:54:31,502] Trial 8 finished with value: 12.560069038817744 and parameters: {'units': 128, 'num_layers': 2, 'dropout': 0.18884616740192134, 'batch_size': 16, 'lr': 0.007334576822081806, 'l2': 9.285626135535096e-06}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 09:04:48,410] Trial 9 finished with value: 12.606962605051939 and parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.10910172620327861, 'batch_size': 16, 'lr': 0.00738322549765662, 'l2': 2.6237546508053486e-06}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 09:11:09,902] Trial 10 finished with value: 13.046118798464853 and parameters: {'units': 128, 'num_layers': 1, 'dropout': 0.48473458796378127, 'batch_size': 64, 'lr': 0.00840735362020614, 'l2': 0.0001522702756690579}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 09:42:20,867] Trial 11 finished with value: 13.111193165834287 and parameters: {'units': 128, 'num_layers': 2, 'dropout': 0.3849315992685508, 'batch_size': 32, 'lr': 0.00406982633141637, 'l2': 4.4137632175197384e-05}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 10:16:37,084] Trial 12 finished with value: 12.04536131703864 and parameters: {'units': 128, 'num_layers': 2, 'dropout': 0.2030767341637743, 'batch_size': 32, 'lr': 0.0024260731774238533, 'l2': 1.812008949141705e-05}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:11:27,014] Trial 13 finished with value: 12.166126274755038 and parameters: {'units': 128, 'num_layers': 2, 'dropout': 0.198597293853071, 'batch_size': 32, 'lr': 0.000939595995517766, 'l2': 2.466240081718981e-05}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:49:17,079] Trial 14 finished with value: 12.274137892750906 and parameters: {'units': 128, 'num_layers': 2, 'dropout': 0.22260556239955612, 'batch_size': 32, 'lr': 0.0023771238168786226, 'l2': 7.052336041359656e-06}. Best is trial 5 with value: 12.031897122249399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'units': 128, 'num_layers': 2, 'dropout': 0.2086256460377257, 'batch_size': 32, 'lr': 0.009489187343057233, 'l2': 3.7707799079880474e-05}\n",
      "Best CV RMSE: 12.031897122249399\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_attention_model(input_shape, units, num_layers, dropout, lr, l2_lambda, dense_units=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = LSTM(units, return_sequences=True, dropout=dropout,\n",
    "                 kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    # Attention (Self-Attention)\n",
    "    attention_output = Attention()([x, x])  # shape: [batch, time, units]\n",
    "    context_vector = GlobalAveragePooling1D()(attention_output)  # shape: [batch, units]\n",
    "\n",
    "    x = Dense(dense_units, activation='relu', kernel_regularizer=l2(l2_lambda))(context_vector)\n",
    "    output = Dense(1, activation='linear', kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    # model.compile(optimizer=RMSprop(learning_rate=lr), loss='mse')\n",
    "    model.compile(optimizer=AdamW(1e-3), loss=tf.keras.losses.Huber(delta=20))\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "    l2_lambda = trial.suggest_float('l2', 1e-7, 1e-3, log=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in tscv.split(X):  # あなたのX, yのウィンドウ化後配列を前提\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = create_lstm_attention_model((X.shape[1], X.shape[2]), units, num_layers, dropout, learning_rate, l2_lambda)\n",
    "        es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=200,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es, reduce_lr]\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val).flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(y_pred)))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)\n",
    "\n",
    "# --- Optunaでパラメータ探索 ---\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best CV RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d7c69",
   "metadata": {},
   "source": [
    "#### 全データで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e545207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "units = best_params['units']\n",
    "num_layers = best_params['num_layers']\n",
    "dropout = best_params['dropout']\n",
    "batch_size = best_params['batch_size']\n",
    "learning_rate = best_params['lr']\n",
    "l2_lambda = best_params['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f982f3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - loss: 0.2639 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - loss: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1007s\u001b[0m 1s/step - loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4028s\u001b[0m 5s/step - loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1932s\u001b[0m 2s/step - loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1897s\u001b[0m 2s/step - loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1154s\u001b[0m 1s/step - loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1447s\u001b[0m 2s/step - loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3945s\u001b[0m 5s/step - loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1950s\u001b[0m 2s/step - loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2583s\u001b[0m 3s/step - loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3656s\u001b[0m 4s/step - loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1988s\u001b[0m 2s/step - loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 188ms/step - loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2580s\u001b[0m 3s/step - loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2601s\u001b[0m 3s/step - loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2975s\u001b[0m 4s/step - loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1693s\u001b[0m 2s/step - loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m933s\u001b[0m 1s/step - loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1930s\u001b[0m 2s/step - loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m945s\u001b[0m 1s/step - loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1655s\u001b[0m 793ms/step - loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2011s\u001b[0m 2s/step - loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2883s\u001b[0m 4s/step - loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3629s\u001b[0m 4s/step - loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1988s\u001b[0m 2s/step - loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2846s\u001b[0m 3s/step - loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2436s\u001b[0m 3s/step - loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2676s\u001b[0m 3s/step - loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2819s\u001b[0m 3s/step - loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0156 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0152 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0149 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0149 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0152 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0144 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m954s\u001b[0m 1s/step - loss: 0.0144 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3726s\u001b[0m 5s/step - loss: 0.0144 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m936s\u001b[0m 1s/step - loss: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1648s\u001b[0m 2s/step - loss: 0.0138 - learning_rate: 5.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1831s\u001b[0m 2s/step - loss: 0.0143 - learning_rate: 5.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1829s\u001b[0m 2s/step - loss: 0.0139 - learning_rate: 5.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3656s\u001b[0m 4s/step - loss: 0.0144 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2974s\u001b[0m 4s/step - loss: 0.0134 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2691s\u001b[0m 3s/step - loss: 0.0136 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2688s\u001b[0m 3s/step - loss: 0.0134 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2632s\u001b[0m 3s/step - loss: 0.0125 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3656s\u001b[0m 4s/step - loss: 0.0127 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1891s\u001b[0m 2s/step - loss: 0.0123 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3718s\u001b[0m 5s/step - loss: 0.0128 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1711s\u001b[0m 2s/step - loss: 0.0123 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1079s\u001b[0m 1s/step - loss: 0.0121 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2581s\u001b[0m 3s/step - loss: 0.0120 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2880s\u001b[0m 4s/step - loss: 0.0122 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2735s\u001b[0m 3s/step - loss: 0.0125 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2757s\u001b[0m 3s/step - loss: 0.0122 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2609s\u001b[0m 3s/step - loss: 0.0119 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3655s\u001b[0m 4s/step - loss: 0.0121 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1962s\u001b[0m 2s/step - loss: 0.0115 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1703s\u001b[0m 2s/step - loss: 0.0118 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3891s\u001b[0m 5s/step - loss: 0.0115 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1071s\u001b[0m 1s/step - loss: 0.0115 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1993s\u001b[0m 2s/step - loss: 0.0116 - learning_rate: 2.5000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1730s\u001b[0m 2s/step - loss: 0.0114 - learning_rate: 2.5000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4057s\u001b[0m 5s/step - loss: 0.0114 - learning_rate: 2.5000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1349s\u001b[0m 2s/step - loss: 0.0112 - learning_rate: 2.5000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3835s\u001b[0m 5s/step - loss: 0.0114 - learning_rate: 2.5000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2003s\u001b[0m 2s/step - loss: 0.0113 - learning_rate: 2.5000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2481s\u001b[0m 3s/step - loss: 0.0115 - learning_rate: 2.5000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3573s\u001b[0m 4s/step - loss: 0.0110 - learning_rate: 2.5000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1916s\u001b[0m 2s/step - loss: 0.0114 - learning_rate: 2.5000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m945s\u001b[0m 1s/step - loss: 0.0108 - learning_rate: 2.5000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 433ms/step - loss: 0.0108 - learning_rate: 2.5000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0110 - learning_rate: 2.5000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0112 - learning_rate: 2.5000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0108 - learning_rate: 2.5000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - loss: 0.0113 - learning_rate: 2.5000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - loss: 0.0107 - learning_rate: 2.5000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m977s\u001b[0m 1s/step - loss: 0.0109 - learning_rate: 2.5000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2487s\u001b[0m 3s/step - loss: 0.0107 - learning_rate: 2.5000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1391s\u001b[0m 2s/step - loss: 0.0111 - learning_rate: 2.5000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2414s\u001b[0m 3s/step - loss: 0.0103 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1706s\u001b[0m 2s/step - loss: 0.0109 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3886s\u001b[0m 5s/step - loss: 0.0113 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1736s\u001b[0m 2s/step - loss: 0.0109 - learning_rate: 2.5000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1902s\u001b[0m 2s/step - loss: 0.0107 - learning_rate: 2.5000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2772s\u001b[0m 3s/step - loss: 0.0104 - learning_rate: 2.5000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2639s\u001b[0m 3s/step - loss: 0.0102 - learning_rate: 1.2500e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3657s\u001b[0m 4s/step - loss: 0.0099 - learning_rate: 1.2500e-04\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step\n",
      "Train RMSE: 10.591\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_all, y_all = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X_all.append(train_features[i:i+SEQ_LEN])\n",
    "    y_all.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(np.log1p(y_all))\n",
    "\n",
    "# --- Attention付きLSTMモデルの構築 ---\n",
    "model = create_lstm_attention_model(\n",
    "    input_shape=(SEQ_LEN, X_all.shape[2]),\n",
    "    units=units,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    lr=learning_rate,\n",
    "    l2_lambda=l2_lambda\n",
    ")\n",
    "\n",
    "# --- コールバックの設定 ---\n",
    "es = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# --- 学習 ---\n",
    "history = model.fit(\n",
    "    X_all, y_all,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[es, reduce_lr]\n",
    ")\n",
    "\n",
    "# --- 全データでの予測とRMSE計算 ---\n",
    "y_pred = model.predict(X_all).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(np.expm1(y_all), np.expm1(y_pred)))\n",
    "print(f\"Train RMSE: {rmse:.3f}\")\n",
    "\n",
    "# --- 学習曲線の可視化 ---\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b33750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../output/モデル/lstm_model24.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf95cd",
   "metadata": {},
   "source": [
    "## SEQ_LEN: 1週間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LSTM用の時系列ウィンドウデータ作成 ---\n",
    "SEQ_LEN = 168\n",
    "X, y = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X.append(train_features[i:i+SEQ_LEN])\n",
    "    y.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X = np.array(X)\n",
    "y = np.array(np.log1p(y))\n",
    "\n",
    "# trainの最後SEQ_LEN行を取得\n",
    "tail_train = train_features[-SEQ_LEN:, :]   # shape: (SEQ_LEN, 特徴量数)\n",
    "\n",
    "# test_features（np.array）と連結\n",
    "concat_test = np.vstack([tail_train, test_features])   # shape: (SEQ_LEN + len(test), 特徴量数)\n",
    "concat_test_df = pd.DataFrame(concat_test, columns=features)\n",
    "concat_test_df.to_csv('../output/中間データ/評価用データ/test_features_for_lstm168.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa667bd6",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d95a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 10:11:10,001] A new study created in memory with name: no-name-f9f4c257-27c4-45b6-86a9-e8ce5f770edf\n",
      "[W 2025-06-11 10:11:40,634] Trial 0 failed with parameters: {'units': 64, 'num_layers': 2, 'dropout': 0.2985807913397629, 'batch_size': 32, 'lr': 0.008091627020217134, 'l2': 6.51118212219688e-07} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/sb/t91v_nzj05sbsfnhcjb832xr0000gn/T/ipykernel_5924/1792540141.py\", line 38, in objective\n",
      "    model.fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
      "    results = tracing_compilation.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1500, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-11 10:11:40,644] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# --- Optunaでパラメータ探索 ---\u001b[39;00m\n\u001b[32m     54\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest CV RMSE:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    357\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    358\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    359\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    360\u001b[39m \n\u001b[32m    361\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    244\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    247\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    248\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    250\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    202\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    203\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     35\u001b[39m es = EarlyStopping(patience=\u001b[32m20\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     36\u001b[39m reduce_lr = ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m8\u001b[39m, min_lr=\u001b[32m1e-6\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m y_pred = model.predict(X_val).flatten()\n\u001b[32m     48\u001b[39m rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1498\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1509\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1510\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1514\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1515\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def create_lstm_attention_model(input_shape, units, num_layers, dropout, lr, l2_lambda, dense_units=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = LSTM(units, return_sequences=True, dropout=dropout,\n",
    "                 kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    # Attention (Self-Attention)\n",
    "    attention_output = Attention()([x, x])  # shape: [batch, time, units]\n",
    "    context_vector = GlobalAveragePooling1D()(attention_output)  # shape: [batch, units]\n",
    "\n",
    "    x = Dense(dense_units, activation='relu', kernel_regularizer=l2(l2_lambda))(context_vector)\n",
    "    output = Dense(1, activation='linear', kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    # model.compile(optimizer=RMSprop(learning_rate=lr), loss='mse')\n",
    "    model.compile(optimizer=AdamW(1e-3), loss=tf.keras.losses.Huber(delta=20))\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "    l2_lambda = trial.suggest_float('l2', 1e-7, 1e-3, log=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in tscv.split(X):  # あなたのX, yのウィンドウ化後配列を前提\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = create_lstm_attention_model((X.shape[1], X.shape[2]), units, num_layers, dropout, learning_rate, l2_lambda)\n",
    "        es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=200,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es, reduce_lr]\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val).flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)\n",
    "\n",
    "# --- Optunaでパラメータ探索 ---\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best CV RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569bde7c",
   "metadata": {},
   "source": [
    "#### 全データで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f46ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "units = best_params['units']\n",
    "num_layers = best_params['num_layers']\n",
    "dropout = best_params['dropout']\n",
    "batch_size = best_params['batch_size']\n",
    "learning_rate = best_params['lr']\n",
    "l2_lambda = best_params['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71242411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 46ms/step - loss: 1726.6941\n",
      "Epoch 2/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 249.2115\n",
      "Epoch 3/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 198.7570\n",
      "Epoch 4/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 124.8483\n",
      "Epoch 5/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - loss: 105.8403\n",
      "Epoch 6/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 95.3063\n",
      "Epoch 7/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 88.0377\n",
      "Epoch 8/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 85.3183\n",
      "Epoch 9/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 84.7468\n",
      "Epoch 10/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 80.5158\n",
      "Epoch 11/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 76.4179\n",
      "Epoch 12/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1032s\u001b[0m 3s/step - loss: 71.8479\n",
      "Epoch 13/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 73.5621\n",
      "Epoch 14/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 72.4995\n",
      "Epoch 15/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 71.8405\n",
      "Epoch 16/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 69.6505\n",
      "Epoch 17/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 68.0200\n",
      "Epoch 18/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 66.3726\n",
      "Epoch 19/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 66.0126\n",
      "Epoch 20/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 64.9808\n",
      "Epoch 21/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 62.8984\n",
      "Epoch 22/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - loss: 61.8864\n",
      "Epoch 23/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 63.6750\n",
      "Epoch 24/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 62.7459\n",
      "Epoch 25/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1025s\u001b[0m 3s/step - loss: 60.1563\n",
      "Epoch 26/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 60.2484\n",
      "Epoch 27/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 59.3820\n",
      "Epoch 28/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 58.1327\n",
      "Epoch 29/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1041s\u001b[0m 3s/step - loss: 56.7412\n",
      "Epoch 30/30\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - loss: 57.0022\n",
      "\u001b[1m814/814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step\n",
      "Train RMSE: 5.710\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X_all.append(train_features[i:i+SEQ_LEN])\n",
    "    y_all.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "# --- Attention付きLSTMモデルの構築 ---\n",
    "model = create_lstm_attention_model(\n",
    "    input_shape=(SEQ_LEN, X_all.shape[2]),\n",
    "    units=units,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    lr=learning_rate,\n",
    "    l2_lambda=l2_lambda\n",
    ")\n",
    "\n",
    "# --- コールバックの設定 ---\n",
    "es = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# --- 学習 ---\n",
    "history = model.fit(\n",
    "    X_all, y_all,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[es, reduce_lr]\n",
    ")\n",
    "\n",
    "# --- 全データでの予測とRMSE計算 ---\n",
    "y_pred = model.predict(X_all).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(y_all, y_pred))\n",
    "print(f\"Train RMSE: {rmse:.3f}\")\n",
    "\n",
    "# --- 学習曲線の可視化 ---\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../output/モデル/lstm_model168.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c60e47",
   "metadata": {},
   "source": [
    "## SEQ_LEN: 1ヶ月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee65b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LSTM用の時系列ウィンドウデータ作成 ---\n",
    "SEQ_LEN = 720\n",
    "X, y = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X.append(train_features[i:i+SEQ_LEN])\n",
    "    y.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X = np.array(X)\n",
    "y = np.array(np.log1p(y))\n",
    "\n",
    "# trainの最後SEQ_LEN行を取得\n",
    "tail_train = train_features[-SEQ_LEN:, :]   # shape: (SEQ_LEN, 特徴量数)\n",
    "\n",
    "# test_features（np.array）と連結\n",
    "concat_test = np.vstack([tail_train, test_features])   # shape: (SEQ_LEN + len(test), 特徴量数)\n",
    "concat_test_df = pd.DataFrame(concat_test, columns=features)\n",
    "concat_test_df.to_csv('../output/中間データ/評価用データ/test_features_for_lstm720.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069fc31",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 07:29:29,594] A new study created in memory with name: no-name-97ac65c7-8ceb-4beb-b1e1-63043373cde5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 07:44:49,040] Trial 0 finished with value: 13.685517930485718 and parameters: {'units': 32, 'num_layers': 1, 'dropout': 0.3835501303239237, 'batch_size': 64, 'lr': 0.009183389122550368}. Best is trial 0 with value: 13.685517930485718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-09 09:22:07,411] Trial 1 failed with parameters: {'units': 32, 'num_layers': 2, 'dropout': 0.46850881206753436, 'batch_size': 64, 'lr': 0.0014355950712513347} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/sb/t91v_nzj05sbsfnhcjb832xr0000gn/T/ipykernel_80921/272806354.py\", line 29, in objective\n",
      "    model.fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
      "    results = tracing_compilation.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1500, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-09 09:22:07,514] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# --- Optunaでパラメータ探索 ---\u001b[39;00m\n\u001b[32m     45\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest CV RMSE:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    357\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    358\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    359\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    360\u001b[39m \n\u001b[32m    361\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    244\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    247\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    248\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    250\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    202\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    203\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     27\u001b[39m model = create_lstm_model((X.shape[\u001b[32m1\u001b[39m], X.shape[\u001b[32m2\u001b[39m]), units, num_layers, dropout, learning_rate)\n\u001b[32m     28\u001b[39m es = EarlyStopping(patience=\u001b[32m5\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m y_pred = model.predict(X_val).flatten()\n\u001b[32m     39\u001b[39m rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1498\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1509\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1510\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1514\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1515\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def create_lstm_attention_model(input_shape, units, num_layers, dropout, lr, l2_lambda, dense_units=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = LSTM(units, return_sequences=True, dropout=dropout,\n",
    "                 kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    # Attention (Self-Attention)\n",
    "    attention_output = Attention()([x, x])  # shape: [batch, time, units]\n",
    "    context_vector = GlobalAveragePooling1D()(attention_output)  # shape: [batch, units]\n",
    "\n",
    "    x = Dense(dense_units, activation='relu', kernel_regularizer=l2(l2_lambda))(context_vector)\n",
    "    output = Dense(1, activation='linear', kernel_regularizer=l2(l2_lambda))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer=RMSprop(learning_rate=lr), loss='mse')\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "    l2_lambda = trial.suggest_float('l2', 1e-7, 1e-3, log=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in tscv.split(X):  # あなたのX, yのウィンドウ化後配列を前提\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = create_lstm_attention_model((X.shape[1], X.shape[2]), units, num_layers, dropout, learning_rate, l2_lambda)\n",
    "        es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=200,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es, reduce_lr]\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val).flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)\n",
    "\n",
    "# --- Optunaでパラメータ探索 ---\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best CV RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ca460",
   "metadata": {},
   "source": [
    "#### 全データで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febdb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "units = best_params['units']\n",
    "num_layers = best_params['num_layers']\n",
    "dropout = best_params['dropout']\n",
    "batch_size = best_params['batch_size']\n",
    "learning_rate = best_params['lr']\n",
    "l2_lambda = best_params['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a72209",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = [], []\n",
    "for i in range(len(train_features) - SEQ_LEN):\n",
    "    X_all.append(train_features[i:i+SEQ_LEN])\n",
    "    y_all.append(train_df[target_col].iloc[i+SEQ_LEN])\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "# --- Attention付きLSTMモデルの構築 ---\n",
    "model = create_lstm_attention_model(\n",
    "    input_shape=(SEQ_LEN, X_all.shape[2]),\n",
    "    units=units,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    lr=learning_rate,\n",
    "    l2_lambda=l2_lambda\n",
    ")\n",
    "\n",
    "# --- コールバックの設定 ---\n",
    "es = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# --- 学習 ---\n",
    "history = model.fit(\n",
    "    X_all, y_all,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[es, reduce_lr]\n",
    ")\n",
    "\n",
    "# --- 全データでの予測とRMSE計算 ---\n",
    "y_pred = model.predict(X_all).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(y_all, y_pred))\n",
    "print(f\"Train RMSE: {rmse:.3f}\")\n",
    "\n",
    "# --- 学習曲線の可視化 ---\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeddafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../output/モデル/lstm_model720.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
