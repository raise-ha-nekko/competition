{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c54be4",
   "metadata": {},
   "source": [
    "# 国土数値情報の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7375f2",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b518e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの取り扱いに関するライブラリ\n",
    "import numpy as np # 高速計算\n",
    "import pandas as pd # 表データの扱い\n",
    "\n",
    "# 可視化に関するライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "\n",
    "import geopandas as gpd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pyogrio import read_dataframe\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29fd42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自身がファイルを格納したディレクトリを指定\n",
    "ROOT_DIR = '../input/'\n",
    "train_file_path = ROOT_DIR + 'train.csv'\n",
    "test_file_path = ROOT_DIR + 'test.csv'\n",
    "intermediate_path = '../output/intermediate_file/'\n",
    "gis_path = ROOT_DIR + 'GISデータ/'\n",
    "\n",
    "pkey_cols = ['target_ym', 'building_id', 'unit_id']\n",
    "geo_cols = ['lat', 'lon']\n",
    "\n",
    "geo_ver = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bd4b4",
   "metadata": {},
   "source": [
    "## File Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae27961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_geo = pd.read_csv(train_file_path)[pkey_cols + geo_cols]\n",
    "test_df_geo = pd.read_csv(test_file_path)[pkey_cols + geo_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa4d782",
   "metadata": {},
   "source": [
    "## データの変換"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c3f3c",
   "metadata": {},
   "source": [
    "#### 対象年の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "689612a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_year(date_input):\n",
    "    try:\n",
    "        s = str(date_input)\n",
    "        if len(s) < 4:\n",
    "            return np.nan\n",
    "        return int(s[:4])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba94e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_geo['target_year'] = train_df_geo['target_ym'].apply(parse_year)\n",
    "test_df_geo['target_year'] = test_df_geo['target_ym'].apply(parse_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19971b5a",
   "metadata": {},
   "source": [
    "#### 測地系の変換(EPSG:6668 → EPSG:4612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff57d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_jgd_from_wgs(df, lon_wgs_col='lon', lat_wgs_col='lat'):\n",
    "    \"\"\"\n",
    "    JGD2011(EPSG:6668) → JGD2000(EPSG:4612) に変換して補完する\n",
    "    \"\"\"\n",
    "\n",
    "    # 2) 世界測地系の GeoDataFrame\n",
    "    gdf_wgs = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(df[lon_wgs_col], df[lat_wgs_col]),\n",
    "        crs='EPSG:6668'\n",
    "    )\n",
    "\n",
    "    # 3) 日本測地系（JGD2000, EPSG:4612）に変換\n",
    "    gdf_jgd = gdf_wgs.to_crs(epsg=4612)\n",
    "\n",
    "    # 4) 変換後の座標を el/nl に入れる\n",
    "    df['lon_jgd'] = gdf_jgd.geometry.x.values  # 経度（4612）\n",
    "    df['lat_jgd'] = gdf_jgd.geometry.y.values  # 緯度（4612）\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b81db26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_geo = fill_jgd_from_wgs(train_df_geo)\n",
    "test_df_geo = fill_jgd_from_wgs(test_df_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1acf9",
   "metadata": {},
   "source": [
    "## 地価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "675b879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4612\n"
     ]
    }
   ],
   "source": [
    "land_gdf = read_dataframe(f'{gis_path}公示地価/L01-23_GML/L01-23.geojson') \n",
    "print(land_gdf.crs) # EPSG:4612(日本測地系2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "73b8c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_gdf = land_gdf.rename(columns={\n",
    "    'L01_005': 'land_year',            # 年度（例: 2023）\n",
    "    'L01_006': 'land_price_2023',    # 公示地価 [円/㎡]\n",
    "    'L01_007': 'land_price_yoy_pct',   # 対前年変動率 [%]\n",
    "})\n",
    "\n",
    "year_to_col = {y: f'L01_{y - 1921:03d}' for y in range(2018, 2023)}\n",
    "rename_price_cols = {col: f'land_price_{year}' \n",
    "                     for year, col in year_to_col.items()}\n",
    "\n",
    "land_gdf = land_gdf.rename(columns=rename_price_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b44f612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_price_features_haversine(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    land_gdf: gpd.GeoDataFrame,\n",
    "    lat_col: str,\n",
    "    lon_col: str,\n",
    "    year_col: str,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    各物件について、同じ year の land_price_YYYY を持つ標準地から\n",
    "\n",
    "    - 最近傍1点の地価: nearest_land_price\n",
    "    - その距離[m]: distance_to_landpoint_m\n",
    "    - log(nearest_land_price + 1): log_land_price\n",
    "    - 最近傍3点距離加重平均地価: weighted_land_price_3\n",
    "    - その log: log_weighted_land_price_3\n",
    "\n",
    "    を haversine 距離（球面距離）を用いて付与する。\n",
    "    緯度経度は「度（deg）」前提（JGD2000/JGD2011/WGS84 いずれでも OK、揃っていればよい）。\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) train/test を結合\n",
    "    combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "    # 2) 座標がまともな行だけ対象\n",
    "    lat = combined_df[lat_col]\n",
    "    lon = combined_df[lon_col]\n",
    "\n",
    "    valid_mask = (\n",
    "        lat.notna() & lon.notna()\n",
    "        & lat.between(-90, 90)\n",
    "        & lon.between(-180, 180)\n",
    "    )\n",
    "    df_valid = combined_df.loc[valid_mask].copy()\n",
    "\n",
    "    n_all = len(combined_df)\n",
    "    nearest_all  = np.full(n_all, np.nan, dtype=float)\n",
    "    dist_all     = np.full(n_all, np.nan, dtype=float)\n",
    "    weighted_all = np.full(n_all, np.nan, dtype=float)\n",
    "    nearest_prev_all  = np.full(n_all, np.nan, dtype=float)\n",
    "    weighted_prev_all = np.full(n_all, np.nan, dtype=float)\n",
    "\n",
    "    # 3) 標準地側の座標（land_gdf）をラジアンに変換\n",
    "    land_lon_deg = land_gdf.geometry.x.to_numpy()\n",
    "    land_lat_deg = land_gdf.geometry.y.to_numpy()\n",
    "\n",
    "    land_lon_rad = np.deg2rad(land_lon_deg)\n",
    "    land_lat_rad = np.deg2rad(land_lat_deg)\n",
    "\n",
    "    land_X = np.vstack([land_lat_rad, land_lon_rad]).T  # (n_land, 2)\n",
    "\n",
    "    # 4) 最近傍 3点探索 (haversine)\n",
    "    nn = NearestNeighbors(n_neighbors=3, metric=\"haversine\")\n",
    "    nn.fit(land_X)\n",
    "\n",
    "    # 5) 物件側の座標をラジアンに変換\n",
    "    prop_lat_deg = df_valid[lat_col].to_numpy()\n",
    "    prop_lon_deg = df_valid[lon_col].to_numpy()\n",
    "\n",
    "    prop_lat_rad = np.deg2rad(prop_lat_deg)\n",
    "    prop_lon_rad = np.deg2rad(prop_lon_deg)\n",
    "\n",
    "    prop_X = np.vstack([prop_lat_rad, prop_lon_rad]).T  # (n_valid, 2)\n",
    "\n",
    "    finite_mask = np.isfinite(prop_lat_rad) & np.isfinite(prop_lon_rad)\n",
    "    valid_index = df_valid.index.to_numpy()[finite_mask]\n",
    "\n",
    "    if len(valid_index) > 0:\n",
    "        # 距離は「ラジアン」で返ってくる\n",
    "        distances_rad, indices = nn.kneighbors(prop_X[finite_mask])  # (n_valid, 3)\n",
    "\n",
    "        # 年情報\n",
    "        years_valid = df_valid.loc[valid_index, year_col].to_numpy().astype(int)\n",
    "\n",
    "        nearest_prices  = []\n",
    "        nearest_dists_m = []\n",
    "        weighted_prices = []\n",
    "        nearest_prev_prices  = []\n",
    "        weighted_prev_prices = []\n",
    "\n",
    "        R = 6_371_000.0  # 地球半径[m]\n",
    "\n",
    "        for dist_row_rad, idx_row, year in zip(distances_rad, indices, years_valid):\n",
    "            # 距離[m] に変換\n",
    "            dist_row_m = dist_row_rad * R\n",
    "\n",
    "            col_y   = f'land_price_{year}'\n",
    "            col_y_1 = f'land_price_{year-1}'\n",
    "\n",
    "            prices_prev = land_gdf.iloc[idx_row][col_y_1].to_numpy().astype(float)\n",
    "            prices = land_gdf.iloc[idx_row][col_y].to_numpy().astype(float)\n",
    "\n",
    "            # --- 1点目（最近傍）の情報 ---\n",
    "            nearest_prices.append(prices[0])\n",
    "            nearest_dists_m.append(dist_row_m[0])\n",
    "\n",
    "            # --- 3点距離加重平均 ---\n",
    "            zero_mask = dist_row_m == 0\n",
    "            if zero_mask.any():\n",
    "                wp = prices[zero_mask].mean()\n",
    "            else:\n",
    "                w = 1.0 / dist_row_m\n",
    "                w = w / w.sum()\n",
    "                wp = np.dot(w, prices)\n",
    "            weighted_prices.append(wp)\n",
    "\n",
    "            nearest_prev_prices.append(prices_prev[0])\n",
    "            if zero_mask.any():\n",
    "                wp_prev = prices_prev[zero_mask].mean()\n",
    "            else:\n",
    "                wp_prev = np.dot(w, prices_prev)\n",
    "            weighted_prev_prices.append(wp_prev)\n",
    "\n",
    "        nearest_prices  = np.array(nearest_prices, dtype=float)\n",
    "        nearest_dists_m = np.array(nearest_dists_m, dtype=float)\n",
    "        weighted_prices = np.array(weighted_prices, dtype=float)\n",
    "        nearest_prev_prices  = np.array(nearest_prev_prices, dtype=float)\n",
    "        weighted_prev_prices = np.array(weighted_prev_prices, dtype=float)\n",
    "\n",
    "        nearest_all[valid_index]  = nearest_prices\n",
    "        dist_all[valid_index]     = nearest_dists_m\n",
    "        weighted_all[valid_index] = weighted_prices\n",
    "        nearest_prev_all[valid_index]  = nearest_prev_prices\n",
    "        weighted_prev_all[valid_index] = weighted_prev_prices\n",
    "\n",
    "    # 6) combined_df に列を追加\n",
    "    combined_df = combined_df.copy()\n",
    "    combined_df['nearest_land_price']       = nearest_all\n",
    "    combined_df['distance_to_landpoint_m']  = dist_all\n",
    "    combined_df['log_land_price']           = np.log1p(combined_df['nearest_land_price'])\n",
    "    combined_df['weighted_land_price_3']    = weighted_all\n",
    "    combined_df['log_weighted_land_price_3'] = np.log1p(combined_df['weighted_land_price_3'])\n",
    "    combined_df['nearest_land_price_prev']      = nearest_prev_all\n",
    "    combined_df['weighted_land_price_3_prev']   = weighted_prev_all\n",
    "\n",
    "    eps = 1.0  # 分母が小さいときの暴れ抑制（単位に応じて調整可）\n",
    "    denom_n = np.maximum(combined_df['nearest_land_price_prev'], eps)\n",
    "    denom_w = np.maximum(combined_df['weighted_land_price_3_prev'], eps)\n",
    "\n",
    "    combined_df['land_price_yoy_nearest'] = (combined_df['nearest_land_price'] - combined_df['nearest_land_price_prev']) / denom_n\n",
    "    combined_df['land_price_yoy_w3']      = (combined_df['weighted_land_price_3'] - combined_df['weighted_land_price_3_prev']) / denom_w\n",
    "\n",
    "    # 変動率（ログ差分：推奨）\n",
    "    combined_df['land_price_dlog_nearest'] = np.log1p(combined_df['nearest_land_price']) - np.log1p(combined_df['nearest_land_price_prev'])\n",
    "    combined_df['land_price_dlog_w3']      = np.log1p(combined_df['weighted_land_price_3']) - np.log1p(combined_df['weighted_land_price_3_prev'])\n",
    "\n",
    "    # 7) train/test に戻す\n",
    "    n_train = len(train_df)\n",
    "    train_out = combined_df.iloc[:n_train].reset_index(drop=True)\n",
    "    test_out  = combined_df.iloc[n_train:].reset_index(drop=True)\n",
    "\n",
    "    return train_out, test_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "269f079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_geo, test_df_geo = add_land_price_features_haversine(\n",
    "    train_df=train_df_geo,\n",
    "    test_df=test_df_geo,\n",
    "    land_gdf=land_gdf,\n",
    "    lat_col='lat_jgd',\n",
    "    lon_col='lon_jgd',\n",
    "    year_col='target_year'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0037e6",
   "metadata": {},
   "source": [
    "## 1kmメッシュ将来人口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a16436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fu_pop_path = gis_path + '人口メッシュ/1km_mesh_2024_GEOJSON/future_pop_1km.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e43dd",
   "metadata": {},
   "source": [
    "#### データの結合（最初の1回のみなのでコメントアウト）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1a739f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_dir = Path(gis_path + '人口メッシュ/1km_mesh_2024_GEOJSON')\n",
    "# files = sorted(in_dir.glob('1km_mesh_2024_*_GEOJSON/*.geojson'))\n",
    "# output_path = gis_path + '人口メッシュ/1km_mesh_2024_GEOJSON'\n",
    "\n",
    "# gdfs = []\n",
    "# base_crs = None\n",
    "\n",
    "# keep_cols = [\n",
    "#     'MESH_ID',\n",
    "#     'SHICODE',\n",
    "#     'PTN_2020', # 2020年の総数人口\n",
    "#     'PTN_2025', 'PTN_2030', 'PTN_2035', 'PTN_2040', 'PTN_2045', 'PTN_2050', # 将来人口\n",
    "#     'PTA_2025', 'RTA_2025', # 2025年男女計0～14歳人口/比率\n",
    "#     'PTB_2025', 'RTB_2025', # 2025年男女計15～64歳人口/比率\n",
    "#     'PTC_2025', 'RTC_2025', # 2025年男女計65歳以上人口/比率\n",
    "#     'PTD_2025', 'RTD_2025', # 2025年男女計75歳以上人口/比率\n",
    "#     'PTE_2025', 'RTE_2025', # 2025年男女計80歳以上人口/比率\n",
    "#     'geometry',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "90eaffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fp in files:\n",
    "#     gdf = read_dataframe(fp) # 高速化しないとめちゃ時間かかる\n",
    "#     gdf_filtered = gdf[keep_cols]\n",
    "\n",
    "#     # CRS を統一（最初のファイルの CRS に合わせる）\n",
    "#     if base_crs is None:\n",
    "#         base_crs = gdf.crs\n",
    "#     else:\n",
    "#         if gdf.crs != base_crs:\n",
    "#             gdf = gdf.to_crs(base_crs)\n",
    "\n",
    "#     gdfs.append(gdf_filtered)\n",
    "\n",
    "# # 結合（index を振り直す）\n",
    "# fu_pop_df = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True), crs=base_crs)\n",
    "# print(f\"crs: {fu_pop_df.crs}\")\n",
    "\n",
    "# del gdfs\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20d460f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 1) 対象年の列を抽出（例：PTN_2025, PTN_2030, ..., PTN_2070）\n",
    "# ptn_cols = sorted(\n",
    "#     [c for c in fu_pop_df.columns if re.match(r'^PTN_20\\d{2}$', c)]\n",
    "# )\n",
    "\n",
    "# years = np.array([int(c.split('_')[1]) for c in ptn_cols])\n",
    "\n",
    "# # --- 2) 線形回帰で傾きを計算\n",
    "# def _calc_slope(row):\n",
    "#     y = row[ptn_cols].values.astype(float)\n",
    "#     if np.isnan(y).sum() >= len(y) - 1:\n",
    "#         return np.nan\n",
    "#     slope, _ = np.polyfit(years, y, 1)\n",
    "#     return slope\n",
    "\n",
    "# fu_pop_df['pop_trend_slope'] = fu_pop_df.apply(_calc_slope, axis=1)\n",
    "\n",
    "# # --- 3) 正規化（0 除算・欠損対策込み）\n",
    "# fu_pop_df['pop_trend_rate'] = (\n",
    "#     fu_pop_df['pop_trend_slope'] /\n",
    "#     fu_pop_df['PTN_2025'].replace({0: np.nan})\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83b15cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ① 平面系へ\n",
    "# fu_pop_df_m = fu_pop_df.to_crs('EPSG:6677')\n",
    "\n",
    "# # ② centroid で Point 化\n",
    "# fu_pop_df_m['geometry'] = fu_pop_df_m.geometry.centroid\n",
    "\n",
    "# # ③ 必要なら緯度経度へ戻す\n",
    "# fu_pop_df_pt = fu_pop_df_m.to_crs('EPSG:4612')\n",
    "# fu_pop_df_pt['lon_4612'] = fu_pop_df_pt.geometry.x\n",
    "# fu_pop_df_pt['lat_4612'] = fu_pop_df_pt.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9408604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fu_pop_df_pt.to_parquet(output_path + '/future_pop_1km.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f470e",
   "metadata": {},
   "source": [
    "#### 学習データ・予測データに結合して特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2fa9e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fu_pop_df = gpd.read_parquet(fu_pop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f68d4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NOTE: 歪みが気になるのであればclipを用いる\n",
    "# display(fu_pop_df[['pop_trend_slope', 'pop_trend_rate']].describe())\n",
    "# q_low, q_high = fu_pop_df['pop_trend_rate'].quantile([0.01, 0.99])\n",
    "\n",
    "# fu_pop_df['pop_trend_rate_clip'] = (\n",
    "#     fu_pop_df['pop_trend_rate']\n",
    "#     .clip(lower=q_low, upper=q_high)\n",
    "# )\n",
    "\n",
    "# display(fu_pop_df[['pop_trend_slope', 'pop_trend_rate_clip']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36a20b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_point_gdf_from_lonlat(df: pd.DataFrame,\n",
    "                                 lon_col: str,\n",
    "                                 lat_col: str,\n",
    "                                 crs: str) -> gpd.GeoDataFrame:\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df.copy(),\n",
    "        geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n",
    "        crs=crs\n",
    "    )\n",
    "    return gdf\n",
    "\n",
    "def _idw(values: np.ndarray, dists: np.ndarray, power: float = 1.0, eps: float = 1e-6) -> np.ndarray:\n",
    "    # values: (n_samples, k), dists: (n_samples, k)\n",
    "    w = 1.0 / np.maximum(dists, eps) ** power\n",
    "    return np.sum(w * values, axis=1) / np.sum(w, axis=1)\n",
    "\n",
    "def add_pop_knn_features(train_df_geo: pd.DataFrame,\n",
    "                         test_df_geo: pd.DataFrame,\n",
    "                         fu_pop_df: gpd.GeoDataFrame,\n",
    "                         pop_cols: list[str],\n",
    "                         lon_col: str = 'lon_jgd',\n",
    "                         lat_col: str = 'lat_jgd',\n",
    "                         in_crs: str = 'EPSG:4612',\n",
    "                         work_crs: str = 'EPSG:6677',\n",
    "                         k: int = 3,\n",
    "                         idw_power: float = 1.0) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    train/test の各点に対して、人口メッシュ点の\n",
    "    - 最近傍（nn）\n",
    "    - k近傍の距離加重平均（idw）\n",
    "    を付与する。\n",
    "    \"\"\"\n",
    "    if k < 1:\n",
    "        raise ValueError('k must be >= 1')\n",
    "\n",
    "    # --- 1) train/test を Point GeoDataFrame 化（EPSG:4612）\n",
    "    tr_gdf = _ensure_point_gdf_from_lonlat(train_df_geo, lon_col, lat_col, in_crs)\n",
    "    te_gdf = _ensure_point_gdf_from_lonlat(test_df_geo, lon_col, lat_col, in_crs)\n",
    "\n",
    "    # --- 2) population を Point 化（Polygon の場合は centroid）\n",
    "    pop_gdf = fu_pop_df.copy()\n",
    "    if pop_gdf.geometry.iloc[0].geom_type != 'Point':\n",
    "        pop_gdf = pop_gdf.to_crs(work_crs)\n",
    "        pop_gdf['geometry'] = pop_gdf.geometry.centroid\n",
    "        pop_gdf = pop_gdf.to_crs(in_crs)\n",
    "\n",
    "    # --- 3) 作業用 CRS（メートル系）へ\n",
    "    tr_m = tr_gdf.to_crs(work_crs)\n",
    "    te_m = te_gdf.to_crs(work_crs)\n",
    "    pop_m = pop_gdf.to_crs(work_crs)\n",
    "\n",
    "    # --- 4) KNN 検索（メートル座標で）\n",
    "    pop_xy = np.column_stack([pop_m.geometry.x.values, pop_m.geometry.y.values])\n",
    "    nn = NearestNeighbors(n_neighbors=k, algorithm='auto', metric='euclidean')\n",
    "    nn.fit(pop_xy)\n",
    "\n",
    "    def _apply(gdf_m: gpd.GeoDataFrame, prefix: str) -> pd.DataFrame:\n",
    "        q_xy = np.column_stack([gdf_m.geometry.x.values, gdf_m.geometry.y.values])\n",
    "        dists, idxs = nn.kneighbors(q_xy, return_distance=True)  # shapes: (n, k)\n",
    "\n",
    "        out = pd.DataFrame(index=gdf_m.index)\n",
    "\n",
    "        # 最近傍距離\n",
    "        out[f'{prefix}_dist_nn_m'] = dists[:, 0].astype(np.float32)\n",
    "\n",
    "        # 各 pop_col について nn と idw を作る\n",
    "        for col in pop_cols:\n",
    "            vals = pop_m[col].values[idxs]  # (n, k)\n",
    "\n",
    "            out[f'{col}_nn'] = vals[:, 0]\n",
    "\n",
    "            if k >= 2:\n",
    "                out[f'{col}_idw{k}'] = _idw(vals.astype(float), dists.astype(float), power=idw_power)\n",
    "            else:\n",
    "                out[f'{col}_idw{k}'] = vals[:, 0]\n",
    "\n",
    "        return out\n",
    "\n",
    "    tr_feat = _apply(tr_m, 'pop')\n",
    "    te_feat = _apply(te_m, 'pop')\n",
    "\n",
    "    train_out = train_df_geo.join(tr_feat)\n",
    "    test_out = test_df_geo.join(te_feat)\n",
    "\n",
    "    return train_out, test_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ca49e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_cols = [\n",
    "    'PTN_2020', # 2020年の総数人口\n",
    "    'RTA_2025', # 2025年男女計0～14歳人口/比率\n",
    "    'RTB_2025', # 2025年男女計15～64歳人口/比率\n",
    "    'RTC_2025', # 2025年男女計65歳以上人口/比率\n",
    "    'RTD_2025', # 2025年男女計75歳以上人口/比率\n",
    "    'RTE_2025', # 2025年男女計80歳以上人口/比率\n",
    "    'pop_trend_rate'\n",
    "]\n",
    "\n",
    "train_df_geo, test_df_geo = add_pop_knn_features(\n",
    "    train_df_geo=train_df_geo,\n",
    "    test_df_geo=test_df_geo,\n",
    "    fu_pop_df=fu_pop_df,\n",
    "    pop_cols=pop_cols,\n",
    "    k=3,\n",
    "    idw_power=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f584d",
   "metadata": {},
   "source": [
    "## 道路密度・道路延長メッシュ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4bb724d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_path = gis_path + '道路密度・道路延長メッシュ/road_mesh_fe.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9633eb9f",
   "metadata": {},
   "source": [
    "#### データの結合（最初の1回のみなのでコメントアウト）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "73bf34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_dir = Path(gis_path + '道路密度・道路延長メッシュ')\n",
    "# files = sorted(in_dir.glob('N04-10_*-jgd_GML/*.shp'))\n",
    "# output_path = gis_path + '道路密度・道路延長メッシュ'\n",
    "\n",
    "# gdfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6d6fa997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fp in files:\n",
    "#     gdf = read_dataframe(fp) # 高速化しないとめちゃ時間かかる\n",
    "#     gdf = gdf.set_crs('EPSG:4612')\n",
    "#     # gdf_filtered = gdf[keep_cols]\n",
    "        \n",
    "#     gdfs.append(gdf)\n",
    "\n",
    "# # 結合（index を振り直す）\n",
    "# road_df = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True), crs=gdf.crs)\n",
    "# print(f\"crs: {road_df.crs}\")\n",
    "\n",
    "# del gdfs\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6fe1a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr_cols = road_df.columns.drop('geometry')\n",
    "\n",
    "# road_df[attr_cols] = (\n",
    "#     road_df[attr_cols]\n",
    "#         .replace('unknown', pd.NA)\n",
    "#         .apply(pd.to_numeric, errors='coerce')\n",
    "#         .astype('float32')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fbce3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_road_base_and_gap_features(\n",
    "#     gdf: gpd.GeoDataFrame,\n",
    "#     nn_epsg: int = 6677,          # 距離計算用（投影）\n",
    "#     k: int = 8,                   # 近傍メッシュ数\n",
    "#     idw_p: float = 1.0,           # 重み 1/(d^p)\n",
    "#     self_exclude: bool = True,    # 自メッシュを加重平均から除外\n",
    "#     add_density: bool = True,     # road_len_total / area を作るか\n",
    "#     area_unit_scale: float = 1e6, # 密度を 'm per km^2' にしたいなら 1e6\n",
    "#     eps: float = 1e-6,\n",
    "# ) -> gpd.GeoDataFrame:\n",
    "#     \"\"\"\n",
    "#     3次メッシュ polygon の GeoDataFrame（road_df想定）に対して、\n",
    "#     1) メッシュ内の道路延長集約（total/wide/narrow）と比率\n",
    "#     2) 周辺 k 近傍メッシュのIDW加重平均との差分（gap）\n",
    "#     3) 任意で道路延長密度（m/km^2 等）\n",
    "#     を付与して返す。\n",
    "\n",
    "#     前提:\n",
    "#       - gdf は polygon geometry を持つ\n",
    "#       - N04_*** 列は「当該メッシュ内の道路延長（m）」等の集計値として扱う（あなたの設計を踏襲）\n",
    "#     \"\"\"\n",
    "#     if gdf is None or len(gdf) == 0:\n",
    "#         raise ValueError('gdf is empty.')\n",
    "\n",
    "#     out = gdf.copy()\n",
    "\n",
    "#     # ---------\n",
    "#     # 1) ベース特徴量（メッシュ内）\n",
    "#     # ---------\n",
    "#     total_cols = ['N04_051', 'N04_052', 'N04_053', 'N04_054', 'N04_055', 'N04_056']\n",
    "#     wide_cols  = ['N04_003', 'N04_009', 'N04_015']  # ≒ 11m以上\n",
    "#     narrow_cols= ['N04_027', 'N04_033', 'N04_039']  # ≒ 5.5m未満\n",
    "\n",
    "#     # ない列があっても落ちないように 0 列を補う（データによって列が欠けることがあるため）\n",
    "#     for c in set(total_cols + wide_cols + narrow_cols):\n",
    "#         if c not in out.columns:\n",
    "#             out[c] = 0.0\n",
    "\n",
    "#     # 数値化（'unknown' 等が混ざるケースにも耐性）\n",
    "#     use_cols = list(dict.fromkeys(total_cols + wide_cols + narrow_cols))\n",
    "#     out[use_cols] = (\n",
    "#         out[use_cols]\n",
    "#             .replace('unknown', np.nan)\n",
    "#             .apply(lambda s: np.nan_to_num(np.asarray(s, dtype='float64'), nan=0.0))\n",
    "#     )\n",
    "\n",
    "#     out['road_len_total'] = out[total_cols].sum(axis=1).astype('float32')\n",
    "#     out['road_len_wide'] = out[wide_cols].sum(axis=1).astype('float32')\n",
    "#     out['road_len_narrow'] = out[narrow_cols].sum(axis=1).astype('float32')\n",
    "\n",
    "#     denom = (out['road_len_total'].to_numpy(dtype='float32') + eps)\n",
    "#     out['road_wide_ratio'] = (out['road_len_wide'].to_numpy(dtype='float32') / denom).astype('float32')\n",
    "#     out['road_narrow_ratio'] = (out['road_len_narrow'].to_numpy(dtype='float32') / denom).astype('float32')\n",
    "\n",
    "#     # 密度（任意）\n",
    "#     # 注意: EPSG:4612 のまま area を取るのはNG（度単位）なので、投影して計算して戻す\n",
    "#     if add_density:\n",
    "#         out_p = out.to_crs(epsg=nn_epsg)\n",
    "#         area_m2 = out_p.geometry.area.to_numpy(dtype='float64')\n",
    "#         area_m2 = np.maximum(area_m2, eps)\n",
    "#         # m / m^2 = 1/m。見やすくするなら m/km^2 = (m / m^2) * 1e6\n",
    "#         out['road_len_density'] = (out['road_len_total'].to_numpy(dtype='float64') / area_m2 * area_unit_scale).astype('float32')\n",
    "\n",
    "#     # ---------\n",
    "#     # 2) gap（周辺メッシュ平均との差）\n",
    "#     # ---------\n",
    "#     # centroid の点で kNN（polygon のままだと不安定/重い）\n",
    "#     gdf_p = out.to_crs(epsg=nn_epsg).copy()\n",
    "#     cent = gdf_p.geometry.centroid\n",
    "#     xy = np.column_stack([cent.x.to_numpy(), cent.y.to_numpy()])\n",
    "\n",
    "#     # scipy が無い環境対策（ただしあなたの環境は概ねOKのはず）\n",
    "#     try:\n",
    "#         from scipy.spatial import cKDTree\n",
    "#     except Exception as e:\n",
    "#         raise ImportError('scipy is required for kNN gap features. Please install scipy.') from e\n",
    "\n",
    "#     tree = cKDTree(xy)\n",
    "\n",
    "#     # k+1 で self を含めて後で落とす\n",
    "#     qk = k + 1 if self_exclude else k\n",
    "#     dists, idxs = tree.query(xy, k=qk, workers=-1)\n",
    "\n",
    "#     # k=1 等で1次元になるケース対策\n",
    "#     if qk == 1:\n",
    "#         dists = dists.reshape(-1, 1)\n",
    "#         idxs = idxs.reshape(-1, 1)\n",
    "\n",
    "#     if self_exclude:\n",
    "#         # 先頭が self（距離0）になる前提\n",
    "#         dists = dists[:, 1:]\n",
    "#         idxs = idxs[:, 1:]\n",
    "\n",
    "#     # IDW 重み\n",
    "#     w = 1.0 / np.power(np.maximum(dists, eps), idw_p)\n",
    "#     w_sum = w.sum(axis=1, keepdims=True)\n",
    "#     valid = (w_sum[:, 0] > 0)\n",
    "\n",
    "#     def _wmean(values: np.ndarray) -> np.ndarray:\n",
    "#         # values: (n,)\n",
    "#         neigh = values[idxs]              # (n, k)\n",
    "#         num = (w * neigh).sum(axis=1)     # (n,)\n",
    "#         out_arr = np.full(len(values), np.nan, dtype='float32')\n",
    "#         out_arr[valid] = (num[valid] / w_sum[valid, 0]).astype('float32')\n",
    "#         return out_arr\n",
    "\n",
    "#     # 近傍加重平均\n",
    "#     v_total = out['road_len_total'].to_numpy(dtype='float32')\n",
    "#     v_narrow_ratio = out['road_narrow_ratio'].to_numpy(dtype='float32')\n",
    "#     wmean_total = _wmean(v_total)\n",
    "#     wmean_narrow_ratio = _wmean(v_narrow_ratio)\n",
    "\n",
    "#     # gap = self - wmean(neighbors)\n",
    "#     out['road_len_total_gap'] = (v_total - wmean_total).astype('float32')\n",
    "#     out['road_narrow_ratio_gap'] = (v_narrow_ratio - wmean_narrow_ratio).astype('float32')\n",
    "\n",
    "#     # 任意: 密度のgapも作りたい場合\n",
    "#     if add_density:\n",
    "#         v_density = out['road_len_density'].to_numpy(dtype='float32')\n",
    "#         wmean_density = _wmean(v_density)\n",
    "#         out['road_len_density_gap'] = (v_density - wmean_density).astype('float32')\n",
    "\n",
    "#     keep_cols = [\n",
    "#         'geometry',\n",
    "#         'road_len_total',\n",
    "#         'road_len_wide',\n",
    "#         'road_len_narrow',\n",
    "#         'road_wide_ratio',\n",
    "#         'road_narrow_ratio',\n",
    "#         'road_len_total_gap',\n",
    "#         'road_narrow_ratio_gap',\n",
    "#     ]\n",
    "#     if add_density:\n",
    "#         keep_cols += ['road_len_density', 'road_len_density_gap']\n",
    "\n",
    "#     return out[keep_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d08d16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# road_df = build_road_base_and_gap_features(road_df)\n",
    "# road_df.to_parquet(output_path + '/road_mesh_fe.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d9003",
   "metadata": {},
   "source": [
    "#### 学習データ・予測データに結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "68f19649",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_df = gpd.read_parquet(road_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e789c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_road_features_sjoin(\n",
    "    df: pd.DataFrame,\n",
    "    road_poly: gpd.GeoDataFrame,\n",
    "    lon_col: str = 'lon_jgd',\n",
    "    lat_col: str = 'lat_jgd',\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # df を point 化（EPSG:4612）\n",
    "    gdf_pts = gpd.GeoDataFrame(\n",
    "        out,\n",
    "        geometry=gpd.points_from_xy(out[lon_col], out[lat_col]),\n",
    "        crs='EPSG:4612',\n",
    "    )\n",
    "\n",
    "    # road_poly も EPSG:4612 に揃える（重要）\n",
    "    road_poly_4612 = road_poly.to_crs('EPSG:4612')\n",
    "\n",
    "    # sjoin: point がどの polygon に入るか\n",
    "    joined = gpd.sjoin(\n",
    "        gdf_pts[['geometry']],\n",
    "        road_poly_4612,\n",
    "        how='left',\n",
    "        predicate='within',\n",
    "    )\n",
    "\n",
    "    out = out.join(joined)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8aee96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_geo = add_road_features_sjoin(train_df_geo, road_df)\n",
    "test_df_geo = add_road_features_sjoin(test_df_geo, road_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d630c",
   "metadata": {},
   "source": [
    "## 駅乗降者数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88ee11",
   "metadata": {},
   "source": [
    "## 特徴量の追加・削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4c5acac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target_ym', 'building_id', 'unit_id', 'lat', 'lon', 'target_year',\n",
       "       'lon_jgd', 'lat_jgd', 'nearest_land_price', 'distance_to_landpoint_m',\n",
       "       'log_land_price', 'weighted_land_price_3', 'log_weighted_land_price_3',\n",
       "       'nearest_land_price_prev', 'weighted_land_price_3_prev',\n",
       "       'land_price_yoy_nearest', 'land_price_yoy_w3',\n",
       "       'land_price_dlog_nearest', 'land_price_dlog_w3', 'pop_dist_nn_m',\n",
       "       'PTN_2020_nn', 'PTN_2020_idw3', 'RTA_2025_nn', 'RTA_2025_idw3',\n",
       "       'RTB_2025_nn', 'RTB_2025_idw3', 'RTC_2025_nn', 'RTC_2025_idw3',\n",
       "       'RTD_2025_nn', 'RTD_2025_idw3', 'RTE_2025_nn', 'RTE_2025_idw3',\n",
       "       'pop_trend_rate_nn', 'pop_trend_rate_idw3', 'geometry', 'index_right',\n",
       "       'road_len_total', 'road_len_wide', 'road_len_narrow', 'road_wide_ratio',\n",
       "       'road_narrow_ratio', 'road_len_total_gap', 'road_narrow_ratio_gap',\n",
       "       'road_len_density', 'road_len_density_gap'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_geo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "329e9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cols = [\n",
    "    'nearest_land_price', 'weighted_land_price_3', 'distance_to_landpoint_m', 'log_land_price', 'log_weighted_land_price_3',\n",
    "    'land_price_yoy_nearest', 'land_price_yoy_w3', 'land_price_dlog_nearest', 'land_price_dlog_w3',\n",
    "    'PTN_2020_nn', 'PTN_2020_idw3', 'RTA_2025_nn', 'RTA_2025_idw3',\n",
    "    'RTB_2025_nn', 'RTB_2025_idw3', 'RTC_2025_nn', 'RTC_2025_idw3',\n",
    "    'RTD_2025_nn', 'RTD_2025_idw3', 'RTE_2025_nn', 'RTE_2025_idw3',\n",
    "    'pop_trend_rate_nn', 'pop_trend_rate_idw3',\n",
    "    'road_len_total', 'road_len_wide', 'road_len_narrow',\n",
    "    'road_wide_ratio', 'road_narrow_ratio',\n",
    "    'road_len_total_gap', 'road_narrow_ratio_gap',\n",
    "    'road_len_density', 'road_len_density_gap'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7a29b",
   "metadata": {},
   "source": [
    "## 出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c83b8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_geo[pkey_cols + add_cols].to_parquet(f'{intermediate_path}train_df_geo_v{geo_ver}.parquet')\n",
    "test_df_geo[pkey_cols + add_cols].to_parquet(f'{intermediate_path}test_df_geo_v{geo_ver}.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
