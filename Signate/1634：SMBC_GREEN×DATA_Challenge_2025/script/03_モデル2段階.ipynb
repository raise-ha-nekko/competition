{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea1283ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'packaging.requirements'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjapanize_matplotlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesDataSet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_forecasting/__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mPyTorch Forecasting package for timeseries forecasting with PyTorch.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m1.4.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     EncoderNormalizer,\n\u001b[32m      9\u001b[39m     GroupNormalizer,\n\u001b[32m     10\u001b[39m     MultiNormalizer,\n\u001b[32m     11\u001b[39m     NaNLabelEncoder,\n\u001b[32m     12\u001b[39m     TimeSeriesDataSet,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     MAE,\n\u001b[32m     16\u001b[39m     MAPE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     QuantileLoss,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     35\u001b[39m     GRU,\n\u001b[32m     36\u001b[39m     LSTM,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     get_rnn,\n\u001b[32m     51\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_forecasting/data/__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mDatasets, etc. for timeseries data.\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[33;03mHandling timeseries data is not trivial. It requires special treatment.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mThis sub-package provides the necessary tools to abstracts the necessary work.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mencoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     EncoderNormalizer,\n\u001b[32m     10\u001b[39m     GroupNormalizer,\n\u001b[32m     11\u001b[39m     MultiNormalizer,\n\u001b[32m     12\u001b[39m     NaNLabelEncoder,\n\u001b[32m     13\u001b[39m     TorchNormalizer,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msamplers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSynchronizedBatchSampler\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries, TimeSeriesDataSet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_forecasting/data/encoders.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rnn\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InitialParameterRepresenterMixIn\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_plus_one\u001b[39m(x):\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_forecasting/utils/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mPyTorch Forecasting package for timeseries forecasting with PyTorch.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     InitialParameterRepresenterMixIn,\n\u001b[32m      7\u001b[39m     OutputMixIn,\n\u001b[32m      8\u001b[39m     TupleOutputMixIn,\n\u001b[32m      9\u001b[39m     apply_to_list,\n\u001b[32m     10\u001b[39m     autocorrelation,\n\u001b[32m     11\u001b[39m     concat_sequences,\n\u001b[32m     12\u001b[39m     create_mask,\n\u001b[32m     13\u001b[39m     detach,\n\u001b[32m     14\u001b[39m     get_embedding_size,\n\u001b[32m     15\u001b[39m     groupby_apply,\n\u001b[32m     16\u001b[39m     integer_histogram,\n\u001b[32m     17\u001b[39m     masked_op,\n\u001b[32m     18\u001b[39m     move_to_device,\n\u001b[32m     19\u001b[39m     padded_stack,\n\u001b[32m     20\u001b[39m     profile,\n\u001b[32m     21\u001b[39m     redirect_stdout,\n\u001b[32m     22\u001b[39m     repr_class,\n\u001b[32m     23\u001b[39m     to_list,\n\u001b[32m     24\u001b[39m     unpack_sequence,\n\u001b[32m     25\u001b[39m     unsqueeze_like,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m __all__ = [\n\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mInitialParameterRepresenterMixIn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOutputMixIn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munsqueeze_like\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_forecasting/utils/_utils.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Union\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightning/__init__.py:18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__about__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: E402, F403\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__version__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Fabric  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m seed_everything  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightning/fabric/__init__.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m package_available\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.isfile(os.path.join(os.path.dirname(\u001b[34m__file__\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33m__about__.py\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__about__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightning_utilities/__init__.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__about__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply_func\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_to_collection\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrEnum\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compare_version, module_available\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightning_utilities/core/__init__.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply_func\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_to_collection\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrEnum\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compare_version, module_available\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_overridden\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_utilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrank_zero\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WarningCache\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightning_utilities/core/imports.py:16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, TypeVar\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequirements\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Requirement\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InvalidVersion, Version\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParamSpec\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'packaging.requirements'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import shap\n",
    "from pdpbox import pdp\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90382c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/iwasakitakahiro/github')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import common\n",
    "\n",
    "# モジュールの再読み込み\n",
    "importlib.reload(common)\n",
    "\n",
    "_common = common.Common()\n",
    "_common.BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a682e90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'func' from '/Users/iwasakitakahiro/github/共通関数/func.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_func_path = _common.COMMON_FUNC_PATH\n",
    "sys.path.append(str(common_func_path))\n",
    "\n",
    "import func\n",
    "\n",
    "importlib.reload(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6088f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../output/中間データ/学習用データ/train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "001bb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[_common.UNIQUE_KEY_COLS] = pd.to_datetime(train_df[_common.UNIQUE_KEY_COLS])\n",
    "train_df = train_df.sort_values(_common.UNIQUE_KEY_COLS).set_index(_common.UNIQUE_KEY_COLS)\n",
    "\n",
    "price_series = train_df[_common.TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d400b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STL分解（1ヶ月周期＝24時間×30日）\n",
    "stl_result = STL(price_series, period=24*30).fit()\n",
    "train_df['trend'] = stl_result.trend\n",
    "train_df['seasonal'] = stl_result.seasonal\n",
    "train_df['residual'] = stl_result.resid\n",
    "train_df['trend_seasonal'] = train_df['trend'] + train_df['seasonal']\n",
    "\n",
    "# モデル1用に1日 or 1ヶ月単位で集約（例：月平均）\n",
    "df_model1 = train_df.resample('M').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f952cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_month = 24 * 30\n",
    "window_day = 24\n",
    "\n",
    "# price_actual列を基準に平均\n",
    "train_df['monthly_avg'] = train_df['price_actual'].rolling(window=window_month, min_periods=1).mean()\n",
    "train_df['daily_avg'] = train_df['price_actual'].rolling(window=window_day, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f95f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 最適なα（月次の重み）: 0.5700\n",
      "✅ 最小RMSE: 7.4472\n"
     ]
    }
   ],
   "source": [
    "# --- STL分解後の目的変数を作成 ---\n",
    "# trend + seasonal を教師データとする\n",
    "y_true = train_df['trend'] + train_df['seasonal']\n",
    "\n",
    "# --- monthly_avg, daily_avg の定義 ---\n",
    "x_monthly = train_df['monthly_avg']\n",
    "x_daily = train_df['daily_avg']\n",
    "\n",
    "# --- RMSE を返す目的関数を定義 ---\n",
    "def rmse_weight(alpha):\n",
    "    y_pred = alpha * x_monthly + (1 - alpha) * x_daily\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# --- 最適化実行 ---\n",
    "result = minimize_scalar(rmse_weight, bounds=(0, 1), method='bounded')\n",
    "\n",
    "# --- 最適αとRMSE出力 ---\n",
    "best_alpha = result.x\n",
    "best_rmse = result.fun\n",
    "\n",
    "print(f\"✅ 最適なα（月次の重み）: {best_alpha:.4f}\")\n",
    "print(f\"✅ 最小RMSE: {best_rmse:.4f}\")\n",
    "\n",
    "# --- 最適比率で trend_seasonal 列を再計算 ---\n",
    "train_df['trend_seasonal'] = best_alpha * x_monthly + (1 - best_alpha) * x_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27dece9",
   "metadata": {},
   "source": [
    "## モデル1（前日12時までの情報で暫定価格を予測）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb0e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1_dataset(df, is_test=False):\n",
    "    df = df.copy()\n",
    "    df[_common.UNIQUE_KEY_COLS] = pd.to_datetime(df[_common.UNIQUE_KEY_COLS])\n",
    "    records = []\n",
    "\n",
    "    for day in pd.date_range(df[_common.UNIQUE_KEY_COLS].min() + pd.Timedelta(days=2),\n",
    "                              df[_common.UNIQUE_KEY_COLS].max() - pd.Timedelta(days=0), freq='D'):\n",
    "        day_start = day.replace(hour=0)\n",
    "        day_end = day.replace(hour=23)\n",
    "        day_times = pd.date_range(day_start, day_end, freq='h')\n",
    "\n",
    "        feature_end = day - pd.Timedelta(hours=12)\n",
    "        feature_start = feature_end - pd.Timedelta(hours=23)\n",
    "        feature_times = pd.date_range(feature_start, feature_end, freq='h')\n",
    "\n",
    "        x = df[df[_common.UNIQUE_KEY_COLS].isin(feature_times)].copy()\n",
    "        y = df[df[_common.UNIQUE_KEY_COLS].isin(day_times)].copy() if not is_test else None\n",
    "\n",
    "        if len(x) == 24 and (is_test or len(y) == 24):\n",
    "            # target_col がない場合は drop から除外する\n",
    "            drop_cols = [_common.UNIQUE_KEY_COLS]\n",
    "            if not is_test:\n",
    "                drop_cols.append(_common.TARGET_COL)\n",
    "            x_agg = x.drop(columns=drop_cols).mean().to_dict()\n",
    "\n",
    "            x_agg['day'] = day.date()\n",
    "            for i, t in enumerate(day_times):\n",
    "                row = x_agg.copy()\n",
    "                row['forecast_hour'] = t.hour\n",
    "                row['target_time'] = t\n",
    "                if not is_test:\n",
    "                    row['target_price'] = y.loc[y[_common.UNIQUE_KEY_COLS] == t, _common.TARGET_COL].values[0]\n",
    "                records.append(row)\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7bc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model1 = build_model1_dataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ba38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量と目的変数\n",
    "features_model1 = [col for col in df_model1.columns if col not in ['day', 'forecast_hour', 'target_time', 'target_price']]\n",
    "X_model1 = df_model1[features_model1]\n",
    "y_model1 = df_model1['target_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04abe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現性確保のための固定シード\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Optunaのシードも固定\n",
    "sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "\n",
    "# LightGBMにも同様に\n",
    "default_params = {\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': SEED,\n",
    "    'verbosity': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b86f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ed1d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:13,932] A new study created in memory with name: no-name-c085d89c-cd24-4296-bbc3-0c8cd1592af8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's rmse: 11.5119\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's rmse: 20.4456\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's rmse: 10.479\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's rmse: 13.9024\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:21,507] Trial 0 finished with value: 13.066626105638274 and parameters: {'learning_rate': 0.015542448978618607, 'num_leaves': 74, 'feature_fraction': 0.8875455478014229, 'bagging_fraction': 0.9570717167427538, 'bagging_freq': 8}. Best is trial 0 with value: 13.066626105638274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's rmse: 8.99424\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's rmse: 11.5933\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's rmse: 20.5939\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's rmse: 10.326\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's rmse: 14.0885\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:26,702] Trial 1 finished with value: 13.09622846741662 and parameters: {'learning_rate': 0.01873236473539007, 'num_leaves': 50, 'feature_fraction': 0.9603744355070039, 'bagging_fraction': 0.991627870736741, 'bagging_freq': 9}. Best is trial 0 with value: 13.066626105638274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's rmse: 8.87951\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's rmse: 11.5391\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's rmse: 20.6808\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's rmse: 10.3671\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 13.9595\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:32,182] Trial 2 finished with value: 13.115393003341321 and parameters: {'learning_rate': 0.02279382816537334, 'num_leaves': 66, 'feature_fraction': 0.9366925870344273, 'bagging_fraction': 0.94254040539658, 'bagging_freq': 4}. Best is trial 0 with value: 13.066626105638274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's rmse: 9.03051\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's rmse: 11.3495\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's rmse: 20.3171\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's rmse: 10.4829\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 13.885\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:36,858] Trial 3 finished with value: 13.01213319363288 and parameters: {'learning_rate': 0.036407946646282316, 'num_leaves': 66, 'feature_fraction': 0.8027536899181364, 'bagging_fraction': 0.9545653243224748, 'bagging_freq': 9}. Best is trial 3 with value: 13.01213319363288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's rmse: 9.02624\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's rmse: 11.3617\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's rmse: 20.5343\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's rmse: 10.5524\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's rmse: 13.8497\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:43,920] Trial 4 finished with value: 13.060202455702642 and parameters: {'learning_rate': 0.02316786340105235, 'num_leaves': 74, 'feature_fraction': 0.8150762483285954, 'bagging_fraction': 0.8737648012003949, 'bagging_freq': 10}. Best is trial 3 with value: 13.01213319363288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's rmse: 9.00286\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's rmse: 11.3725\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's rmse: 20.795\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's rmse: 10.4109\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's rmse: 13.9408\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:47,201] Trial 5 finished with value: 13.085224720266075 and parameters: {'learning_rate': 0.04481033010266881, 'num_leaves': 58, 'feature_fraction': 0.9577460285881492, 'bagging_fraction': 0.8633672244337742, 'bagging_freq': 6}. Best is trial 3 with value: 13.01213319363288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's rmse: 8.90692\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's rmse: 11.4039\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's rmse: 20.3133\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's rmse: 10.2007\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's rmse: 14.0338\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:50,067] Trial 6 finished with value: 12.995771466416079 and parameters: {'learning_rate': 0.07398222518217204, 'num_leaves': 61, 'feature_fraction': 0.9604295284160318, 'bagging_fraction': 0.828753364902913, 'bagging_freq': 8}. Best is trial 6 with value: 12.995771466416079.\n",
      "[I 2025-06-12 09:20:50,108] Trial 7 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-06-12 09:20:50,123] Trial 8 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's rmse: 9.02717\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 11.4237\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's rmse: 20.6674\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's rmse: 10.0995\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's rmse: 13.7435\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:52,384] Trial 9 finished with value: 12.959418669980156 and parameters: {'learning_rate': 0.034143667068185966, 'num_leaves': 34, 'feature_fraction': 0.9122866160126796, 'bagging_fraction': 0.865933689124183, 'bagging_freq': 6}. Best is trial 9 with value: 12.959418669980156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's rmse: 8.86294\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 11.4214\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's rmse: 20.6106\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's rmse: 10.3469\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 13.679\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:53,714] Trial 10 finished with value: 12.980715917285744 and parameters: {'learning_rate': 0.08314237192881471, 'num_leaves': 31, 'feature_fraction': 0.8818402735782713, 'bagging_fraction': 0.806695940147704, 'bagging_freq': 1}. Best is trial 9 with value: 12.959418669980156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's rmse: 8.84557\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's rmse: 11.4662\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's rmse: 20.6238\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's rmse: 10.3346\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's rmse: 13.6744\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:54,979] Trial 11 finished with value: 13.007579080402948 and parameters: {'learning_rate': 0.0938940405042952, 'num_leaves': 32, 'feature_fraction': 0.8836182576675167, 'bagging_fraction': 0.809312130090698, 'bagging_freq': 1}. Best is trial 9 with value: 12.959418669980156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's rmse: 8.93898\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's rmse: 11.3983\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's rmse: 20.4654\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 10.707\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 13.7174\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:20:58,611] Trial 12 finished with value: 13.05068960036501 and parameters: {'learning_rate': 0.06346216122533317, 'num_leaves': 95, 'feature_fraction': 0.8499069209571629, 'bagging_fraction': 0.8351205624045043, 'bagging_freq': 1}. Best is trial 9 with value: 12.959418669980156.\n",
      "[I 2025-06-12 09:20:58,632] Trial 13 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 8.96526\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 11.4248\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's rmse: 20.3123\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's rmse: 10.491\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's rmse: 13.5263\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:00,217] Trial 14 finished with value: 12.956739716814784 and parameters: {'learning_rate': 0.09848298104468174, 'num_leaves': 38, 'feature_fraction': 0.8569576978946065, 'bagging_fraction': 0.8393830350982093, 'bagging_freq': 3}. Best is trial 14 with value: 12.956739716814784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's rmse: 9.02935\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's rmse: 11.3248\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's rmse: 20.5497\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's rmse: 10.3767\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 13.818\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:02,474] Trial 15 finished with value: 12.966008767862022 and parameters: {'learning_rate': 0.055158473476608155, 'num_leaves': 41, 'feature_fraction': 0.854810890530028, 'bagging_fraction': 0.8474893770334594, 'bagging_freq': 3}. Best is trial 14 with value: 12.956739716814784.\n",
      "[I 2025-06-12 09:21:02,497] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:02,536] Trial 17 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-06-12 09:21:02,558] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:02,600] Trial 19 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-06-12 09:21:02,622] Trial 20 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's rmse: 8.76072\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 11.2997\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's rmse: 20.5493\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's rmse: 10.365\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 13.7515\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:05,028] Trial 21 finished with value: 12.955722912875505 and parameters: {'learning_rate': 0.05977839766920579, 'num_leaves': 44, 'feature_fraction': 0.8521842705483471, 'bagging_fraction': 0.8484816844633801, 'bagging_freq': 3}. Best is trial 21 with value: 12.955722912875505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's rmse: 8.81311\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 11.3571\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's rmse: 20.564\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's rmse: 10.561\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's rmse: 13.5619\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:07,875] Trial 22 finished with value: 12.974779462837024 and parameters: {'learning_rate': 0.06970026424720498, 'num_leaves': 49, 'feature_fraction': 0.8322207738227406, 'bagging_fraction': 0.8426074837816652, 'bagging_freq': 2}. Best is trial 21 with value: 12.955722912875505.\n",
      "[I 2025-06-12 09:21:07,902] Trial 23 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-06-12 09:21:07,932] Trial 24 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's rmse: 8.82987\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's rmse: 11.321\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's rmse: 20.5164\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's rmse: 10.2159\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 13.6971\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:09,888] Trial 25 finished with value: 12.927258458610376 and parameters: {'learning_rate': 0.07303989435698531, 'num_leaves': 44, 'feature_fraction': 0.8948499975545757, 'bagging_fraction': 0.8506858808589413, 'bagging_freq': 5}. Best is trial 25 with value: 12.927258458610376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's rmse: 8.88594\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's rmse: 11.4166\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's rmse: 20.9599\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's rmse: 10.5178\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's rmse: 13.5962\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:11,803] Trial 26 finished with value: 13.060032251624605 and parameters: {'learning_rate': 0.07980750283959928, 'num_leaves': 46, 'feature_fraction': 0.8325319562181925, 'bagging_fraction': 0.8197179233062364, 'bagging_freq': 2}. Best is trial 25 with value: 12.927258458610376.\n",
      "[I 2025-06-12 09:21:11,857] Trial 27 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-06-12 09:21:11,878] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:11,903] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:11,950] Trial 30 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-06-12 09:21:11,971] Trial 31 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's rmse: 8.80968\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:12,007] Trial 32 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-06-12 09:21:12,030] Trial 33 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:12,051] Trial 34 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:12,085] Trial 35 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-06-12 09:21:12,107] Trial 36 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:12,128] Trial 37 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:12,151] Trial 38 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's rmse: 11.2884\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's rmse: 20.6909\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 10.2664\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's rmse: 13.8983\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:14,470] Trial 39 finished with value: 13.028140772749882 and parameters: {'learning_rate': 0.0727405368146837, 'num_leaves': 43, 'feature_fraction': 0.985051946437993, 'bagging_fraction': 0.8674803261540727, 'bagging_freq': 9}. Best is trial 25 with value: 12.927258458610376.\n",
      "[I 2025-06-12 09:21:14,497] Trial 40 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:14,528] Trial 41 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's rmse: 8.9967\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's rmse: 11.3811\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's rmse: 20.254\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 10.2772\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 13.4826\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:16,038] Trial 42 finished with value: 12.83131877773829 and parameters: {'learning_rate': 0.08657339830018494, 'num_leaves': 36, 'feature_fraction': 0.8830666366692606, 'bagging_fraction': 0.8429387571767321, 'bagging_freq': 2}. Best is trial 42 with value: 12.83131877773829.\n",
      "[I 2025-06-12 09:21:16,060] Trial 43 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-06-12 09:21:16,095] Trial 44 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-06-12 09:21:16,133] Trial 45 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-06-12 09:21:16,166] Trial 46 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-06-12 09:21:16,200] Trial 47 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's rmse: 8.76173\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's rmse: 11.421\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's rmse: 20.2276\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's rmse: 10.0532\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's rmse: 13.5722\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 09:21:18,171] Trial 48 finished with value: 12.82649640460453 and parameters: {'learning_rate': 0.06953540158438691, 'num_leaves': 34, 'feature_fraction': 0.9058326266100843, 'bagging_fraction': 0.8439798053738218, 'bagging_freq': 2}. Best is trial 48 with value: 12.82649640460453.\n",
      "[I 2025-06-12 09:21:18,196] Trial 49 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's rmse: 8.85852\n",
      "Best trial:\n",
      "RMSE: 12.8265\n",
      "Params:\n",
      "learning_rate: 0.06953540158438691\n",
      "num_leaves: 34\n",
      "feature_fraction: 0.9058326266100843\n",
      "bagging_fraction: 0.8439798053738218\n",
      "bagging_freq: 2\n"
     ]
    }
   ],
   "source": [
    "# 最適化の対象関数\n",
    "def objective(trial):\n",
    "    return func.run_optuna(\n",
    "        trial=trial,\n",
    "        features=X_model1,         # 特徴量データフレーム\n",
    "        target=y_model1,           # 目的変数\n",
    "        cv_strategy=tscv,         # ← partition_col → cv_strategy に変更済み\n",
    "        model_name='lgb',\n",
    "        default_columns=default_params,\n",
    "        metric='rmse',\n",
    "        random_seed=SEED\n",
    "    )\n",
    "\n",
    "# Optuna スタディの作成・実行\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    ")\n",
    "study.optimize(objective, n_trials=50, timeout=1800)\n",
    "\n",
    "# 最良トライアルの結果\n",
    "trial = study.best_trial\n",
    "lgb_params1 = default_params | trial.params  # Python 3.9以降\n",
    "\n",
    "# 結果の表示\n",
    "print('Best trial:')\n",
    "print(f'RMSE: {trial.value:.4f}')\n",
    "print('Params:')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3543e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgb_oof_predictions(X, y, lgb_params, n_splits=5, num_boost_round=1000, es=50):\n",
    "    \"\"\"\n",
    "    LightGBMで時系列交差検証を用いたOOF予測を作成\n",
    "    \"\"\"\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    models = []\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "        print(f\"Fold {fold+1}/{n_splits}\")\n",
    "\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dval = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "        model = lgb.train(\n",
    "            lgb_params1,\n",
    "            dtrain,\n",
    "            valid_sets=[dval],\n",
    "            num_boost_round=num_boost_round,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(es),\n",
    "                lgb.log_evaluation(period=0),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        oof_preds[val_idx] = preds\n",
    "        models.append(model)\n",
    "\n",
    "    return oof_preds, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "186b9f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's rmse: 11.421\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's rmse: 20.2276\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's rmse: 10.0532\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's rmse: 13.5722\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's rmse: 8.85852\n"
     ]
    }
   ],
   "source": [
    "# OOF予測\n",
    "oof_preds_model1, model1_folds = get_lgb_oof_predictions(\n",
    "    X_model1, y_model1,\n",
    "    lgb_params=lgb_params1,  # ここにOptunaなどでチューニング済のパラメータを指定\n",
    "    n_splits=5\n",
    ")\n",
    "\n",
    "# df_model1 に予測値を追加\n",
    "df_model1['price_day_ahead_pred'] = oof_preds_model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f670068",
   "metadata": {},
   "source": [
    "#### 全データで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c79e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model1 = X_model1.drop(columns=['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe4095b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBMのトレーニングRMSE: 7.7668\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Dataset の作成\n",
    "lgb_train = lgb.Dataset(X_model1, label=y_model1)\n",
    "\n",
    "callbacks = [\n",
    "    lgb.log_evaluation(period=50)\n",
    "]\n",
    "\n",
    "# モデルの再学習（最終学習）\n",
    "final_model1 = lgb.train(\n",
    "    lgb_params1,\n",
    "    train_set=lgb_train,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# トレーニングデータで予測\n",
    "y_train_pred = final_model1.predict(X_model1)\n",
    "\n",
    "# RMSEを計算\n",
    "final_rmse = np.sqrt(mean_squared_error(y_model1, y_train_pred))\n",
    "\n",
    "print(f\"LightGBMのトレーニングRMSE: {final_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bba8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存用のディクショナリにまとめる\n",
    "model_package1 = {\n",
    "    'model': final_model1,\n",
    "    'feature_name': X_model1.columns.tolist()\n",
    "}\n",
    "\n",
    "# 保存\n",
    "with open('../output/モデル/sep_model1_lgb.pkl', 'wb') as f:\n",
    "    pickle.dump(model_package1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da41dce2",
   "metadata": {},
   "source": [
    "## モデル2(TFT）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting pytorch-forecasting\n",
      "  Downloading pytorch_forecasting-1.4.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting torch>=2.1.0 (from pytorch-lightning)\n",
      "  Downloading torch-2.7.1-cp311-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytorch-lightning) (6.0.2)\n",
      "Collecting fsspec>=2022.5.0 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
      "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/iwasakitakahiro/Library/Python/3.11/lib/python/site-packages (from pytorch-lightning) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/iwasakitakahiro/Library/Python/3.11/lib/python/site-packages (from pytorch-lightning) (4.13.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: numpy<=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytorch-forecasting) (1.26.4)\n",
      "Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n",
      "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytorch-forecasting) (1.15.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytorch-forecasting) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytorch-forecasting) (1.3.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiohttp-3.12.12-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Collecting packaging>=20.0 (from pytorch-lightning)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (65.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/iwasakitakahiro/Library/Python/3.11/lib/python/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.6.0)\n",
      "Collecting filelock (from torch>=2.1.0->pytorch-lightning)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.1.0->pytorch-lightning)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.1.0->pytorch-lightning)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading multidict-6.4.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/iwasakitakahiro/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
      "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_forecasting-1.4.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading torch-2.7.1-cp311-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.12-cp311-cp311-macosx_11_0_arm64.whl (469 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.9/469.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-macosx_11_0_arm64.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading multidict-6.4.4-cp311-cp311-macosx_11_0_arm64.whl (37 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-macosx_11_0_arm64.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.1-cp311-cp311-macosx_11_0_arm64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.8/89.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, propcache, packaging, networkx, multidict, fsspec, frozenlist, filelock, aiohappyeyeballs, yarl, torch, lightning-utilities, aiosignal, torchmetrics, aiohttp, pytorch-lightning, lightning, pytorch-forecasting\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.12 aiosignal-1.3.2 filelock-3.18.0 frozenlist-1.7.0 fsspec-2025.5.1 lightning-2.5.1.post0 lightning-utilities-0.14.3 mpmath-1.3.0 multidict-6.4.4 networkx-3.5 packaging-24.2 propcache-0.3.2 pytorch-forecasting-1.4.0 pytorch-lightning-2.5.1.post0 sympy-1.14.0 torch-2.7.1 torchmetrics-1.7.3 yarl-1.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "def make_tft_dataframe(X_list, y_array, model1_pred_df, time_col='time', max_seq_len=36):\n",
    "    \"\"\"\n",
    "    X_list: 各サンプルが [seq_len × features] の list\n",
    "    y_array: 各サンプルに対する target（=target_price）\n",
    "    model1_pred_df: 各サンプルの予測仮価格が入ったDataFrame（time, price_day_ahead_pred あり）\n",
    "    \"\"\"\n",
    "\n",
    "    rows = []\n",
    "    for i, (x_seq, y, meta_row) in enumerate(zip(X_list, y_array, model1_pred_df.itertuples())):\n",
    "        time_base = pd.to_datetime(meta_row.time)\n",
    "        for j in range(x_seq.shape[0]):\n",
    "            time_step = time_base - pd.Timedelta(hours=max_seq_len - j)\n",
    "            row = {\n",
    "                'time_idx': j,  # 時間軸\n",
    "                'group_id': i,  # 系列ごとのID\n",
    "                'actual_price': y,  # 目的変数\n",
    "                'price_day_ahead_pred': meta_row.price_day_ahead_pred,\n",
    "                'time': time_step,\n",
    "            }\n",
    "            # 特徴量列追加\n",
    "            for k in range(x_seq.shape[1]):\n",
    "                row[f'feature_{k}'] = x_seq[j, k]\n",
    "            rows.append(row)\n",
    "\n",
    "    df_tft = pd.DataFrame(rows)\n",
    "    return df_tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "def create_tft_dataset(df_tft, max_seq_len=36):\n",
    "    \"\"\"\n",
    "    df_tft: long形式のDataFrame\n",
    "    \"\"\"\n",
    "    dataset = TimeSeriesDataSet(\n",
    "        df_tft,\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"actual_price\",\n",
    "        group_ids=[\"group_id\"],\n",
    "        max_encoder_length=max_seq_len,\n",
    "        max_prediction_length=1,\n",
    "        static_categoricals=[],\n",
    "        static_reals=[],\n",
    "        time_varying_known_reals=[\"time_idx\", \"price_day_ahead_pred\"],\n",
    "        time_varying_unknown_reals=[c for c in df_tft.columns if c.startswith(\"feature_\")],\n",
    "    )\n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
