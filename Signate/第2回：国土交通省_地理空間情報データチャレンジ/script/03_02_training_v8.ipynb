{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4569e3",
   "metadata": {},
   "source": [
    "# モデル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7375f2",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b518e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29fd42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '../input/'\n",
    "data_definition_path = ROOT_DIR + 'data_definition.xlsx'\n",
    "intermediate_path = '../output/intermediate_file/'\n",
    "model_path = '../output/model/'\n",
    "oof_path = '../output/oof/'\n",
    "fi_path = '../output/fi/'\n",
    "\n",
    "# スクリプトのバージョン指定\n",
    "create_tbl_ver = 2\n",
    "training_ver = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cafd1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_types = [\n",
    "    'residential',\n",
    "    # 'house',\n",
    "    # 'other'\n",
    "]\n",
    "\n",
    "alg = 'lgb'     # ※この notebook の light 版は lgb 前提（cat は別途実装が必要）\n",
    "# alg = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e46b0e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = 'target_ym'\n",
    "target_col = 'money_room'\n",
    "year_col = 'target_year'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a45479",
   "metadata": {},
   "source": [
    "## データ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5877f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 東京23区 ---\n",
    "TOKYO_23 = [\n",
    "    '千代田区', '中央区', '港区', '新宿区', '文京区', '台東区',\n",
    "    '墨田区', '江東区', '品川区', '目黒区', '大田区', '世田谷区',\n",
    "    '渋谷区', '中野区', '杉並区', '豊島区', '北区', '荒川区',\n",
    "    '板橋区', '練馬区', '足立区', '葛飾区', '江戸川区'\n",
    "]\n",
    "\n",
    "# --- 政令指定都市 ---\n",
    "SEIREI_CITIES = [\n",
    "    '札幌市', '仙台市', 'さいたま市', '千葉市', '横浜市', '川崎市', '相模原市',\n",
    "    '新潟市', '静岡市', '浜松市', '名古屋市',\n",
    "    '京都市', '大阪市', '堺市', '神戸市',\n",
    "    '岡山市', '広島市', '北九州市', '福岡市', '熊本市'\n",
    "]\n",
    "\n",
    "# --- 首都圏（都道府県） ---\n",
    "CAPITAL_PREFS = ['東京都', '神奈川県', '埼玉県', '千葉県']\n",
    "\n",
    "# --- 県庁所在地（市名のみ） ---\n",
    "PREF_CAPITALS = [\n",
    "    '札幌市','青森市','盛岡市','仙台市','秋田市','山形市','福島市',\n",
    "    '水戸市','宇都宮市','前橋市','さいたま市','千葉市','新宿区',\n",
    "    '横浜市','新潟市','富山市','金沢市','福井市','甲府市','長野市',\n",
    "    '岐阜市','静岡市','名古屋市','津市','大津市','京都市','大阪市',\n",
    "    '神戸市','奈良市','和歌山市','鳥取市','松江市','岡山市','広島市',\n",
    "    '山口市','徳島市','高松市','松山市','高知市','福岡市','佐賀市',\n",
    "    '長崎市','熊本市','大分市','宮崎市','鹿児島市','那覇市'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1401e",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f712a4",
   "metadata": {},
   "source": [
    "#### 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dde1c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5fd317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_inputs(\n",
    "    target_model: str,\n",
    "    alg: str,\n",
    "):\n",
    "    # 1) load\n",
    "    train_df = pd.read_parquet(f'{intermediate_path}train_df_{target_model}_v{create_tbl_ver}.parquet')\n",
    "    train_df = normalize_columns(train_df)\n",
    "\n",
    "    # 2) feature cols\n",
    "    fe_cols = train_df.columns.to_list()\n",
    "\n",
    "    idx_key_cols = [\n",
    "        'Prefecture_name',\n",
    "        'City/town/village_name',\n",
    "        'zone_residential_rank',\n",
    "    ]\n",
    "    drop_cols = set([target_col] + idx_key_cols)\n",
    "    fe_cols = [c for c in fe_cols if c not in drop_cols]\n",
    "\n",
    "    # 3) cat cols（lgb でもカテゴリとして使う）\n",
    "    cat_cols_candidate = [\n",
    "        'building_category', 'land_area_kind', 'walk_distance_bin', 'building_land_chimoku',\n",
    "        'land_chisei', 'land_road_cond', 'access_zone', 'fireproof_x_structure', 'structure_group'\n",
    "    ]\n",
    "    cat_cols = [c for c in cat_cols_candidate if c in fe_cols]\n",
    "\n",
    "    obj_cols = train_df[fe_cols].select_dtypes(['object']).columns.tolist()\n",
    "    cat_cols = list(dict.fromkeys(cat_cols + obj_cols))\n",
    "\n",
    "    if alg == 'lgb':\n",
    "        cat_cols_use = [c for c in cat_cols if c in train_df.columns]\n",
    "    else:\n",
    "        cat_cols_use = cat_cols\n",
    "\n",
    "    # 4) idx_dict\n",
    "    if target_model == 'house':\n",
    "        idx_low_density = train_df.index[\n",
    "            train_df['zone_residential_rank'] == 1\n",
    "        ]\n",
    "\n",
    "        idx_mid_density = train_df.index[\n",
    "            train_df['zone_residential_rank'] == 2\n",
    "        ]\n",
    "\n",
    "        idx_high_density = train_df.index[\n",
    "            train_df['zone_residential_rank'].isin([3, 4, 0]) |\n",
    "            train_df['zone_residential_rank'].isna()\n",
    "        ]\n",
    "\n",
    "        density_idx_dict = {\n",
    "            'low': idx_low_density,\n",
    "            'mid': idx_mid_density,\n",
    "            'high': idx_high_density,\n",
    "        }\n",
    "        idx_dict = density_idx_dict\n",
    "    elif target_model == 'residential':\n",
    "        # residential 用の urban_idx_dict は train_df から作る（他propertyに依存させない）\n",
    "        main_city = train_df.index[\n",
    "            (\n",
    "                (train_df['Prefecture_name'] == '東京都') &\n",
    "                (train_df['City/town/village_name'].isin(TOKYO_23))\n",
    "            )\n",
    "            |\n",
    "            (train_df['City/town/village_name'].isin(['大阪市', '名古屋市']))\n",
    "        ]\n",
    "\n",
    "        mid_city = train_df.index[\n",
    "            (\n",
    "                # 首都圏（23区除外）\n",
    "                (\n",
    "                    train_df['Prefecture_name'].isin(CAPITAL_PREFS)\n",
    "                    &\n",
    "                    ~(\n",
    "                        (train_df['Prefecture_name'] == '東京都') &\n",
    "                        (train_df['City/town/village_name'].isin(TOKYO_23))\n",
    "                    )\n",
    "                )\n",
    "                |\n",
    "                # 政令指定都市\n",
    "                (train_df['City/town/village_name'].isin(SEIREI_CITIES))\n",
    "                |\n",
    "                # 県庁所在地\n",
    "                (train_df['City/town/village_name'].isin(PREF_CAPITALS))\n",
    "            )\n",
    "            &\n",
    "            ~train_df.index.isin(main_city)\n",
    "        ]\n",
    "\n",
    "        other = train_df.index[\n",
    "            ~train_df.index.isin(main_city) &\n",
    "            ~train_df.index.isin(mid_city)\n",
    "        ]\n",
    "\n",
    "        idx_dict = {\n",
    "            'main_city': main_city,\n",
    "            'mid_city': mid_city,\n",
    "            'other': other,\n",
    "        }\n",
    "    else:\n",
    "        idx_dict = None\n",
    "\n",
    "    return train_df, fe_cols, cat_cols_use, idx_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964aa3c3",
   "metadata": {},
   "source": [
    "#### パラメータチューニングの探索範囲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbe0c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PARAMS_BY_MODEL = {\n",
    "  'lgb': {\n",
    "    'objective': 'regression',\n",
    "    'n_estimators': 20000,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.8,\n",
    "    'subsample_freq': 1,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.0,\n",
    "    'reg_lambda': 3.0,\n",
    "    'min_child_samples': 50,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': -1\n",
    "  },\n",
    "  'cat': {\n",
    "    'loss_function': 'MAE',\n",
    "    'eval_metric': 'MAE',\n",
    "    'iterations': 20000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 8,\n",
    "    'l2_leaf_reg': 6.0,\n",
    "    'random_strength': 1.0,\n",
    "    'bagging_temperature': 0.5,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d18b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_2STAGE_CONF = {\n",
    "    'residential': {\n",
    "        'phase1': dict(\n",
    "            num_leaves=(31, 127),\n",
    "            max_depth=(4, 10),\n",
    "            min_child_samples=(50, 200),\n",
    "            learning_rate=(0.03, 0.12),\n",
    "            subsample=(0.65, 0.95),\n",
    "            colsample_bytree=(0.65, 0.95),\n",
    "            reg_alpha=(0.0, 1.0),\n",
    "            reg_lambda=(1.0, 20.0),\n",
    "        ),\n",
    "        'phase2': dict(\n",
    "            num_leaves_width=32,\n",
    "            max_depth_width=2,\n",
    "            min_child_samples_width=40,\n",
    "            learning_rate_rel=0.5,\n",
    "            subsample_rel=0.15,\n",
    "            colsample_bytree_rel=0.15,\n",
    "            reg_alpha_rel=1.0,\n",
    "            reg_lambda_rel=0.8,\n",
    "        )\n",
    "    },\n",
    "\n",
    "    'house': {\n",
    "        'phase1': dict(\n",
    "            num_leaves=(31, 127),\n",
    "            max_depth=(3, 9),\n",
    "            min_child_samples=(80, 400),\n",
    "            learning_rate=(0.02, 0.10),\n",
    "            subsample=(0.65, 0.95),\n",
    "            colsample_bytree=(0.65, 0.95),\n",
    "            reg_alpha=(0.0, 2.0),\n",
    "            reg_lambda=(2.0, 30.0),\n",
    "        ),\n",
    "        'phase2': dict(\n",
    "            num_leaves_width=32,\n",
    "            max_depth_width=2,\n",
    "            min_child_samples_width=80,\n",
    "            learning_rate_rel=0.6,\n",
    "            subsample_rel=0.18,\n",
    "            colsample_bytree_rel=0.18,\n",
    "            reg_alpha_rel=1.0,\n",
    "            reg_lambda_rel=0.9,\n",
    "        )\n",
    "    },\n",
    "    'other': {\n",
    "        # Phase1: 速度×当たり率（あなたの当初案ベース）\n",
    "        'phase1': dict(\n",
    "            num_leaves=(16, 63),\n",
    "            max_depth=(2, 8),\n",
    "            min_child_samples=(50, 500),\n",
    "            learning_rate=(0.02, 0.10),\n",
    "            subsample=(0.70, 0.95),\n",
    "            colsample_bytree=(0.70, 0.95),\n",
    "            reg_alpha=(0.0, 3.0),          # 一貫性のためPhase1から探索\n",
    "            reg_lambda=(3.0, 25.0),\n",
    "        ),\n",
    "        # Phase2: best近傍だが「緩め」（ハマり回避）\n",
    "        'phase2': dict(\n",
    "            num_leaves_width=24,\n",
    "            max_depth_width=2,\n",
    "            min_child_samples_width=150,   # 広めが重要\n",
    "            learning_rate_rel=0.9,         # かなり広いband（ほぼ再探索に近い）\n",
    "            subsample_rel=0.25,\n",
    "            colsample_bytree_rel=0.25,\n",
    "            reg_alpha_rel=1.3,\n",
    "            reg_lambda_rel=1.0,\n",
    "        )\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "072d441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _space_lgb_phase1(trial, property_type):\n",
    "    c = LGB_2STAGE_CONF[property_type]['phase1']\n",
    "    return {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', *c['num_leaves']),\n",
    "        'max_depth': trial.suggest_int('max_depth', *c['max_depth']),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', *c['min_child_samples']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', *c['learning_rate']),\n",
    "        'subsample': trial.suggest_float('subsample', *c['subsample']),\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', *c['colsample_bytree']),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', *c['reg_alpha']),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', *c['reg_lambda'], log=True),\n",
    "        'max_bin': 255,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b55b23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clamp_int(x, lo, hi):\n",
    "    return int(max(lo, min(hi, int(x))))\n",
    "\n",
    "def _clamp_float(x, lo, hi):\n",
    "    return float(max(lo, min(hi, float(x))))\n",
    "\n",
    "def _band_int(center, width, lo, hi):\n",
    "    return _clamp_int(center - width, lo, hi), _clamp_int(center + width, lo, hi)\n",
    "\n",
    "def _band_float(center, rel, lo, hi):\n",
    "    return _clamp_float(center * (1 - rel), lo, hi), _clamp_float(center * (1 + rel), lo, hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c1f6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _space_lgb_phase2(trial, best_params, property_type):\n",
    "    c1 = LGB_2STAGE_CONF[property_type]['phase1']\n",
    "    c2 = LGB_2STAGE_CONF[property_type]['phase2']\n",
    "\n",
    "    nl_lo, nl_hi = _band_int(best_params['num_leaves'], c2['num_leaves_width'], *c1['num_leaves'])\n",
    "    md_lo, md_hi = _band_int(best_params['max_depth'], c2['max_depth_width'], *c1['max_depth'])\n",
    "    mcs_lo, mcs_hi = _band_int(best_params['min_child_samples'], c2['min_child_samples_width'], *c1['min_child_samples'])\n",
    "\n",
    "    lr_lo, lr_hi = _band_float(best_params['learning_rate'], c2['learning_rate_rel'], *c1['learning_rate'])\n",
    "    ss_lo, ss_hi = _band_float(best_params['subsample'], c2['subsample_rel'], *c1['subsample'])\n",
    "    cs_lo, cs_hi = _band_float(best_params['colsample_bytree'], c2['colsample_bytree_rel'], *c1['colsample_bytree'])\n",
    "\n",
    "    ra_lo, ra_hi = _band_float(best_params.get('reg_alpha', 0.0), c2['reg_alpha_rel'], *c1['reg_alpha'])\n",
    "    rl_lo, rl_hi = _band_float(best_params.get('reg_lambda', 3.0), c2['reg_lambda_rel'], *c1['reg_lambda'])\n",
    "\n",
    "    return {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', nl_lo, nl_hi),\n",
    "        'max_depth': trial.suggest_int('max_depth', md_lo, md_hi),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', mcs_lo, mcs_hi),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', lr_lo, lr_hi),\n",
    "        'subsample': trial.suggest_float('subsample', ss_lo, ss_hi),\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', cs_lo, cs_hi),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', ra_lo, ra_hi),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', rl_lo, rl_hi, log=True),\n",
    "        'max_bin': 255,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b77ee",
   "metadata": {},
   "source": [
    "#### CV実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54c6e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "def mape(y_true, y_pred, eps=1e-9):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77b51fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_take_index(idx: pd.Index, pos: np.ndarray) -> pd.Index:\n",
    "    arr = idx.to_numpy()\n",
    "    return pd.Index(arr[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8cf4726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _force_lgbm_train_categories(X: pd.DataFrame, cat_cols_use: list[str], na_token: str = 'NA') -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    for c in cat_cols_use:\n",
    "        if c not in X.columns:\n",
    "            continue\n",
    "        s = X[c].astype('string').fillna(na_token)\n",
    "        X[c] = s.astype('category')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42e4326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_te_source_col(te_col: str) -> str:\n",
    "    # 'xxx_te' -> 'xxx'\n",
    "    return te_col[:-3] if te_col.endswith('_te') else te_col\n",
    "\n",
    "\n",
    "def fit_target_encoding_map(\n",
    "    s_cat: pd.Series,\n",
    "    y: pd.Series,\n",
    "    smoothing: float = 50.0,\n",
    "    min_samples_leaf: int = 1,\n",
    ") -> tuple[pd.Series, float]:\n",
    "    \"\"\"\n",
    "    1列のカテゴリ s_cat をターゲット y で target encoding するための mapping を作る。\n",
    "    smoothing: 大きいほど全体平均に寄る（過学習防止）\n",
    "    min_samples_leaf: 出現数が小さいカテゴリは prior に寄せる\n",
    "    \"\"\"\n",
    "    s_cat = s_cat.astype('object')\n",
    "    y = y.astype(float)\n",
    "\n",
    "    prior = float(y.mean())\n",
    "\n",
    "    stats = (\n",
    "        pd.DataFrame({'cat': s_cat, 'y': y})\n",
    "        .groupby('cat')['y']\n",
    "        .agg(['mean', 'count'])\n",
    "    )\n",
    "\n",
    "    enc = (stats['mean'] * stats['count'] + prior * smoothing) / (stats['count'] + smoothing)\n",
    "\n",
    "    # min_samples_leaf 未満は prior に寄せる\n",
    "    if min_samples_leaf > 1:\n",
    "        enc = enc.where(stats['count'] >= min_samples_leaf, prior)\n",
    "\n",
    "    # mapping: index=category, value=encoded\n",
    "    mapping = enc.astype(float)\n",
    "    return mapping, prior\n",
    "\n",
    "\n",
    "def apply_target_encoding(\n",
    "    s_cat: pd.Series,\n",
    "    mapping: pd.Series,\n",
    "    prior: float,\n",
    ") -> pd.Series:\n",
    "    s_cat = s_cat.astype('object')\n",
    "    out = s_cat.map(mapping)\n",
    "    return out.fillna(prior).astype(float)\n",
    "\n",
    "\n",
    "def recompute_te_for_fold(\n",
    "    train_df: pd.DataFrame,\n",
    "    tr_idx: pd.Index,\n",
    "    apply_idx_list: list[pd.Index],\n",
    "    te_cols: list[str],\n",
    "    y_tr: pd.Series,  # log(y) を渡す想定\n",
    "    smoothing: float = 50.0,\n",
    "    min_samples_leaf: int = 1,\n",
    "    verbose: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    foldごとにTE列を再計算して train_df の te_cols を（指定idxだけ）上書きする。\n",
    "    重要：元列が存在しないTEはスキップ（元スクリプト互換）。\n",
    "    \"\"\"\n",
    "    te_meta: dict[str, dict] = {}\n",
    "\n",
    "    prior = float(y_tr.loc[tr_idx].mean())  # log空間のprior（元の挙動に合わせる）\n",
    "    for te_col in te_cols:\n",
    "        src_col = _infer_te_source_col(te_col)\n",
    "\n",
    "        # ---- ここが今回の修正点：元列が無いならスキップ ----\n",
    "        if src_col not in train_df.columns:\n",
    "            if verbose:\n",
    "                print(f'[TE] skip: src_col missing: {te_col} -> {src_col}')\n",
    "            continue\n",
    "\n",
    "        # tr_idx 内に src_col が無い/全欠損でも落ちないように\n",
    "        s_tr = train_df.loc[tr_idx, src_col]\n",
    "        if s_tr.isna().all():\n",
    "            if verbose:\n",
    "                print(f'[TE] skip: all NA on train fold: {te_col} -> {src_col}')\n",
    "            continue\n",
    "\n",
    "        mapping, _prior = fit_target_encoding_map(\n",
    "            s_cat=s_tr,\n",
    "            y=y_tr.loc[tr_idx],\n",
    "            smoothing=smoothing,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "        )\n",
    "\n",
    "        # apply\n",
    "        for idx in apply_idx_list:\n",
    "            # apply側に元列が無いことは基本ないが、念のため\n",
    "            if src_col not in train_df.columns:\n",
    "                continue\n",
    "\n",
    "            train_df.loc[idx, te_col] = apply_target_encoding(\n",
    "                train_df.loc[idx, src_col],\n",
    "                mapping,\n",
    "                prior,\n",
    "            ).values\n",
    "\n",
    "        te_meta[te_col] = {'src_col': src_col, 'mapping': mapping, 'prior': prior}\n",
    "\n",
    "    return te_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7f3b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv_by_separate(\n",
    "    train_df: pd.DataFrame,\n",
    "    base_cols: list[str],\n",
    "    cat_cols: list[str],\n",
    "    target_col: str,\n",
    "    year_col: str,\n",
    "    base_params: dict,  # {'lgb':..., 'cat':...}\n",
    "    alg: str,\n",
    "    idx_dict: dict[str, pd.Index] | None = None,\n",
    "    n_splits: int = 5,\n",
    "    te_smoothing: float = 50.0,\n",
    "    te_min_samples_leaf: int = 1,\n",
    "    ho_year: int = 2022,\n",
    "    cv_year_max: int = 2021,\n",
    "    stage_name: str = 'CV',\n",
    "    print_mape: bool = True,\n",
    "):\n",
    "    y = train_df[target_col].astype(float)\n",
    "    y_log = np.log(y)\n",
    "\n",
    "    if idx_dict is None:\n",
    "        idx_dict = {'all': train_df.index}\n",
    "\n",
    "    te_cols_base = [\n",
    "        c for c in base_cols\n",
    "        if c.endswith('_te') and (_infer_te_source_col(c) in train_df.columns)\n",
    "    ]\n",
    "\n",
    "    results: dict[str, dict] = {}\n",
    "\n",
    "    print(f'\\n[{stage_name}] start: alg={alg}, n_splits={n_splits}, n_features={len(base_cols)}, n_te_cols={len(te_cols_base)}')\n",
    "\n",
    "    for split_key, split_idx in idx_dict.items():\n",
    "        idx_cv = split_idx.intersection(train_df.index[train_df[year_col] <= cv_year_max])\n",
    "        idx_ho = split_idx.intersection(train_df.index[train_df[year_col] == ho_year])\n",
    "\n",
    "        if len(idx_cv) == 0:\n",
    "            print(f'[{stage_name}] split={split_key} skip (no CV rows)')\n",
    "            continue\n",
    "\n",
    "        has_ho = len(idx_ho) > 0\n",
    "\n",
    "        print(f'\\n[{stage_name}] split={split_key} | CV={len(idx_cv)} | HO={len(idx_ho)}')\n",
    "\n",
    "        oof_pred_log = pd.Series(np.nan, index=idx_cv, dtype=float)\n",
    "        ho_pred_log_accum = pd.Series(0.0, index=idx_ho, dtype=float) if has_ho else None\n",
    "        fi_list = []\n",
    "\n",
    "        X_cv = train_df.loc[idx_cv, base_cols]\n",
    "        y_cv_log = y_log.loc[idx_cv]\n",
    "        groups_cv = train_df.loc[idx_cv, 'building_id']\n",
    "\n",
    "        gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "        for fold, (tr_pos, va_pos) in enumerate(gkf.split(X_cv, y_cv_log, groups_cv), 1):\n",
    "            tr_idx = _safe_take_index(idx_cv, tr_pos)\n",
    "            va_idx = _safe_take_index(idx_cv, va_pos)\n",
    "\n",
    "            print(f'[{stage_name}] split={split_key} fold={fold}/{n_splits} | tr={len(tr_idx)} va={len(va_idx)}')\n",
    "\n",
    "            # TE 再計算\n",
    "            if te_cols_base:\n",
    "                apply_list = [tr_idx, va_idx]\n",
    "                if has_ho:\n",
    "                    apply_list.append(idx_ho)\n",
    "\n",
    "                recompute_te_for_fold(\n",
    "                    train_df=train_df,\n",
    "                    tr_idx=tr_idx,\n",
    "                    apply_idx_list=apply_list,\n",
    "                    te_cols=te_cols_base,\n",
    "                    y_tr=y_log,\n",
    "                    smoothing=te_smoothing,\n",
    "                    min_samples_leaf=te_min_samples_leaf,\n",
    "                    verbose=False,\n",
    "                )\n",
    "\n",
    "            if alg == 'lgb':\n",
    "                model = lgb.LGBMRegressor(**base_params['lgb'])\n",
    "                X_train = train_df.loc[tr_idx, base_cols].copy()\n",
    "                y_train = y_log.loc[tr_idx].to_numpy()\n",
    "                X_valid = train_df.loc[va_idx, base_cols].copy()\n",
    "                y_valid = y_log.loc[va_idx].to_numpy()\n",
    "                X_ho = train_df.loc[idx_ho, base_cols]\n",
    "\n",
    "                # categorical_feature に渡す列は X に存在するものだけに限定（安全）\n",
    "                cat_cols_use_in_X = [c for c in (cat_cols or []) if c in X_train.columns]\n",
    "\n",
    "                # cat列を category dtype に統一（学習・推論で同じ前処理にする）\n",
    "                if cat_cols_use_in_X:\n",
    "                    X_train = _force_lgbm_train_categories(X_train, cat_cols_use_in_X, na_token='NA')\n",
    "                    X_valid = _force_lgbm_train_categories(X_valid, cat_cols_use_in_X, na_token='NA')\n",
    "                    X_ho = _force_lgbm_train_categories(X_ho, cat_cols_use_in_X, na_token='NA')\n",
    "                \n",
    "                model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    categorical_feature=cat_cols_use_in_X,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    eval_metric='rmse',\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)],\n",
    "                )\n",
    "                oof_pred_log.loc[va_idx] = model.predict(X_valid)\n",
    "\n",
    "                if has_ho:\n",
    "                    ho_pred_log_accum += model.predict(X_ho) / n_splits\n",
    "\n",
    "                fi_list.append(pd.DataFrame({'feature': base_cols, 'importance': model.feature_importances_}))\n",
    "\n",
    "            elif alg == 'cat':\n",
    "                X_tr = train_df.loc[tr_idx, base_cols].copy()\n",
    "                X_va = train_df.loc[va_idx, base_cols].copy()\n",
    "\n",
    "                if cat_cols:\n",
    "                    for c in cat_cols:\n",
    "                        if c in X_tr.columns:\n",
    "                            X_tr[c] = X_tr[c].astype('string').fillna('NA')\n",
    "                            X_va[c] = X_va[c].astype('string').fillna('NA')\n",
    "\n",
    "                model = CatBoostRegressor(**base_params['cat'], cat_features=(cat_cols or []))\n",
    "                model.fit(\n",
    "                    X_tr, y_log.loc[tr_idx],\n",
    "                    eval_set=(X_va, y_log.loc[va_idx]),\n",
    "                    use_best_model=True,\n",
    "                    verbose=False,\n",
    "                )\n",
    "                oof_pred_log.loc[va_idx] = model.predict(X_va)\n",
    "\n",
    "                if has_ho:\n",
    "                    X_ho = train_df.loc[idx_ho, base_cols].copy()\n",
    "                    if cat_cols:\n",
    "                        for c in cat_cols:\n",
    "                            if c in X_ho.columns:\n",
    "                                X_ho[c] = X_ho[c].astype('string').fillna('NA')\n",
    "                    ho_pred_log_accum += model.predict(X_ho) / n_splits\n",
    "\n",
    "                fi_list.append(pd.DataFrame({'feature': base_cols, 'importance': model.get_feature_importance()}))\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f'alg must be lgb or cat, got: {alg}')\n",
    "\n",
    "        # metrics\n",
    "        cv_mae_log = float(np.mean(np.abs(y_cv_log.values - oof_pred_log.values)))\n",
    "        cv_mape = mape(y.loc[idx_cv].values, np.exp(oof_pred_log.values))\n",
    "\n",
    "        ho_mape = None\n",
    "        if has_ho:\n",
    "            ho_mape = mape(y.loc[idx_ho].values, np.exp(ho_pred_log_accum.values))\n",
    "\n",
    "        if print_mape:\n",
    "            if has_ho:\n",
    "                print(f'[{stage_name}] split={split_key} DONE | log-MAE={cv_mae_log:.6f} | OOF MAPE={cv_mape:.6f} | HO MAPE={ho_mape:.6f}')\n",
    "            else:\n",
    "                print(f'[{stage_name}] split={split_key} DONE | log-MAE={cv_mae_log:.6f} | OOF MAPE={cv_mape:.6f} | HO MAPE=NA')\n",
    "\n",
    "        results[split_key] = {\n",
    "            'cv_mae_log': cv_mae_log,\n",
    "            'cv_mape': cv_mape,\n",
    "            'ho_mape': ho_mape,\n",
    "            'oof_pred_log': oof_pred_log,\n",
    "            'ho_pred_log': ho_pred_log_accum if has_ho else None,\n",
    "            'fi': pd.concat(fi_list, ignore_index=True) if fi_list else pd.DataFrame(),\n",
    "            'used_cols': base_cols,\n",
    "            'idx_cv': idx_cv,\n",
    "            'idx_ho': idx_ho,\n",
    "        }\n",
    "\n",
    "    print(f'\\n[{stage_name}] done.')\n",
    "\n",
    "    return {\n",
    "        'results_by_split': results,\n",
    "        'bias_table_ho_log_final': pd.DataFrame(),  # 今回はprint運用なので空でOK\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5322baa",
   "metadata": {},
   "source": [
    "#### 特徴量選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cad5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_features_by_fi(\n",
    "    fi_df: pd.DataFrame,\n",
    "    base_cols: list[str],\n",
    "    fi_drop_threshold: float = 1.0,\n",
    "    fi_keep_topk: int | None = None,\n",
    ") -> list[str]:\n",
    "    if fi_df is None or fi_df.empty:\n",
    "        return base_cols\n",
    "\n",
    "    fi_mean = fi_df.groupby('feature', as_index=True)['importance'].mean()\n",
    "\n",
    "    if fi_keep_topk is not None:\n",
    "        keep = set(fi_mean.sort_values(ascending=False).head(fi_keep_topk).index.tolist())\n",
    "    else:\n",
    "        keep = set(fi_mean[fi_mean > fi_drop_threshold].index.tolist())\n",
    "\n",
    "    return [c for c in base_cols if c in keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b6802",
   "metadata": {},
   "source": [
    "#### パラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff902614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_params_light_two_stage_lgb(\n",
    "    train_df: pd.DataFrame,\n",
    "    idx_cv: pd.Index,\n",
    "    idx_ho: pd.Index,\n",
    "    base_cols: list[str],\n",
    "    cat_cols: list[str],\n",
    "    target_col: str,\n",
    "    base_params: dict,          # BASE_PARAMS_BY_MODEL\n",
    "    property_type: str,         # 'residential' 想定\n",
    "    n_trials_phase1: int = 20,\n",
    "    n_trials_phase2: int = 30,\n",
    "\n",
    "    hpo_n_splits: int = 3,\n",
    "    hpo_n_estimators: int = 4000,\n",
    "    es_rounds: int = 30,        # ★HPO中だけ強める\n",
    "\n",
    "    te_smoothing: float = 50.0,\n",
    "    te_min_samples_leaf: int = 1,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    if property_type not in LGB_2STAGE_CONF:\n",
    "        raise ValueError(f'unknown property_type: {property_type}')\n",
    "\n",
    "    y = train_df[target_col].astype(float)\n",
    "    y_log = np.log(y)\n",
    "\n",
    "    X_cv_full = train_df.loc[idx_cv, base_cols]\n",
    "    y_cv_full = y_log.loc[idx_cv]\n",
    "    groups = train_df.loc[idx_cv, 'building_id']\n",
    "\n",
    "    gkf = GroupKFold(n_splits=hpo_n_splits)\n",
    "\n",
    "    has_ho = idx_ho is not None and len(idx_ho) > 0\n",
    "\n",
    "    te_cols_base = [\n",
    "        c for c in base_cols\n",
    "        if c.endswith('_te') and (_infer_te_source_col(c) in train_df.columns)\n",
    "    ]\n",
    "\n",
    "    def _objective(trial: optuna.Trial, space_fn, best_params_ref=None) -> float:\n",
    "        params = dict(base_params['lgb'])\n",
    "        if best_params_ref is None:\n",
    "            params.update(space_fn(trial))\n",
    "        else:\n",
    "            params.update(space_fn(trial, best_params_ref))\n",
    "\n",
    "        params['n_estimators'] = hpo_n_estimators\n",
    "        params['verbosity'] = -1\n",
    "\n",
    "        oof_pred_log = pd.Series(np.nan, index=idx_cv, dtype=float)\n",
    "        ho_pred_log_accum = pd.Series(0.0, index=idx_ho, dtype=float) if has_ho else None\n",
    "\n",
    "        fold_scores = []\n",
    "\n",
    "        for fold, (tr_pos, va_pos) in enumerate(gkf.split(X_cv_full, y_cv_full, groups), 1):\n",
    "            tr_idx = _safe_take_index(idx_cv, tr_pos)\n",
    "            va_idx = _safe_take_index(idx_cv, va_pos)\n",
    "\n",
    "            # TE再計算（tr/va/ho）\n",
    "            if te_cols_base:\n",
    "                apply_list = [tr_idx, va_idx]\n",
    "                if has_ho:\n",
    "                    apply_list.append(idx_ho)\n",
    "                recompute_te_for_fold(\n",
    "                    train_df=train_df,\n",
    "                    tr_idx=tr_idx,\n",
    "                    apply_idx_list=apply_list,\n",
    "                    te_cols=te_cols_base,\n",
    "                    y_tr=y_log,\n",
    "                    smoothing=te_smoothing,\n",
    "                    min_samples_leaf=te_min_samples_leaf,\n",
    "                    verbose=False,\n",
    "                )\n",
    "\n",
    "            model = lgb.LGBMRegressor(**params)\n",
    "            X_train = train_df.loc[tr_idx, base_cols].copy()\n",
    "            y_train = y_log.loc[tr_idx].to_numpy()\n",
    "            X_valid = train_df.loc[va_idx, base_cols].copy()\n",
    "            y_valid = y_log.loc[va_idx].to_numpy()\n",
    "            X_ho = train_df.loc[idx_ho, base_cols]\n",
    "\n",
    "            # categorical_feature に渡す列は X に存在するものだけに限定（安全）\n",
    "            cat_cols_use_in_X = [c for c in (cat_cols or []) if c in X_train.columns]\n",
    "\n",
    "            # cat列を category dtype に統一（学習・推論で同じ前処理にする）\n",
    "            if cat_cols_use_in_X:\n",
    "                X_train = _force_lgbm_train_categories(X_train, cat_cols_use_in_X, na_token='NA')\n",
    "                X_valid = _force_lgbm_train_categories(X_valid, cat_cols_use_in_X, na_token='NA')\n",
    "                X_ho = _force_lgbm_train_categories(X_ho, cat_cols_use_in_X, na_token='NA')\n",
    "\n",
    "\n",
    "            model.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                categorical_feature=cat_cols_use_in_X,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                eval_metric='rmse',\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=es_rounds, verbose=False)],\n",
    "            )\n",
    "\n",
    "            pred_va = model.predict(X_valid)\n",
    "            oof_pred_log.loc[va_idx] = pred_va\n",
    "\n",
    "            fold_mae = float(np.mean(np.abs(y_log.loc[va_idx].values - pred_va)))\n",
    "            fold_scores.append(fold_mae)\n",
    "\n",
    "            # ★Pruner判定：foldごとに報告して剪定\n",
    "            trial.report(float(np.mean(fold_scores)), step=fold)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            if has_ho:\n",
    "                ho_pred_log_accum += model.predict(X_ho) / hpo_n_splits\n",
    "\n",
    "        score = float(np.mean(fold_scores))\n",
    "\n",
    "        # best更新時にMAPEをprintするため保持\n",
    "        trial.set_user_attr('oof_pred_log', oof_pred_log)\n",
    "        if has_ho:\n",
    "            trial.set_user_attr('ho_pred_log', ho_pred_log_accum)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _run_phase(phase_name: str, n_trials: int, space_fn, best_params_ref=None):\n",
    "        print(f'\\n[HPO-2STAGE] {phase_name} start: trials={n_trials}, folds={hpo_n_splits}, est={hpo_n_estimators}, es={es_rounds}')\n",
    "\n",
    "        # Phase2は pruner を強める\n",
    "        if phase_name == 'PHASE2':\n",
    "            pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=1, interval_steps=1)\n",
    "        else:\n",
    "            pruner = optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=1, interval_steps=1)\n",
    "\n",
    "        sampler = optuna.samplers.TPESampler(seed=seed, multivariate=True, group=True)\n",
    "        study = optuna.create_study(direction='minimize', sampler=sampler, pruner=pruner)\n",
    "\n",
    "        best_value_seen = None\n",
    "\n",
    "        def _callback(study: optuna.Study, trial: optuna.Trial):\n",
    "            nonlocal best_value_seen\n",
    "            if study.best_trial.number != trial.number:\n",
    "                return\n",
    "\n",
    "            if best_value_seen is None or study.best_value < best_value_seen:\n",
    "                best_value_seen = study.best_value\n",
    "\n",
    "                oof_pred_log = trial.user_attrs.get('oof_pred_log')\n",
    "                ho_pred_log = trial.user_attrs.get('ho_pred_log')\n",
    "\n",
    "                oof_m = mape(y.loc[idx_cv].values, np.exp(oof_pred_log.values)) if oof_pred_log is not None else None\n",
    "                ho_m = mape(y.loc[idx_ho].values, np.exp(ho_pred_log.values)) if (has_ho and ho_pred_log is not None) else None\n",
    "\n",
    "                print(f'[HPO-2STAGE] {phase_name} NEW BEST: trial={trial.number} logMAE={study.best_value:.6f} | OOF_MAPE={oof_m:.6f} | HO_MAPE={(ho_m if ho_m is not None else float(\"nan\")):.6f}')\n",
    "\n",
    "        study.optimize(\n",
    "            lambda t: _objective(t, space_fn, best_params_ref),\n",
    "            n_trials=n_trials,\n",
    "            callbacks=[_callback],\n",
    "        )\n",
    "\n",
    "        print(f'[HPO-2STAGE] {phase_name} done: best_logMAE={study.best_value:.6f}')\n",
    "        print(f'[HPO-2STAGE] {phase_name} best_params={study.best_params}')\n",
    "        return study\n",
    "\n",
    "    # Phase1\n",
    "    study1 = _run_phase(\n",
    "        'PHASE1',\n",
    "        n_trials_phase1,\n",
    "        lambda t: _space_lgb_phase1(t, property_type),\n",
    "    )\n",
    "    best1 = study1.best_params\n",
    "\n",
    "    # Phase2\n",
    "    study2 = _run_phase(\n",
    "        'PHASE2',\n",
    "        n_trials_phase2,\n",
    "        lambda t, bp: _space_lgb_phase2(t, bp, property_type),\n",
    "        best_params_ref=best1,\n",
    "    )\n",
    "\n",
    "    # 最終best（Phase2 bestを採用）\n",
    "    best = study2.best_params\n",
    "    merged = dict(base_params['lgb'])\n",
    "    merged.update(best)\n",
    "    merged['verbosity'] = -1\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc81a61",
   "metadata": {},
   "source": [
    "#### 最終モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29c5f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_models_by_split(\n",
    "    train_df: pd.DataFrame,\n",
    "    idx_dict: dict[str, pd.Index] | None,\n",
    "    feature_cols_by_split: dict[str, list[str]],\n",
    "    cat_cols_by_split: dict[str, list[str]],\n",
    "    target_col: str,\n",
    "    alg: str,\n",
    "    params_by_split: dict[str, dict],\n",
    "    te_smoothing: float = 50.0,\n",
    "    te_min_samples_leaf: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    splitごとに、与えられた feature_cols で最終モデルを学習する。\n",
    "    TE列(*_te)が含まれている場合：\n",
    "      - split内の全行をtrとしてTEをfit\n",
    "      - split内の全行にTEを適用\n",
    "    してから学習する（最終モデル整合）。\n",
    "    \"\"\"\n",
    "    if idx_dict is None:\n",
    "        idx_dict = {'all': train_df.index}\n",
    "\n",
    "    y_log = np.log(train_df[target_col].astype(float))\n",
    "\n",
    "    models_by_split = {}\n",
    "    final_cols_by_split = {}\n",
    "\n",
    "    for split_key, idx in idx_dict.items():\n",
    "        cols = feature_cols_by_split[split_key]\n",
    "        cat_cols = cat_cols_by_split[split_key]\n",
    "        te_cols = [c for c in cols if c.endswith('_te')]\n",
    "\n",
    "        # 最終学習用に TE を split全体で fit→apply\n",
    "        if te_cols:\n",
    "            recompute_te_for_fold(\n",
    "                train_df=train_df,\n",
    "                tr_idx=idx,\n",
    "                apply_idx_list=[idx],\n",
    "                te_cols=te_cols,\n",
    "                y_tr=y_log,\n",
    "                smoothing=te_smoothing,\n",
    "                min_samples_leaf=te_min_samples_leaf,\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "        final_cols_by_split[split_key] = cols\n",
    "\n",
    "        if alg == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params_by_split[split_key])\n",
    "            X_train = train_df.loc[idx, cols].copy()\n",
    "            y_train = y_log.loc[idx].to_numpy()\n",
    "\n",
    "            # categorical_feature に渡す列は X に存在するものだけに限定（安全）\n",
    "            cat_cols_use_in_X = [c for c in (cat_cols or []) if c in X_train.columns]\n",
    "\n",
    "            # cat列を category dtype に統一（学習・推論で同じ前処理にする）\n",
    "            if cat_cols_use_in_X:\n",
    "                X_train = _force_lgbm_train_categories(X_train, cat_cols_use_in_X, na_token='NA')\n",
    "\n",
    "            model.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                categorical_feature=cat_cols_use_in_X,\n",
    "            )\n",
    "\n",
    "            models_by_split[split_key] = model\n",
    "\n",
    "        elif alg == 'cat':\n",
    "            X = train_df.loc[idx, cols].copy()\n",
    "            if cat_cols:\n",
    "                for c in cat_cols:\n",
    "                    if c in X.columns:\n",
    "                        X[c] = X[c].astype('string').fillna('NA')\n",
    "\n",
    "            model = CatBoostRegressor(**params_by_split[split_key], cat_features=(cat_cols or []))\n",
    "            model.fit(X, y_log.loc[idx], verbose=False)\n",
    "            models_by_split[split_key] = model\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'alg must be lgb or cat, got: {alg}')\n",
    "\n",
    "    return models_by_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea06cd",
   "metadata": {},
   "source": [
    "#### パイプライン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04f884e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_fs_and_hpo_by_separate_light(\n",
    "    train_df: pd.DataFrame,\n",
    "    base_cols: list[str],\n",
    "    cat_cols: list[str],\n",
    "    target_col: str,\n",
    "    year_col: str,\n",
    "    property_type: str,\n",
    "    alg: str,\n",
    "    idx_dict: dict[str, pd.Index] | None,\n",
    "    base_params: dict,\n",
    "    n_splits_fixed: int = 5,\n",
    "\n",
    "    # TE\n",
    "    te_smoothing: float = 50.0,\n",
    "    te_min_samples_leaf: int = 1,\n",
    "\n",
    "    # FS\n",
    "    fi_drop_threshold: float = 1.0,\n",
    "    fi_keep_topk: int | None = None,\n",
    "\n",
    "    # HPO (two-stage)\n",
    "    n_trials_phase1: int = 20,\n",
    "    n_trials_phase2: int = 30,\n",
    "    hpo_n_splits: int = 3,\n",
    "    hpo_n_estimators: int = 4000,\n",
    "    es_rounds: int = 30,\n",
    "\n",
    "    # time split\n",
    "    ho_year: int = 2022,\n",
    "    cv_year_max: int = 2021,\n",
    "):\n",
    "    if idx_dict is None:\n",
    "        idx_dict = {'all': train_df.index}\n",
    "\n",
    "    if alg != 'lgb':\n",
    "        raise ValueError('この軽量二段階実装はまずlgb対象です（catは別途実装）')\n",
    "\n",
    "    print('\\n' + '=' * 80)\n",
    "    print(f'[PIPELINE-LIGHT] START | target_model={property_type} | alg={alg}')\n",
    "    print('=' * 80)\n",
    "\n",
    "    # Step1: FIXED CV（FI用）\n",
    "    print('\\n[PIPELINE-LIGHT] Step1: FIXED CV (for FI only)')\n",
    "    cv_fixed = run_cv_by_separate(\n",
    "        train_df=train_df,\n",
    "        base_cols=base_cols,\n",
    "        cat_cols=cat_cols,\n",
    "        target_col=target_col,\n",
    "        year_col=year_col,\n",
    "        base_params=base_params,\n",
    "        alg=alg,\n",
    "        idx_dict=idx_dict,\n",
    "        n_splits=n_splits_fixed,\n",
    "        te_smoothing=te_smoothing,\n",
    "        te_min_samples_leaf=te_min_samples_leaf,\n",
    "        ho_year=ho_year,\n",
    "        cv_year_max=cv_year_max,\n",
    "        stage_name='CV_FIXED',\n",
    "        print_mape=False,\n",
    "    )\n",
    "\n",
    "    # Step2: FS by FI\n",
    "    print('\\n[PIPELINE-LIGHT] Step2: Feature selection by FI')\n",
    "    reduced_cols_by_split = {}\n",
    "    cat_cols_by_split = {}\n",
    "    for split_key, res in cv_fixed['results_by_split'].items():\n",
    "        fi_df = res.get('fi')\n",
    "        reduced_cols = reduce_features_by_fi(\n",
    "            fi_df=fi_df,\n",
    "            base_cols=base_cols,\n",
    "            fi_drop_threshold=fi_drop_threshold,\n",
    "            fi_keep_topk=fi_keep_topk,\n",
    "        )\n",
    "        cat_cols_use = [c for c in cat_cols if c in reduced_cols]\n",
    "        reduced_cols_by_split[split_key] = reduced_cols\n",
    "        cat_cols_by_split[split_key] = cat_cols_use\n",
    "        print(f'  [FS] split={split_key} | {len(base_cols)} -> {len(reduced_cols)}, {len(cat_cols_use)}')\n",
    "\n",
    "    # Step3: HPO（二段階 + Pruner + es_rounds=30）\n",
    "    print('\\n[PIPELINE-LIGHT] Step3: HPO 2-stage (Pruner + strong early stop)')\n",
    "\n",
    "    best_params_by_split = {}\n",
    "    for split_key, split_idx in idx_dict.items():\n",
    "        idx_cv = split_idx.intersection(train_df.index[train_df[year_col] <= cv_year_max])\n",
    "        idx_ho = split_idx.intersection(train_df.index[train_df[year_col] == ho_year])\n",
    "\n",
    "        cols = reduced_cols_by_split[split_key]\n",
    "        cat_cols = cat_cols_by_split[split_key]\n",
    "        print(f'\\n[PIPELINE-LIGHT] HPO split={split_key} | cv={len(idx_cv)} ho={len(idx_ho)} | n_features={len(cols)}')\n",
    "\n",
    "        tuned_params = tune_params_light_two_stage_lgb(\n",
    "            train_df=train_df,\n",
    "            idx_cv=idx_cv,\n",
    "            idx_ho=idx_ho,\n",
    "            base_cols=cols,\n",
    "            cat_cols=cat_cols,\n",
    "            target_col=target_col,\n",
    "            base_params=base_params,\n",
    "            property_type=property_type,\n",
    "            n_trials_phase1=n_trials_phase1,\n",
    "            n_trials_phase2=n_trials_phase2,\n",
    "            hpo_n_splits=hpo_n_splits,\n",
    "            hpo_n_estimators=hpo_n_estimators,\n",
    "            es_rounds=es_rounds,\n",
    "            te_smoothing=te_smoothing,\n",
    "            te_min_samples_leaf=te_min_samples_leaf,\n",
    "        )\n",
    "        best_params_by_split[split_key] = tuned_params\n",
    "\n",
    "    # Step4: Final train（tuned再CVなし）\n",
    "    print('\\n[PIPELINE-LIGHT] Step4: Final training (no tuned re-CV)')\n",
    "    final_models_by_split= train_final_models_by_split(\n",
    "        train_df=train_df,\n",
    "        idx_dict=idx_dict,\n",
    "        feature_cols_by_split=reduced_cols_by_split,\n",
    "        cat_cols_by_split=cat_cols_by_split,\n",
    "        target_col=target_col,\n",
    "        alg=alg,\n",
    "        params_by_split=best_params_by_split,\n",
    "        te_smoothing=te_smoothing,\n",
    "        te_min_samples_leaf=te_min_samples_leaf,\n",
    "    )\n",
    "    print('[PIPELINE-LIGHT] Final training done.')\n",
    "\n",
    "    print('\\n' + '=' * 80)\n",
    "    print('[PIPELINE-LIGHT] DONE')\n",
    "    print('=' * 80)\n",
    "\n",
    "    return {\n",
    "        'cv_fixed': cv_fixed,\n",
    "        'reduced_cols_by_split': reduced_cols_by_split,\n",
    "        'cat_cols_by_split': cat_cols_by_split,\n",
    "        'best_params_by_split': best_params_by_split,\n",
    "        'final_models_by_split': final_models_by_split,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f1d67",
   "metadata": {},
   "source": [
    "## 関数の呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe55b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, fe_cols, cat_cols, idx_dict = prepare_training_inputs(\n",
    "    target_model=property_types[0],\n",
    "    alg=alg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15a48b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################################\n",
      "[RUN] target_model=residential | alg=lgb\n",
      "####################################################################################################\n",
      "\n",
      "================================================================================\n",
      "[PIPELINE-LIGHT] START | target_model=residential | alg=lgb\n",
      "================================================================================\n",
      "\n",
      "[PIPELINE-LIGHT] Step1: FIXED CV (for FI only)\n",
      "\n",
      "[CV_FIXED] start: alg=lgb, n_splits=5, n_features=365, n_te_cols=2\n",
      "\n",
      "[CV_FIXED] split=main_city | CV=31627 | HO=11070\n",
      "[CV_FIXED] split=main_city fold=1/5 | tr=25301 va=6326\n",
      "[CV_FIXED] split=main_city fold=2/5 | tr=25301 va=6326\n",
      "[CV_FIXED] split=main_city fold=3/5 | tr=25302 va=6325\n",
      "[CV_FIXED] split=main_city fold=4/5 | tr=25302 va=6325\n",
      "[CV_FIXED] split=main_city fold=5/5 | tr=25302 va=6325\n",
      "\n",
      "[CV_FIXED] split=mid_city | CV=54265 | HO=15471\n",
      "[CV_FIXED] split=mid_city fold=1/5 | tr=43412 va=10853\n",
      "[CV_FIXED] split=mid_city fold=2/5 | tr=43412 va=10853\n",
      "[CV_FIXED] split=mid_city fold=3/5 | tr=43412 va=10853\n",
      "[CV_FIXED] split=mid_city fold=4/5 | tr=43412 va=10853\n",
      "[CV_FIXED] split=mid_city fold=5/5 | tr=43412 va=10853\n",
      "\n",
      "[CV_FIXED] split=other | CV=62062 | HO=20659\n",
      "[CV_FIXED] split=other fold=1/5 | tr=49649 va=12413\n",
      "[CV_FIXED] split=other fold=2/5 | tr=49649 va=12413\n",
      "[CV_FIXED] split=other fold=3/5 | tr=49650 va=12412\n",
      "[CV_FIXED] split=other fold=4/5 | tr=49650 va=12412\n",
      "[CV_FIXED] split=other fold=5/5 | tr=49650 va=12412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:330: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2026-01-09 07:13:28,798] A new study created in memory with name: no-name-d508181c-ea42-43e1-a9c5-b946f3f91f07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV_FIXED] done.\n",
      "\n",
      "[PIPELINE-LIGHT] Step2: Feature selection by FI\n",
      "  [FS] split=main_city | 365 -> 258, 5\n",
      "  [FS] split=mid_city | 365 -> 280, 5\n",
      "  [FS] split=other | 365 -> 279, 6\n",
      "\n",
      "[PIPELINE-LIGHT] Step3: HPO 2-stage (Pruner + strong early stop)\n",
      "\n",
      "[PIPELINE-LIGHT] HPO split=main_city | cv=31627 ho=11070 | n_features=258\n",
      "\n",
      "[HPO-2STAGE] PHASE1 start: trials=20, folds=3, est=4000, es=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:13:40,777] Trial 0 finished with value: 0.12353618876655109 and parameters: {'num_leaves': 67, 'max_depth': 10, 'min_child_samples': 160, 'learning_rate': 0.08387926357773329, 'subsample': 0.696805592132731, 'colsample_bytree': 0.6967983561008608, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 13.39433470675048}. Best is trial 0 with value: 0.12353618876655109.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=0 logMAE=0.123536 | OOF_MAPE=0.125176 | HO_MAPE=0.124499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:13:54,441] Trial 1 finished with value: 0.12537333208121818 and parameters: {'num_leaves': 89, 'max_depth': 8, 'min_child_samples': 53, 'learning_rate': 0.11729188669457949, 'subsample': 0.8997327922401265, 'colsample_bytree': 0.7137017332034828, 'reg_alpha': 0.18182496720710062, 'reg_lambda': 1.7322667470546256}. Best is trial 0 with value: 0.12353618876655109.\n",
      "[I 2026-01-09 07:14:12,408] Trial 2 finished with value: 0.12143331811092095 and parameters: {'num_leaves': 60, 'max_depth': 7, 'min_child_samples': 115, 'learning_rate': 0.056210622617823766, 'subsample': 0.8335558684167138, 'colsample_bytree': 0.6918481581956125, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 2.9967309097101573}. Best is trial 2 with value: 0.12143331811092095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=2 logMAE=0.121433 | OOF_MAPE=0.122948 | HO_MAPE=0.123250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:14:29,340] Trial 3 finished with value: 0.12213392682183592 and parameters: {'num_leaves': 75, 'max_depth': 9, 'min_child_samples': 80, 'learning_rate': 0.07628109945722504, 'subsample': 0.8277243706586127, 'colsample_bytree': 0.6639351238159993, 'reg_alpha': 0.6075448519014384, 'reg_lambda': 1.6666983286066417}. Best is trial 2 with value: 0.12143331811092095.\n",
      "[I 2026-01-09 07:14:39,811] Trial 4 finished with value: 0.12325661913230106 and parameters: {'num_leaves': 37, 'max_depth': 10, 'min_child_samples': 195, 'learning_rate': 0.1027557613304815, 'subsample': 0.7413841307520113, 'colsample_bytree': 0.6793016342019151, 'reg_alpha': 0.6842330265121569, 'reg_lambda': 3.738105868191796}. Best is trial 2 with value: 0.12143331811092095.\n",
      "[I 2026-01-09 07:14:49,589] Trial 5 finished with value: 0.1245325361590387 and parameters: {'num_leaves': 42, 'max_depth': 7, 'min_child_samples': 55, 'learning_rate': 0.11183883618709038, 'subsample': 0.7276339944800051, 'colsample_bytree': 0.8487566853061945, 'reg_alpha': 0.31171107608941095, 'reg_lambda': 4.749239763680407}. Best is trial 2 with value: 0.12143331811092095.\n",
      "[I 2026-01-09 07:15:00,365] Trial 6 finished with value: 0.12293967142692186 and parameters: {'num_leaves': 84, 'max_depth': 5, 'min_child_samples': 196, 'learning_rate': 0.0997619541025003, 'subsample': 0.9318496824692567, 'colsample_bytree': 0.9184482051282946, 'reg_alpha': 0.5978999788110851, 'reg_lambda': 15.826541904647563}. Best is trial 2 with value: 0.12143331811092095.\n",
      "[I 2026-01-09 07:15:14,925] Trial 7 finished with value: 0.12094471177874984 and parameters: {'num_leaves': 39, 'max_depth': 5, 'min_child_samples': 56, 'learning_rate': 0.05927972976869379, 'subsample': 0.7666031869068446, 'colsample_bytree': 0.7314047095321687, 'reg_alpha': 0.8287375091519293, 'reg_lambda': 2.9117010232427414}. Best is trial 7 with value: 0.12094471177874984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=7 logMAE=0.120945 | OOF_MAPE=0.122437 | HO_MAPE=0.122780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:15:25,774] Trial 8 finished with value: 0.12396853864021068 and parameters: {'num_leaves': 58, 'max_depth': 7, 'min_child_samples': 71, 'learning_rate': 0.10219772826786357, 'subsample': 0.6723651931039313, 'colsample_bytree': 0.9460660809801551, 'reg_alpha': 0.7722447692966574, 'reg_lambda': 1.8135730867783397}. Best is trial 7 with value: 0.12094471177874984.\n",
      "[I 2026-01-09 07:15:37,657] Trial 9 finished with value: 0.12315150250392144 and parameters: {'num_leaves': 31, 'max_depth': 9, 'min_child_samples': 156, 'learning_rate': 0.09561064512368886, 'subsample': 0.8813811040057837, 'colsample_bytree': 0.6722133955202271, 'reg_alpha': 0.3584657285442726, 'reg_lambda': 1.414976157494142}. Best is trial 7 with value: 0.12094471177874984.\n",
      "[I 2026-01-09 07:15:52,538] Trial 10 finished with value: 0.120692863373012 and parameters: {'num_leaves': 47, 'max_depth': 5, 'min_child_samples': 55, 'learning_rate': 0.050540451698769064, 'subsample': 0.6537610918690696, 'colsample_bytree': 0.6742388213758379, 'reg_alpha': 0.855381558133683, 'reg_lambda': 1.4223069965263562}. Best is trial 10 with value: 0.120692863373012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=10 logMAE=0.120693 | OOF_MAPE=0.122210 | HO_MAPE=0.123309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:16:08,100] Trial 11 finished with value: 0.12075656852627575 and parameters: {'num_leaves': 33, 'max_depth': 5, 'min_child_samples': 69, 'learning_rate': 0.05557330416752304, 'subsample': 0.7613062360755578, 'colsample_bytree': 0.7560461445705187, 'reg_alpha': 0.9009551686189577, 'reg_lambda': 3.1432862812561972}. Best is trial 10 with value: 0.120692863373012.\n",
      "[I 2026-01-09 07:16:20,979] Trial 12 finished with value: 0.12151937046729493 and parameters: {'num_leaves': 72, 'max_depth': 6, 'min_child_samples': 93, 'learning_rate': 0.06337841838276713, 'subsample': 0.6595652648832914, 'colsample_bytree': 0.667259855326242, 'reg_alpha': 0.6060559890252085, 'reg_lambda': 1.3034044501969555}. Best is trial 10 with value: 0.120692863373012.\n",
      "[I 2026-01-09 07:16:36,109] Trial 13 finished with value: 0.12091090268402295 and parameters: {'num_leaves': 36, 'max_depth': 4, 'min_child_samples': 70, 'learning_rate': 0.03918997076277981, 'subsample': 0.6674808566760786, 'colsample_bytree': 0.699214081203387, 'reg_alpha': 0.3011815988734019, 'reg_lambda': 1.0794404011899306}. Best is trial 10 with value: 0.120692863373012.\n",
      "[I 2026-01-09 07:16:44,880] Trial 14 finished with value: 0.12201788553410987 and parameters: {'num_leaves': 48, 'max_depth': 4, 'min_child_samples': 88, 'learning_rate': 0.0810853353539809, 'subsample': 0.6735701371522077, 'colsample_bytree': 0.6516082746603468, 'reg_alpha': 0.9570186586959591, 'reg_lambda': 1.5219890981184048}. Best is trial 10 with value: 0.120692863373012.\n",
      "[I 2026-01-09 07:16:59,212] Trial 15 finished with value: 0.12088619140731542 and parameters: {'num_leaves': 35, 'max_depth': 4, 'min_child_samples': 68, 'learning_rate': 0.044791571461698716, 'subsample': 0.6532471997707581, 'colsample_bytree': 0.7850187627871998, 'reg_alpha': 0.9344949317631429, 'reg_lambda': 1.0166403265455597}. Best is trial 10 with value: 0.120692863373012.\n",
      "[I 2026-01-09 07:17:10,205] Trial 16 finished with value: 0.12141334004262543 and parameters: {'num_leaves': 33, 'max_depth': 4, 'min_child_samples': 58, 'learning_rate': 0.06856299667582064, 'subsample': 0.6892661595288333, 'colsample_bytree': 0.679528504754577, 'reg_alpha': 0.9842708856903106, 'reg_lambda': 16.045718986214244}. Best is trial 10 with value: 0.120692863373012.\n",
      "[I 2026-01-09 07:17:25,470] Trial 17 finished with value: 0.1206812284598055 and parameters: {'num_leaves': 72, 'max_depth': 4, 'min_child_samples': 80, 'learning_rate': 0.04334061106387149, 'subsample': 0.6603387980300108, 'colsample_bytree': 0.7373789179683782, 'reg_alpha': 0.6621169948589065, 'reg_lambda': 6.982718496905917}. Best is trial 17 with value: 0.1206812284598055.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=17 logMAE=0.120681 | OOF_MAPE=0.122182 | HO_MAPE=0.123413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:17:28,093] Trial 18 pruned. \n",
      "[I 2026-01-09 07:17:46,336] Trial 19 finished with value: 0.12045594864585728 and parameters: {'num_leaves': 104, 'max_depth': 4, 'min_child_samples': 94, 'learning_rate': 0.03293805506756523, 'subsample': 0.6751457447050042, 'colsample_bytree': 0.7480848723782374, 'reg_alpha': 0.8972661621428522, 'reg_lambda': 1.4083606825059687}. Best is trial 19 with value: 0.12045594864585728.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:330: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2026-01-09 07:17:46,341] A new study created in memory with name: no-name-c2434729-efa0-4086-a56e-c5b57ae61925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=19 logMAE=0.120456 | OOF_MAPE=0.121975 | HO_MAPE=0.123895\n",
      "[HPO-2STAGE] PHASE1 done: best_logMAE=0.120456\n",
      "[HPO-2STAGE] PHASE1 best_params={'num_leaves': 104, 'max_depth': 4, 'min_child_samples': 94, 'learning_rate': 0.03293805506756523, 'subsample': 0.6751457447050042, 'colsample_bytree': 0.7480848723782374, 'reg_alpha': 0.8972661621428522, 'reg_lambda': 1.4083606825059687}\n",
      "\n",
      "[HPO-2STAGE] PHASE2 start: trials=30, folds=3, est=4000, es=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:18:02,031] Trial 0 finished with value: 0.12061297439722268 and parameters: {'num_leaves': 92, 'max_depth': 6, 'min_child_samples': 113, 'learning_rate': 0.041618214652809585, 'subsample': 0.669723503080193, 'colsample_bytree': 0.6828052737444927, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 2.2383262123610987}. Best is trial 0 with value: 0.12061297439722268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=0 logMAE=0.120613 | OOF_MAPE=0.122107 | HO_MAPE=0.123422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:18:20,671] Trial 1 finished with value: 0.12088748478121869 and parameters: {'num_leaves': 105, 'max_depth': 6, 'min_child_samples': 55, 'learning_rate': 0.04882312061676891, 'subsample': 0.755235406124237, 'colsample_bytree': 0.6946544060486871, 'reg_alpha': 0.18182496720710062, 'reg_lambda': 1.1860224975542433}. Best is trial 0 with value: 0.12061297439722268.\n",
      "[I 2026-01-09 07:18:39,719] Trial 2 finished with value: 0.12047276628722965 and parameters: {'num_leaves': 89, 'max_depth': 5, 'min_child_samples': 88, 'learning_rate': 0.035651907979742915, 'subsample': 0.7273489784262948, 'colsample_bytree': 0.6793352245611177, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 1.4060643633794512}. Best is trial 2 with value: 0.12047276628722965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=2 logMAE=0.120473 | OOF_MAPE=0.121904 | HO_MAPE=0.122943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:19:00,561] Trial 3 finished with value: 0.12029579801779074 and parameters: {'num_leaves': 97, 'max_depth': 6, 'min_child_samples': 70, 'learning_rate': 0.03997979022275068, 'subsample': 0.7248916317983987, 'colsample_bytree': 0.6597684104642908, 'reg_alpha': 0.6075448519014384, 'reg_lambda': 1.1718969565798714}. Best is trial 3 with value: 0.12029579801779074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=3 logMAE=0.120296 | OOF_MAPE=0.121886 | HO_MAPE=0.123169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:19:18,197] Trial 4 finished with value: 0.12090200628624598 and parameters: {'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 132, 'learning_rate': 0.04568863410960672, 'subsample': 0.6885085435786557, 'colsample_bytree': 0.6705402114784356, 'reg_alpha': 0.6842330265121569, 'reg_lambda': 1.5059675718009737}. Best is trial 3 with value: 0.12029579801779074.\n",
      "[I 2026-01-09 07:19:36,175] Trial 5 finished with value: 0.12025572639211063 and parameters: {'num_leaves': 78, 'max_depth': 5, 'min_child_samples': 56, 'learning_rate': 0.047647256154233764, 'subsample': 0.6827143458608933, 'colsample_bytree': 0.7893268484894016, 'reg_alpha': 0.31171107608941095, 'reg_lambda': 1.6221850934359126}. Best is trial 5 with value: 0.12025572639211063.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=5 logMAE=0.120256 | OOF_MAPE=0.121793 | HO_MAPE=0.122273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:19:41,526] Trial 6 pruned. \n",
      "[I 2026-01-09 07:20:00,291] Trial 7 finished with value: 0.12031194087929524 and parameters: {'num_leaves': 76, 'max_depth': 4, 'min_child_samples': 57, 'learning_rate': 0.03631371260184649, 'subsample': 0.6991356526287639, 'colsample_bytree': 0.7070640510221808, 'reg_alpha': 0.8287375091519293, 'reg_lambda': 1.3935530020271982}. Best is trial 5 with value: 0.12025572639211063.\n",
      "[I 2026-01-09 07:20:06,377] Trial 8 pruned. \n",
      "[I 2026-01-09 07:20:12,684] Trial 9 pruned. \n",
      "[I 2026-01-09 07:20:18,734] Trial 10 pruned. \n",
      "[I 2026-01-09 07:20:24,084] Trial 11 pruned. \n",
      "[I 2026-01-09 07:20:27,714] Trial 12 pruned. \n",
      "[I 2026-01-09 07:20:34,690] Trial 13 pruned. \n",
      "[I 2026-01-09 07:20:38,255] Trial 14 pruned. \n",
      "[I 2026-01-09 07:20:43,462] Trial 15 pruned. \n",
      "[I 2026-01-09 07:20:48,066] Trial 16 pruned. \n",
      "[I 2026-01-09 07:20:54,064] Trial 17 pruned. \n",
      "[I 2026-01-09 07:21:29,725] Trial 18 finished with value: 0.11956200962607516 and parameters: {'num_leaves': 87, 'max_depth': 6, 'min_child_samples': 63, 'learning_rate': 0.03095252127426993, 'subsample': 0.7391296146838218, 'colsample_bytree': 0.6740739132093512, 'reg_alpha': 0.7332109418789587, 'reg_lambda': 1.2122434308198053}. Best is trial 18 with value: 0.11956200962607516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=18 logMAE=0.119562 | OOF_MAPE=0.121048 | HO_MAPE=0.122545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:22:01,669] Trial 19 finished with value: 0.11953482077458695 and parameters: {'num_leaves': 84, 'max_depth': 6, 'min_child_samples': 81, 'learning_rate': 0.030489907734239114, 'subsample': 0.7373480809994508, 'colsample_bytree': 0.6977671371137035, 'reg_alpha': 0.7013659436962031, 'reg_lambda': 1.363365061625741}. Best is trial 19 with value: 0.11953482077458695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=19 logMAE=0.119535 | OOF_MAPE=0.121038 | HO_MAPE=0.122709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:22:30,241] Trial 20 finished with value: 0.11999924899527377 and parameters: {'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 84, 'learning_rate': 0.03194188032890291, 'subsample': 0.741112425037547, 'colsample_bytree': 0.7277194835680821, 'reg_alpha': 0.9337716061483156, 'reg_lambda': 1.5074798910468705}. Best is trial 19 with value: 0.11953482077458695.\n",
      "[I 2026-01-09 07:23:01,022] Trial 21 finished with value: 0.11970904313143323 and parameters: {'num_leaves': 89, 'max_depth': 6, 'min_child_samples': 84, 'learning_rate': 0.03138567049403701, 'subsample': 0.7572715339055287, 'colsample_bytree': 0.7251504986225761, 'reg_alpha': 0.8760320587469266, 'reg_lambda': 1.3600856721982202}. Best is trial 19 with value: 0.11953482077458695.\n",
      "[I 2026-01-09 07:23:35,281] Trial 22 finished with value: 0.11985818759316798 and parameters: {'num_leaves': 90, 'max_depth': 6, 'min_child_samples': 55, 'learning_rate': 0.0302591130054256, 'subsample': 0.7688036031232437, 'colsample_bytree': 0.7356165669365339, 'reg_alpha': 0.619456650079317, 'reg_lambda': 1.1463084637312257}. Best is trial 19 with value: 0.11953482077458695.\n",
      "[I 2026-01-09 07:24:06,351] Trial 23 finished with value: 0.11962415511522502 and parameters: {'num_leaves': 104, 'max_depth': 6, 'min_child_samples': 87, 'learning_rate': 0.03119835395433288, 'subsample': 0.7328898862477703, 'colsample_bytree': 0.7399718240358717, 'reg_alpha': 0.8198484830906368, 'reg_lambda': 1.1640034947601554}. Best is trial 19 with value: 0.11953482077458695.\n",
      "[I 2026-01-09 07:24:32,254] Trial 24 finished with value: 0.12000467559806821 and parameters: {'num_leaves': 103, 'max_depth': 6, 'min_child_samples': 92, 'learning_rate': 0.030657136738355066, 'subsample': 0.7072141689219315, 'colsample_bytree': 0.7177227040513482, 'reg_alpha': 0.5954920921876347, 'reg_lambda': 1.480453338764386}. Best is trial 19 with value: 0.11953482077458695.\n",
      "[I 2026-01-09 07:25:01,350] Trial 25 finished with value: 0.11969862567742447 and parameters: {'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 69, 'learning_rate': 0.032060029376786446, 'subsample': 0.6974944827535143, 'colsample_bytree': 0.6650396307077587, 'reg_alpha': 0.4605348895448373, 'reg_lambda': 1.3202123499607696}. Best is trial 19 with value: 0.11953482077458695.\n",
      "[I 2026-01-09 07:25:09,029] Trial 26 pruned. \n",
      "[I 2026-01-09 07:25:19,288] Trial 27 pruned. \n",
      "[I 2026-01-09 07:25:47,679] Trial 28 finished with value: 0.1196087711642076 and parameters: {'num_leaves': 79, 'max_depth': 6, 'min_child_samples': 78, 'learning_rate': 0.0312579362310523, 'subsample': 0.7660780143531127, 'colsample_bytree': 0.6542669586714234, 'reg_alpha': 0.6500113453111303, 'reg_lambda': 1.658438677721776}. Best is trial 19 with value: 0.11953482077458695.\n",
      "[I 2026-01-09 07:25:55,793] Trial 29 pruned. \n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:330: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2026-01-09 07:25:55,888] A new study created in memory with name: no-name-a2724f3b-0982-4a06-9beb-e418d22c11af\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 done: best_logMAE=0.119535\n",
      "[HPO-2STAGE] PHASE2 best_params={'num_leaves': 84, 'max_depth': 6, 'min_child_samples': 81, 'learning_rate': 0.030489907734239114, 'subsample': 0.7373480809994508, 'colsample_bytree': 0.6977671371137035, 'reg_alpha': 0.7013659436962031, 'reg_lambda': 1.363365061625741}\n",
      "\n",
      "[PIPELINE-LIGHT] HPO split=mid_city | cv=54265 ho=15471 | n_features=280\n",
      "\n",
      "[HPO-2STAGE] PHASE1 start: trials=20, folds=3, est=4000, es=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:26:18,784] Trial 0 finished with value: 0.14042470248964725 and parameters: {'num_leaves': 67, 'max_depth': 10, 'min_child_samples': 160, 'learning_rate': 0.08387926357773329, 'subsample': 0.696805592132731, 'colsample_bytree': 0.6967983561008608, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 13.39433470675048}. Best is trial 0 with value: 0.14042470248964725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=0 logMAE=0.140425 | OOF_MAPE=0.142806 | HO_MAPE=0.142731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:26:39,945] Trial 1 finished with value: 0.14227522076130514 and parameters: {'num_leaves': 89, 'max_depth': 8, 'min_child_samples': 53, 'learning_rate': 0.11729188669457949, 'subsample': 0.8997327922401265, 'colsample_bytree': 0.7137017332034828, 'reg_alpha': 0.18182496720710062, 'reg_lambda': 1.7322667470546256}. Best is trial 0 with value: 0.14042470248964725.\n",
      "[I 2026-01-09 07:27:15,047] Trial 2 finished with value: 0.13831968674556286 and parameters: {'num_leaves': 60, 'max_depth': 7, 'min_child_samples': 115, 'learning_rate': 0.056210622617823766, 'subsample': 0.8335558684167138, 'colsample_bytree': 0.6918481581956125, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 2.9967309097101573}. Best is trial 2 with value: 0.13831968674556286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=2 logMAE=0.138320 | OOF_MAPE=0.140713 | HO_MAPE=0.141371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:27:45,949] Trial 3 finished with value: 0.1393790284886747 and parameters: {'num_leaves': 75, 'max_depth': 9, 'min_child_samples': 80, 'learning_rate': 0.07628109945722504, 'subsample': 0.8277243706586127, 'colsample_bytree': 0.6639351238159993, 'reg_alpha': 0.6075448519014384, 'reg_lambda': 1.6666983286066417}. Best is trial 2 with value: 0.13831968674556286.\n",
      "[I 2026-01-09 07:28:04,051] Trial 4 finished with value: 0.14075281345668655 and parameters: {'num_leaves': 37, 'max_depth': 10, 'min_child_samples': 195, 'learning_rate': 0.1027557613304815, 'subsample': 0.7413841307520113, 'colsample_bytree': 0.6793016342019151, 'reg_alpha': 0.6842330265121569, 'reg_lambda': 3.738105868191796}. Best is trial 2 with value: 0.13831968674556286.\n",
      "[I 2026-01-09 07:28:18,381] Trial 5 finished with value: 0.14151304530009778 and parameters: {'num_leaves': 42, 'max_depth': 7, 'min_child_samples': 55, 'learning_rate': 0.11183883618709038, 'subsample': 0.7276339944800051, 'colsample_bytree': 0.8487566853061945, 'reg_alpha': 0.31171107608941095, 'reg_lambda': 4.749239763680407}. Best is trial 2 with value: 0.13831968674556286.\n",
      "[I 2026-01-09 07:28:35,672] Trial 6 finished with value: 0.14037098198814982 and parameters: {'num_leaves': 84, 'max_depth': 5, 'min_child_samples': 196, 'learning_rate': 0.0997619541025003, 'subsample': 0.9318496824692567, 'colsample_bytree': 0.9184482051282946, 'reg_alpha': 0.5978999788110851, 'reg_lambda': 15.826541904647563}. Best is trial 2 with value: 0.13831968674556286.\n",
      "[I 2026-01-09 07:28:58,397] Trial 7 finished with value: 0.13831379829923304 and parameters: {'num_leaves': 39, 'max_depth': 5, 'min_child_samples': 56, 'learning_rate': 0.05927972976869379, 'subsample': 0.7666031869068446, 'colsample_bytree': 0.7314047095321687, 'reg_alpha': 0.8287375091519293, 'reg_lambda': 2.9117010232427414}. Best is trial 7 with value: 0.13831379829923304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=7 logMAE=0.138314 | OOF_MAPE=0.140667 | HO_MAPE=0.142631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:29:17,595] Trial 8 finished with value: 0.14163109877152946 and parameters: {'num_leaves': 58, 'max_depth': 7, 'min_child_samples': 71, 'learning_rate': 0.10219772826786357, 'subsample': 0.6723651931039313, 'colsample_bytree': 0.9460660809801551, 'reg_alpha': 0.7722447692966574, 'reg_lambda': 1.8135730867783397}. Best is trial 7 with value: 0.13831379829923304.\n",
      "[I 2026-01-09 07:29:34,828] Trial 9 finished with value: 0.14025044585473176 and parameters: {'num_leaves': 31, 'max_depth': 9, 'min_child_samples': 156, 'learning_rate': 0.09561064512368886, 'subsample': 0.8813811040057837, 'colsample_bytree': 0.6722133955202271, 'reg_alpha': 0.3584657285442726, 'reg_lambda': 1.414976157494142}. Best is trial 7 with value: 0.13831379829923304.\n",
      "[I 2026-01-09 07:30:00,229] Trial 10 finished with value: 0.13823068424623144 and parameters: {'num_leaves': 47, 'max_depth': 5, 'min_child_samples': 55, 'learning_rate': 0.050540451698769064, 'subsample': 0.6537610918690696, 'colsample_bytree': 0.6742388213758379, 'reg_alpha': 0.855381558133683, 'reg_lambda': 1.4223069965263562}. Best is trial 10 with value: 0.13823068424623144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=10 logMAE=0.138231 | OOF_MAPE=0.140554 | HO_MAPE=0.143000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:30:29,964] Trial 11 finished with value: 0.13801642738784006 and parameters: {'num_leaves': 33, 'max_depth': 5, 'min_child_samples': 69, 'learning_rate': 0.05557330416752304, 'subsample': 0.7613062360755578, 'colsample_bytree': 0.7560461445705187, 'reg_alpha': 0.9009551686189577, 'reg_lambda': 3.1432862812561972}. Best is trial 11 with value: 0.13801642738784006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=11 logMAE=0.138016 | OOF_MAPE=0.140340 | HO_MAPE=0.142110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:30:51,520] Trial 12 finished with value: 0.1390054505492133 and parameters: {'num_leaves': 72, 'max_depth': 6, 'min_child_samples': 93, 'learning_rate': 0.06337841838276713, 'subsample': 0.6595652648832914, 'colsample_bytree': 0.667259855326242, 'reg_alpha': 0.6060559890252085, 'reg_lambda': 1.3034044501969555}. Best is trial 11 with value: 0.13801642738784006.\n",
      "[I 2026-01-09 07:31:18,313] Trial 13 finished with value: 0.13839556790930954 and parameters: {'num_leaves': 36, 'max_depth': 4, 'min_child_samples': 70, 'learning_rate': 0.03918997076277981, 'subsample': 0.6674808566760786, 'colsample_bytree': 0.699214081203387, 'reg_alpha': 0.3011815988734019, 'reg_lambda': 1.0794404011899306}. Best is trial 11 with value: 0.13801642738784006.\n",
      "[I 2026-01-09 07:31:34,115] Trial 14 finished with value: 0.1395772927152276 and parameters: {'num_leaves': 48, 'max_depth': 4, 'min_child_samples': 88, 'learning_rate': 0.0810853353539809, 'subsample': 0.6735701371522077, 'colsample_bytree': 0.6516082746603468, 'reg_alpha': 0.9570186586959591, 'reg_lambda': 1.5219890981184048}. Best is trial 11 with value: 0.13801642738784006.\n",
      "[I 2026-01-09 07:31:56,692] Trial 15 finished with value: 0.13870775554323506 and parameters: {'num_leaves': 35, 'max_depth': 4, 'min_child_samples': 68, 'learning_rate': 0.044791571461698716, 'subsample': 0.6532471997707581, 'colsample_bytree': 0.7850187627871998, 'reg_alpha': 0.9344949317631429, 'reg_lambda': 1.0166403265455597}. Best is trial 11 with value: 0.13801642738784006.\n",
      "[I 2026-01-09 07:32:00,283] Trial 16 pruned. \n",
      "[I 2026-01-09 07:32:28,416] Trial 17 finished with value: 0.1381308035653591 and parameters: {'num_leaves': 72, 'max_depth': 4, 'min_child_samples': 80, 'learning_rate': 0.04334061106387149, 'subsample': 0.6603387980300108, 'colsample_bytree': 0.7373789179683782, 'reg_alpha': 0.6621169948589065, 'reg_lambda': 6.982718496905917}. Best is trial 11 with value: 0.13801642738784006.\n",
      "[I 2026-01-09 07:32:50,991] Trial 18 finished with value: 0.1383686503532101 and parameters: {'num_leaves': 89, 'max_depth': 4, 'min_child_samples': 97, 'learning_rate': 0.058755855153391386, 'subsample': 0.7238681677486447, 'colsample_bytree': 0.741121883529873, 'reg_alpha': 0.7446436747858642, 'reg_lambda': 10.064616115598335}. Best is trial 11 with value: 0.13801642738784006.\n",
      "[I 2026-01-09 07:33:15,142] Trial 19 finished with value: 0.13856523730871864 and parameters: {'num_leaves': 49, 'max_depth': 4, 'min_child_samples': 100, 'learning_rate': 0.04830721800373485, 'subsample': 0.7343658583163133, 'colsample_bytree': 0.873148367834532, 'reg_alpha': 0.9125964420743963, 'reg_lambda': 7.690488612154579}. Best is trial 11 with value: 0.13801642738784006.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:330: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2026-01-09 07:33:15,145] A new study created in memory with name: no-name-120e33de-216d-4e91-a8d0-19fe369fe017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 done: best_logMAE=0.138016\n",
      "[HPO-2STAGE] PHASE1 best_params={'num_leaves': 33, 'max_depth': 5, 'min_child_samples': 69, 'learning_rate': 0.05557330416752304, 'subsample': 0.7613062360755578, 'colsample_bytree': 0.7560461445705187, 'reg_alpha': 0.9009551686189577, 'reg_lambda': 3.1432862812561972}\n",
      "\n",
      "[HPO-2STAGE] PHASE2 start: trials=30, folds=3, est=4000, es=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:33:39,827] Trial 0 finished with value: 0.13858722646053187 and parameters: {'num_leaves': 44, 'max_depth': 7, 'min_child_samples': 93, 'learning_rate': 0.0619443905262142, 'subsample': 0.685182542212202, 'colsample_bytree': 0.6842334758069287, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 4.48676223929695}. Best is trial 0 with value: 0.13858722646053187.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=0 logMAE=0.138587 | OOF_MAPE=0.140987 | HO_MAPE=0.141914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:34:01,805] Trial 1 finished with value: 0.13946340722015318 and parameters: {'num_leaves': 52, 'max_depth': 6, 'min_child_samples': 51, 'learning_rate': 0.0817543472790539, 'subsample': 0.8377176231387774, 'colsample_bytree': 0.6965984689244403, 'reg_alpha': 0.18182496720710062, 'reg_lambda': 1.3741703885495165}. Best is trial 0 with value: 0.13858722646053187.\n",
      "[I 2026-01-09 07:34:34,327] Trial 2 finished with value: 0.1379836207489079 and parameters: {'num_leaves': 41, 'max_depth': 6, 'min_child_samples': 75, 'learning_rate': 0.045539974180066736, 'subsample': 0.7879741563904369, 'colsample_bytree': 0.6806123554439912, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 1.886881391738385}. Best is trial 2 with value: 0.1379836207489079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=2 logMAE=0.137984 | OOF_MAPE=0.140340 | HO_MAPE=0.141397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:35:07,196] Trial 3 finished with value: 0.13789703371009535 and parameters: {'num_leaves': 46, 'max_depth': 7, 'min_child_samples': 61, 'learning_rate': 0.0574395271366542, 'subsample': 0.7835907716988612, 'colsample_bytree': 0.6601936855002647, 'reg_alpha': 0.6075448519014384, 'reg_lambda': 1.3438354090636417}. Best is trial 3 with value: 0.13789703371009535.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=3 logMAE=0.137897 | OOF_MAPE=0.140255 | HO_MAPE=0.141237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:35:28,031] Trial 4 finished with value: 0.13913055261764448 and parameters: {'num_leaves': 33, 'max_depth': 7, 'min_child_samples': 107, 'learning_rate': 0.07313604712914881, 'subsample': 0.7186910664134017, 'colsample_bytree': 0.671434444906416, 'reg_alpha': 0.6842330265121569, 'reg_lambda': 2.1442904429757697}. Best is trial 3 with value: 0.13789703371009535.\n",
      "[I 2026-01-09 07:35:32,812] Trial 5 pruned. \n",
      "[I 2026-01-09 07:35:37,847] Trial 6 pruned. \n",
      "[I 2026-01-09 07:36:06,038] Trial 7 finished with value: 0.13796428964484395 and parameters: {'num_leaves': 34, 'max_depth': 4, 'min_child_samples': 52, 'learning_rate': 0.047359612216743716, 'subsample': 0.7376475728326177, 'colsample_bytree': 0.7095483770484045, 'reg_alpha': 0.8287375091519293, 'reg_lambda': 1.855721030767088}. Best is trial 3 with value: 0.13789703371009535.\n",
      "[I 2026-01-09 07:36:14,687] Trial 8 pruned. \n",
      "[I 2026-01-09 07:36:22,438] Trial 9 pruned. \n",
      "[I 2026-01-09 07:36:59,283] Trial 10 finished with value: 0.13793109392414316 and parameters: {'num_leaves': 42, 'max_depth': 7, 'min_child_samples': 56, 'learning_rate': 0.05155632315662322, 'subsample': 0.8031702215449161, 'colsample_bytree': 0.6960768805976072, 'reg_alpha': 0.7364043002360449, 'reg_lambda': 2.9058435320955867}. Best is trial 3 with value: 0.13789703371009535.\n",
      "[I 2026-01-09 07:37:09,134] Trial 11 pruned. \n",
      "[I 2026-01-09 07:37:18,110] Trial 12 pruned. \n",
      "[I 2026-01-09 07:38:00,683] Trial 13 finished with value: 0.13736338234207454 and parameters: {'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 53, 'learning_rate': 0.04661537787337646, 'subsample': 0.7171205914088287, 'colsample_bytree': 0.6729958808162861, 'reg_alpha': 0.7319656558412722, 'reg_lambda': 2.3997837081065354}. Best is trial 13 with value: 0.13736338234207454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=13 logMAE=0.137363 | OOF_MAPE=0.139669 | HO_MAPE=0.140986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:38:51,825] Trial 14 finished with value: 0.1367896778292751 and parameters: {'num_leaves': 39, 'max_depth': 6, 'min_child_samples': 54, 'learning_rate': 0.0313651935682593, 'subsample': 0.6983900848067615, 'colsample_bytree': 0.6526130984393448, 'reg_alpha': 0.5683254849222301, 'reg_lambda': 2.7069261751102918}. Best is trial 14 with value: 0.1367896778292751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=14 logMAE=0.136790 | OOF_MAPE=0.138967 | HO_MAPE=0.141172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:39:15,331] Trial 15 pruned. \n",
      "[I 2026-01-09 07:39:22,496] Trial 16 pruned. \n",
      "[I 2026-01-09 07:39:29,246] Trial 17 pruned. \n",
      "[I 2026-01-09 07:40:22,476] Trial 18 finished with value: 0.13691227531703168 and parameters: {'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 52, 'learning_rate': 0.031290728093612705, 'subsample': 0.751353777349883, 'colsample_bytree': 0.7197220611498398, 'reg_alpha': 0.5914369476972747, 'reg_lambda': 2.3732106070802264}. Best is trial 14 with value: 0.1367896778292751.\n",
      "[I 2026-01-09 07:41:10,004] Trial 19 finished with value: 0.1367669355940985 and parameters: {'num_leaves': 31, 'max_depth': 6, 'min_child_samples': 61, 'learning_rate': 0.031184219138361842, 'subsample': 0.7396122849938691, 'colsample_bytree': 0.6595455497217406, 'reg_alpha': 0.7467028182925457, 'reg_lambda': 4.195068665331079}. Best is trial 19 with value: 0.1367669355940985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=19 logMAE=0.136767 | OOF_MAPE=0.139089 | HO_MAPE=0.142003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:42:00,697] Trial 20 finished with value: 0.1369847728731672 and parameters: {'num_leaves': 36, 'max_depth': 6, 'min_child_samples': 61, 'learning_rate': 0.030225263232843944, 'subsample': 0.6943154183395582, 'colsample_bytree': 0.7763094558769664, 'reg_alpha': 0.8504598317215939, 'reg_lambda': 4.722629339374298}. Best is trial 19 with value: 0.1367669355940985.\n",
      "[I 2026-01-09 07:42:46,445] Trial 21 finished with value: 0.13716250102674477 and parameters: {'num_leaves': 35, 'max_depth': 6, 'min_child_samples': 54, 'learning_rate': 0.03581332089690793, 'subsample': 0.7576306093716522, 'colsample_bytree': 0.6591374931404884, 'reg_alpha': 0.8774921379488253, 'reg_lambda': 5.418091926062006}. Best is trial 19 with value: 0.1367669355940985.\n",
      "[I 2026-01-09 07:43:41,022] Trial 22 finished with value: 0.13759845441251672 and parameters: {'num_leaves': 51, 'max_depth': 6, 'min_child_samples': 50, 'learning_rate': 0.03070940069454622, 'subsample': 0.8251967033584078, 'colsample_bytree': 0.7567420816010232, 'reg_alpha': 0.5192938224533878, 'reg_lambda': 1.6292622513742447}. Best is trial 19 with value: 0.1367669355940985.\n",
      "[I 2026-01-09 07:43:50,162] Trial 23 pruned. \n",
      "[I 2026-01-09 07:44:00,287] Trial 24 pruned. \n",
      "[I 2026-01-09 07:44:11,478] Trial 25 pruned. \n",
      "[I 2026-01-09 07:44:53,362] Trial 26 finished with value: 0.1373549491288689 and parameters: {'num_leaves': 36, 'max_depth': 6, 'min_child_samples': 89, 'learning_rate': 0.03214764339865071, 'subsample': 0.7352401139084876, 'colsample_bytree': 0.7120788010586825, 'reg_alpha': 0.5769014745447776, 'reg_lambda': 2.8133872104931728}. Best is trial 19 with value: 0.1367669355940985.\n",
      "[I 2026-01-09 07:45:24,019] Trial 27 pruned. \n",
      "[I 2026-01-09 07:46:15,623] Trial 28 finished with value: 0.13718414665552123 and parameters: {'num_leaves': 46, 'max_depth': 6, 'min_child_samples': 55, 'learning_rate': 0.03239544772715078, 'subsample': 0.7494917570694548, 'colsample_bytree': 0.8227630039051455, 'reg_alpha': 0.5426602581991579, 'reg_lambda': 2.7688788488827956}. Best is trial 19 with value: 0.1367669355940985.\n",
      "[I 2026-01-09 07:46:32,040] Trial 29 pruned. \n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:330: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2026-01-09 07:46:32,120] A new study created in memory with name: no-name-6d22d09a-792a-4ad2-b723-76d0d5bc158e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 done: best_logMAE=0.136767\n",
      "[HPO-2STAGE] PHASE2 best_params={'num_leaves': 31, 'max_depth': 6, 'min_child_samples': 61, 'learning_rate': 0.031184219138361842, 'subsample': 0.7396122849938691, 'colsample_bytree': 0.6595455497217406, 'reg_alpha': 0.7467028182925457, 'reg_lambda': 4.195068665331079}\n",
      "\n",
      "[PIPELINE-LIGHT] HPO split=other | cv=62062 ho=20659 | n_features=279\n",
      "\n",
      "[HPO-2STAGE] PHASE1 start: trials=20, folds=3, est=4000, es=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:46:58,914] Trial 0 finished with value: 0.1508174373792283 and parameters: {'num_leaves': 67, 'max_depth': 10, 'min_child_samples': 160, 'learning_rate': 0.08387926357773329, 'subsample': 0.696805592132731, 'colsample_bytree': 0.6967983561008608, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 13.39433470675048}. Best is trial 0 with value: 0.1508174373792283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=0 logMAE=0.150817 | OOF_MAPE=0.153769 | HO_MAPE=0.135970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:47:26,495] Trial 1 finished with value: 0.15152501623395384 and parameters: {'num_leaves': 89, 'max_depth': 8, 'min_child_samples': 53, 'learning_rate': 0.11729188669457949, 'subsample': 0.8997327922401265, 'colsample_bytree': 0.7137017332034828, 'reg_alpha': 0.18182496720710062, 'reg_lambda': 1.7322667470546256}. Best is trial 0 with value: 0.1508174373792283.\n",
      "[I 2026-01-09 07:47:57,677] Trial 2 finished with value: 0.14887687154337725 and parameters: {'num_leaves': 60, 'max_depth': 7, 'min_child_samples': 115, 'learning_rate': 0.056210622617823766, 'subsample': 0.8335558684167138, 'colsample_bytree': 0.6918481581956125, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 2.9967309097101573}. Best is trial 2 with value: 0.14887687154337725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=2 logMAE=0.148877 | OOF_MAPE=0.151909 | HO_MAPE=0.135995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:48:31,526] Trial 3 finished with value: 0.14936170127091022 and parameters: {'num_leaves': 75, 'max_depth': 9, 'min_child_samples': 80, 'learning_rate': 0.07628109945722504, 'subsample': 0.8277243706586127, 'colsample_bytree': 0.6639351238159993, 'reg_alpha': 0.6075448519014384, 'reg_lambda': 1.6666983286066417}. Best is trial 2 with value: 0.14887687154337725.\n",
      "[I 2026-01-09 07:48:48,245] Trial 4 finished with value: 0.15121467508339018 and parameters: {'num_leaves': 37, 'max_depth': 10, 'min_child_samples': 195, 'learning_rate': 0.1027557613304815, 'subsample': 0.7413841307520113, 'colsample_bytree': 0.6793016342019151, 'reg_alpha': 0.6842330265121569, 'reg_lambda': 3.738105868191796}. Best is trial 2 with value: 0.14887687154337725.\n",
      "[I 2026-01-09 07:49:05,581] Trial 5 finished with value: 0.15174275958743735 and parameters: {'num_leaves': 42, 'max_depth': 7, 'min_child_samples': 55, 'learning_rate': 0.11183883618709038, 'subsample': 0.7276339944800051, 'colsample_bytree': 0.8487566853061945, 'reg_alpha': 0.31171107608941095, 'reg_lambda': 4.749239763680407}. Best is trial 2 with value: 0.14887687154337725.\n",
      "[I 2026-01-09 07:49:20,519] Trial 6 finished with value: 0.15164240428402423 and parameters: {'num_leaves': 84, 'max_depth': 5, 'min_child_samples': 196, 'learning_rate': 0.0997619541025003, 'subsample': 0.9318496824692567, 'colsample_bytree': 0.9184482051282946, 'reg_alpha': 0.5978999788110851, 'reg_lambda': 15.826541904647563}. Best is trial 2 with value: 0.14887687154337725.\n",
      "[I 2026-01-09 07:49:47,788] Trial 7 finished with value: 0.14919887146317978 and parameters: {'num_leaves': 39, 'max_depth': 5, 'min_child_samples': 56, 'learning_rate': 0.05927972976869379, 'subsample': 0.7666031869068446, 'colsample_bytree': 0.7314047095321687, 'reg_alpha': 0.8287375091519293, 'reg_lambda': 2.9117010232427414}. Best is trial 2 with value: 0.14887687154337725.\n",
      "[I 2026-01-09 07:50:07,306] Trial 8 finished with value: 0.15169594868070638 and parameters: {'num_leaves': 58, 'max_depth': 7, 'min_child_samples': 71, 'learning_rate': 0.10219772826786357, 'subsample': 0.6723651931039313, 'colsample_bytree': 0.9460660809801551, 'reg_alpha': 0.7722447692966574, 'reg_lambda': 1.8135730867783397}. Best is trial 2 with value: 0.14887687154337725.\n",
      "[I 2026-01-09 07:50:25,091] Trial 9 finished with value: 0.1508579553744831 and parameters: {'num_leaves': 31, 'max_depth': 9, 'min_child_samples': 156, 'learning_rate': 0.09561064512368886, 'subsample': 0.8813811040057837, 'colsample_bytree': 0.6722133955202271, 'reg_alpha': 0.3584657285442726, 'reg_lambda': 1.414976157494142}. Best is trial 2 with value: 0.14887687154337725.\n",
      "[I 2026-01-09 07:50:59,716] Trial 10 finished with value: 0.14855644096905782 and parameters: {'num_leaves': 58, 'max_depth': 5, 'min_child_samples': 133, 'learning_rate': 0.0407173518725638, 'subsample': 0.832730728641749, 'colsample_bytree': 0.6561093247730276, 'reg_alpha': 0.45991534700734943, 'reg_lambda': 7.43656120888366}. Best is trial 10 with value: 0.14855644096905782.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=10 logMAE=0.148556 | OOF_MAPE=0.151679 | HO_MAPE=0.137738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:51:33,573] Trial 11 finished with value: 0.14875846263688552 and parameters: {'num_leaves': 69, 'max_depth': 6, 'min_child_samples': 154, 'learning_rate': 0.05666416481000376, 'subsample': 0.8820560226149139, 'colsample_bytree': 0.682247992506388, 'reg_alpha': 0.5788984085155222, 'reg_lambda': 6.045757551325803}. Best is trial 10 with value: 0.14855644096905782.\n",
      "[I 2026-01-09 07:52:10,415] Trial 12 finished with value: 0.14891318524885708 and parameters: {'num_leaves': 69, 'max_depth': 5, 'min_child_samples': 184, 'learning_rate': 0.0412126397061572, 'subsample': 0.9083096987339445, 'colsample_bytree': 0.7135523370935994, 'reg_alpha': 0.3607358635444904, 'reg_lambda': 5.378494987602776}. Best is trial 10 with value: 0.14855644096905782.\n",
      "[I 2026-01-09 07:52:39,122] Trial 13 finished with value: 0.14889171279318592 and parameters: {'num_leaves': 54, 'max_depth': 7, 'min_child_samples': 160, 'learning_rate': 0.05407687149682746, 'subsample': 0.7656210019810323, 'colsample_bytree': 0.6783524447041125, 'reg_alpha': 0.8010310061481591, 'reg_lambda': 6.298812348722103}. Best is trial 10 with value: 0.14855644096905782.\n",
      "[I 2026-01-09 07:53:17,295] Trial 14 finished with value: 0.1483537242452704 and parameters: {'num_leaves': 82, 'max_depth': 5, 'min_child_samples': 105, 'learning_rate': 0.04280758615653949, 'subsample': 0.813173685821792, 'colsample_bytree': 0.7275010992069361, 'reg_alpha': 0.15560915150688848, 'reg_lambda': 19.744904505461903}. Best is trial 14 with value: 0.1483537242452704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 NEW BEST: trial=14 logMAE=0.148354 | OOF_MAPE=0.151355 | HO_MAPE=0.137134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:54:00,199] Trial 15 finished with value: 0.14852543719919084 and parameters: {'num_leaves': 100, 'max_depth': 7, 'min_child_samples': 128, 'learning_rate': 0.04468893529305789, 'subsample': 0.814530575776954, 'colsample_bytree': 0.8213575256131221, 'reg_alpha': 0.22778702059031886, 'reg_lambda': 16.467079136820082}. Best is trial 14 with value: 0.1483537242452704.\n",
      "[I 2026-01-09 07:54:07,979] Trial 16 pruned. \n",
      "[I 2026-01-09 07:54:17,121] Trial 17 pruned. \n",
      "[I 2026-01-09 07:54:51,913] Trial 18 finished with value: 0.1490940116117865 and parameters: {'num_leaves': 108, 'max_depth': 8, 'min_child_samples': 142, 'learning_rate': 0.05732949133811417, 'subsample': 0.8235348654297622, 'colsample_bytree': 0.8162562047786919, 'reg_alpha': 0.44144257021674516, 'reg_lambda': 9.275102715669616}. Best is trial 14 with value: 0.1483537242452704.\n",
      "[I 2026-01-09 07:55:28,921] Trial 19 finished with value: 0.14869899082610957 and parameters: {'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 93, 'learning_rate': 0.04236659353370548, 'subsample': 0.8114923408914843, 'colsample_bytree': 0.7547258086765094, 'reg_alpha': 0.5958964472407376, 'reg_lambda': 19.63293225706654}. Best is trial 14 with value: 0.1483537242452704.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:330: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2026-01-09 07:55:28,924] A new study created in memory with name: no-name-8ee1cfde-b2ec-4d35-bfa2-4688526bcbff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE1 done: best_logMAE=0.148354\n",
      "[HPO-2STAGE] PHASE1 best_params={'num_leaves': 82, 'max_depth': 5, 'min_child_samples': 105, 'learning_rate': 0.04280758615653949, 'subsample': 0.813173685821792, 'colsample_bytree': 0.7275010992069361, 'reg_alpha': 0.15560915150688848, 'reg_lambda': 19.744904505461903}\n",
      "\n",
      "[HPO-2STAGE] PHASE2 start: trials=30, folds=3, est=4000, es=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:56:03,632] Trial 0 finished with value: 0.14878881157624735 and parameters: {'num_leaves': 74, 'max_depth': 7, 'min_child_samples': 124, 'learning_rate': 0.050480932435000875, 'subsample': 0.7292587088201674, 'colsample_bytree': 0.6791126745485414, 'reg_alpha': 0.018076683211897402, 'reg_lambda': 16.09700479149139}. Best is trial 0 with value: 0.14878881157624735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=0 logMAE=0.148789 | OOF_MAPE=0.151833 | HO_MAPE=0.136119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:56:33,250] Trial 1 finished with value: 0.14909871077363027 and parameters: {'num_leaves': 89, 'max_depth': 6, 'min_child_samples': 66, 'learning_rate': 0.06318195377589175, 'subsample': 0.8942737680849946, 'colsample_bytree': 0.68962805494565, 'reg_alpha': 0.056587257739729495, 'reg_lambda': 5.317429698234924}. Best is trial 0 with value: 0.14878881157624735.\n",
      "[I 2026-01-09 07:57:13,572] Trial 2 finished with value: 0.1483564295624424 and parameters: {'num_leaves': 69, 'max_depth': 6, 'min_child_samples': 99, 'learning_rate': 0.03996335055954264, 'subsample': 0.8404604350231621, 'colsample_bytree': 0.6760332180766994, 'reg_alpha': 0.0909207617516869, 'reg_lambda': 7.15489763017556}. Best is trial 2 with value: 0.1483564295624424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=2 logMAE=0.148356 | OOF_MAPE=0.151280 | HO_MAPE=0.136238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:57:54,499] Trial 3 finished with value: 0.14814280752615433 and parameters: {'num_leaves': 79, 'max_depth': 7, 'min_child_samples': 81, 'learning_rate': 0.047592669388167225, 'subsample': 0.8357184144973455, 'colsample_bytree': 0.6586688669912778, 'reg_alpha': 0.1890790778135221, 'reg_lambda': 5.2074720257072}. Best is trial 3 with value: 0.14814280752615433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=3 logMAE=0.148143 | OOF_MAPE=0.151012 | HO_MAPE=0.134946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 07:58:26,000] Trial 4 finished with value: 0.1488341883586289 and parameters: {'num_leaves': 54, 'max_depth': 7, 'min_child_samples': 143, 'learning_rate': 0.05765638824882635, 'subsample': 0.7655088033777566, 'colsample_bytree': 0.6682281817425864, 'reg_alpha': 0.21294584137709413, 'reg_lambda': 8.064774999571034}. Best is trial 3 with value: 0.14814280752615433.\n",
      "[I 2026-01-09 07:58:32,239] Trial 5 pruned. \n",
      "[I 2026-01-09 07:58:41,258] Trial 6 pruned. \n",
      "[I 2026-01-09 07:59:02,561] Trial 7 pruned. \n",
      "[I 2026-01-09 07:59:11,706] Trial 8 pruned. \n",
      "[I 2026-01-09 07:59:44,847] Trial 9 finished with value: 0.14838526496947235 and parameters: {'num_leaves': 50, 'max_depth': 7, 'min_child_samples': 122, 'learning_rate': 0.05494034069074452, 'subsample': 0.8793506581224216, 'colsample_bytree': 0.6638186767288285, 'reg_alpha': 0.11156109572614575, 'reg_lambda': 4.765626427965508}. Best is trial 3 with value: 0.14814280752615433.\n",
      "[I 2026-01-09 07:59:56,996] Trial 10 pruned. \n",
      "[I 2026-01-09 08:00:32,566] Trial 11 finished with value: 0.14817351778897023 and parameters: {'num_leaves': 103, 'max_depth': 6, 'min_child_samples': 67, 'learning_rate': 0.046821894107701476, 'subsample': 0.7707167829268505, 'colsample_bytree': 0.6594474160246246, 'reg_alpha': 0.2078094879761307, 'reg_lambda': 5.425363467215403}. Best is trial 3 with value: 0.14814280752615433.\n",
      "[I 2026-01-09 08:00:44,867] Trial 12 pruned. \n",
      "[I 2026-01-09 08:00:55,244] Trial 13 pruned. \n",
      "[I 2026-01-09 08:01:37,668] Trial 14 pruned. \n",
      "[I 2026-01-09 08:02:24,458] Trial 15 finished with value: 0.14776415286920286 and parameters: {'num_leaves': 53, 'max_depth': 7, 'min_child_samples': 70, 'learning_rate': 0.04229149497716541, 'subsample': 0.7330376771428743, 'colsample_bytree': 0.6617178290164912, 'reg_alpha': 0.20961203639427098, 'reg_lambda': 6.527687363186128}. Best is trial 15 with value: 0.14776415286920286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=15 logMAE=0.147764 | OOF_MAPE=0.150730 | HO_MAPE=0.134859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 08:03:06,273] Trial 16 finished with value: 0.1482046121294213 and parameters: {'num_leaves': 53, 'max_depth': 7, 'min_child_samples': 71, 'learning_rate': 0.04554415834661815, 'subsample': 0.762130504946761, 'colsample_bytree': 0.6551587635603401, 'reg_alpha': 0.14351199479673765, 'reg_lambda': 7.173320002687351}. Best is trial 15 with value: 0.14776415286920286.\n",
      "[I 2026-01-09 08:03:16,870] Trial 17 pruned. \n",
      "[I 2026-01-09 08:03:32,002] Trial 18 pruned. \n",
      "[I 2026-01-09 08:04:18,740] Trial 19 finished with value: 0.14798750346264303 and parameters: {'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 70, 'learning_rate': 0.03841981574677708, 'subsample': 0.751441557898022, 'colsample_bytree': 0.6631606639682249, 'reg_alpha': 0.2831563285055117, 'reg_lambda': 15.420905059002145}. Best is trial 15 with value: 0.14776415286920286.\n",
      "[I 2026-01-09 08:04:41,507] Trial 20 pruned. \n",
      "[I 2026-01-09 08:05:25,452] Trial 21 finished with value: 0.14812095719816112 and parameters: {'num_leaves': 72, 'max_depth': 7, 'min_child_samples': 77, 'learning_rate': 0.03760509991175713, 'subsample': 0.7134421580965769, 'colsample_bytree': 0.6797772513967222, 'reg_alpha': 0.23044989123540346, 'reg_lambda': 14.348286284317613}. Best is trial 15 with value: 0.14776415286920286.\n",
      "[I 2026-01-09 08:06:14,515] Trial 22 finished with value: 0.14775611098617594 and parameters: {'num_leaves': 89, 'max_depth': 7, 'min_child_samples': 88, 'learning_rate': 0.03774671099802793, 'subsample': 0.7403143621814818, 'colsample_bytree': 0.6806785927458112, 'reg_alpha': 0.24015452133865717, 'reg_lambda': 13.48337661307892}. Best is trial 22 with value: 0.14775611098617594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 NEW BEST: trial=22 logMAE=0.147756 | OOF_MAPE=0.150670 | HO_MAPE=0.134966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 08:06:22,550] Trial 23 pruned. \n",
      "[I 2026-01-09 08:06:33,453] Trial 24 pruned. \n",
      "[I 2026-01-09 08:07:27,113] Trial 25 finished with value: 0.14780582252843913 and parameters: {'num_leaves': 95, 'max_depth': 6, 'min_child_samples': 93, 'learning_rate': 0.03166704111177063, 'subsample': 0.77373533445806, 'colsample_bytree': 0.6884359759708392, 'reg_alpha': 0.1905151102376661, 'reg_lambda': 12.056284954077169}. Best is trial 22 with value: 0.14775611098617594.\n",
      "[I 2026-01-09 08:08:05,174] Trial 26 pruned. \n",
      "[I 2026-01-09 08:08:48,003] Trial 27 finished with value: 0.1478228236854508 and parameters: {'num_leaves': 86, 'max_depth': 5, 'min_child_samples': 90, 'learning_rate': 0.034679053242352646, 'subsample': 0.733682953801987, 'colsample_bytree': 0.6780575459630569, 'reg_alpha': 0.24725880112729645, 'reg_lambda': 12.835379432609756}. Best is trial 22 with value: 0.14775611098617594.\n",
      "[I 2026-01-09 08:09:38,393] Trial 28 finished with value: 0.14784186021013446 and parameters: {'num_leaves': 100, 'max_depth': 7, 'min_child_samples': 103, 'learning_rate': 0.033062235055853456, 'subsample': 0.7035912532057829, 'colsample_bytree': 0.661233758359797, 'reg_alpha': 0.1822286895422565, 'reg_lambda': 13.879315719802616}. Best is trial 22 with value: 0.14775611098617594.\n",
      "[I 2026-01-09 08:10:11,661] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HPO-2STAGE] PHASE2 done: best_logMAE=0.147756\n",
      "[HPO-2STAGE] PHASE2 best_params={'num_leaves': 89, 'max_depth': 7, 'min_child_samples': 88, 'learning_rate': 0.03774671099802793, 'subsample': 0.7403143621814818, 'colsample_bytree': 0.6806785927458112, 'reg_alpha': 0.24015452133865717, 'reg_lambda': 13.48337661307892}\n",
      "\n",
      "[PIPELINE-LIGHT] Step4: Final training (no tuned re-CV)\n",
      "[PIPELINE-LIGHT] Final training done.\n",
      "\n",
      "================================================================================\n",
      "[PIPELINE-LIGHT] DONE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "all_bundles = {}\n",
    "\n",
    "for target_model in property_types:\n",
    "    print('\\n' + '#' * 100)\n",
    "    print(f'[RUN] target_model={target_model} | alg={alg}')\n",
    "    print('#' * 100)\n",
    "\n",
    "    train_df, fe_cols, cat_cols, idx_dict = prepare_training_inputs(\n",
    "        target_model=target_model,\n",
    "        alg=alg,\n",
    "    )\n",
    "\n",
    "    bundle = train_with_fs_and_hpo_by_separate_light(\n",
    "        train_df=train_df,\n",
    "        base_cols=fe_cols,\n",
    "        cat_cols=cat_cols,\n",
    "        target_col=target_col,\n",
    "        year_col=year_col,\n",
    "        property_type=target_model,\n",
    "        alg=alg,\n",
    "        idx_dict=idx_dict,\n",
    "        base_params=BASE_PARAMS_BY_MODEL,\n",
    "\n",
    "        # TE\n",
    "        te_smoothing=50.0,\n",
    "        te_min_samples_leaf=1,\n",
    "\n",
    "        # FS\n",
    "        fi_drop_threshold=1.0,\n",
    "        fi_keep_topk=None,\n",
    "\n",
    "        # HPO(two-stage)\n",
    "        n_trials_phase1=20,\n",
    "        n_trials_phase2=30,\n",
    "        hpo_n_splits=3,\n",
    "        hpo_n_estimators=4000,\n",
    "        es_rounds=30,\n",
    "\n",
    "        ho_year=2022,\n",
    "        cv_year_max=2021,\n",
    "    )\n",
    "\n",
    "    all_bundles[(target_model, alg)] = bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad1d40",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5995ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_bundle_by_split(\n",
    "    models: dict[str, object],\n",
    "    fe_cols: dict[str, list[str]],\n",
    "    cat_cols: dict[str, list[str]] | None,\n",
    "    save_path: str,\n",
    "    meta: dict | None = None,\n",
    "):\n",
    "    bundle = {\n",
    "        'models': models,\n",
    "        'fe_cols': fe_cols,\n",
    "        'cat_cols': cat_cols,\n",
    "        'meta': meta or {},\n",
    "    }\n",
    "    Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(bundle, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "241251db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_models_from_all_bundles(\n",
    "    all_bundles: dict,\n",
    "    model_dir: str,\n",
    "    training_ver: int,\n",
    "):\n",
    "    for (property_type, alg), bundle in all_bundles.items():\n",
    "        # bundle 内のキー差を吸収\n",
    "        models = bundle['final_models_by_split']\n",
    "        fe_cols = bundle['reduced_cols_by_split']\n",
    "        cat_cols = bundle['cat_cols_by_split']\n",
    "\n",
    "        if models is None or fe_cols is None:\n",
    "            raise KeyError(f'Cannot find models/fe_cols in bundle for {property_type},{alg}. keys={list(bundle.keys())}')\n",
    "\n",
    "        # fe_cols も dict である想定（違う場合は dict 化）\n",
    "        if not isinstance(fe_cols, dict):\n",
    "            fe_cols = {k: list(fe_cols) for k in models.keys()}\n",
    "\n",
    "        save_path = f'{model_dir}/model_{property_type}_{alg}_v{training_ver}.pkl'\n",
    "        meta = {\n",
    "            'property_type': property_type,\n",
    "            'alg': alg,\n",
    "            'create_tbl_ver': create_tbl_ver,\n",
    "            'training_ver': training_ver,\n",
    "        }\n",
    "\n",
    "        save_model_bundle_by_split(\n",
    "            models=models,\n",
    "            fe_cols=fe_cols,\n",
    "            cat_cols=cat_cols,\n",
    "            save_path=save_path,\n",
    "            meta=meta,\n",
    "        )\n",
    "\n",
    "        print(f'[SAVED] {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8a5c065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] ../output/model/model_residential_lgb_v8.pkl\n"
     ]
    }
   ],
   "source": [
    "export_models_from_all_bundles(\n",
    "    all_bundles=all_bundles,\n",
    "    model_dir=model_path.rstrip('/'),\n",
    "    training_ver=training_ver,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1513e",
   "metadata": {},
   "source": [
    "## 特徴量重要度・oof結果の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8d49dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _as_array(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (pd.Series, pd.Index)):\n",
    "        return x.to_numpy()\n",
    "    return np.asarray(x)\n",
    "\n",
    "\n",
    "def _collect_pred_series_try_index_then_idx_keys(\n",
    "    cv_out: dict,\n",
    "    pred_key: str,\n",
    "    train_index: pd.Index,\n",
    "    idx_key_for_oof: str = 'idx_cv',\n",
    "    idx_key_for_ho: str = 'idx_ho',\n",
    "    strict: bool = False,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    1) pred が pd.Series なら、その index で train_index にアラインして埋める\n",
    "    2) intersection が小さすぎる場合は、idx_cv/idx_ho を使って埋める（フォールバック）\n",
    "    \"\"\"\n",
    "    # --- まず Series index を信用して埋める（house 系はこれで通る）\n",
    "    out = pd.Series(np.nan, index=train_index, dtype='float32')\n",
    "\n",
    "    any_written = 0\n",
    "    total_pred = 0\n",
    "\n",
    "    for split_key, res in cv_out.items():\n",
    "        if res is None or pred_key not in res:\n",
    "            continue\n",
    "        pred = res.get(pred_key, None)\n",
    "        if not isinstance(pred, pd.Series):\n",
    "            continue\n",
    "\n",
    "        total_pred += len(pred)\n",
    "        inter = train_index.intersection(pred.index)\n",
    "        if len(inter) == 0:\n",
    "            continue\n",
    "\n",
    "        out.loc[inter] = pred.loc[inter].astype('float32')\n",
    "        any_written += len(inter)\n",
    "\n",
    "    # --- そこそこ埋まっているなら、これで返す\n",
    "    # 目安: 交差が 1% もない場合は、別体系の可能性が高いので idx_key フォールバック\n",
    "    if total_pred > 0:\n",
    "        fill_ratio = any_written / max(total_pred, 1)\n",
    "        if fill_ratio >= 0.01:\n",
    "            return out\n",
    "\n",
    "    # --- フォールバック: idx_cv/idx_ho を使って埋める（residential 対策）\n",
    "    out2 = pd.Series(np.nan, index=train_index, dtype='float32')\n",
    "\n",
    "    if pred_key.startswith('oof'):\n",
    "        idx_key = idx_key_for_oof\n",
    "    elif pred_key.startswith('ho'):\n",
    "        idx_key = idx_key_for_ho\n",
    "    else:\n",
    "        raise ValueError(f'pred_key must start with oof/ho: {pred_key}')\n",
    "\n",
    "    for split_key, res in cv_out.items():\n",
    "        if res is None:\n",
    "            continue\n",
    "        pred = res.get(pred_key, None)\n",
    "        idx = res.get(idx_key, None)\n",
    "\n",
    "        if pred is None or idx is None:\n",
    "            if strict:\n",
    "                raise ValueError(f'{split_key}: missing {pred_key} or {idx_key}')\n",
    "            continue\n",
    "\n",
    "        pred_arr = _as_array(pred)\n",
    "        idx_arr = _as_array(idx)\n",
    "\n",
    "        if pred_arr is None or idx_arr is None:\n",
    "            continue\n",
    "        if len(pred_arr) != len(idx_arr):\n",
    "            msg = f'{split_key}: len(pred)={len(pred_arr)} != len({idx_key})={len(idx_arr)}'\n",
    "            if strict:\n",
    "                raise ValueError(msg)\n",
    "            print(f'[WARN] {msg}')\n",
    "            continue\n",
    "\n",
    "        idx_idx = pd.Index(idx_arr)\n",
    "\n",
    "        # (A) idx_arr が train_index のラベルとして存在する場合\n",
    "        inter = train_index.intersection(idx_idx)\n",
    "        if len(inter) > 0:\n",
    "            m = pd.Series(pred_arr, index=idx_idx)\n",
    "            out2.loc[inter] = m.loc[inter].astype('float32')\n",
    "            continue\n",
    "\n",
    "        # (B) 位置 (iloc) として扱える場合\n",
    "        if np.issubdtype(idx_arr.dtype, np.integer):\n",
    "            if idx_arr.min() >= 0 and idx_arr.max() < len(train_index):\n",
    "                out2.iloc[idx_arr] = pred_arr.astype('float32')\n",
    "                continue\n",
    "\n",
    "        msg = f'{split_key}: {idx_key} not alignable to train_index'\n",
    "        if strict:\n",
    "            raise ValueError(msg)\n",
    "        print(f'[WARN] {msg}')\n",
    "\n",
    "    return out2\n",
    "\n",
    "\n",
    "def export_cv_outputs_for_each_property_type(\n",
    "    all_bundles: dict,\n",
    "    property_types: list[str],\n",
    "    alg: str,\n",
    "    prepare_training_inputs: Callable[..., tuple[pd.DataFrame, list[str], list[str], dict]],\n",
    "    oof_path: str,\n",
    "    fi_path: str,\n",
    "    training_ver: int,\n",
    "    include_feature_cols: bool = True,\n",
    "    include_exp_preds: bool = True,\n",
    "    fi_agg_how: str = 'mean',\n",
    "    feature_col: str = 'feature',\n",
    "    importance_col: str = 'importance',\n",
    "    debug: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    target_model ごとに prepare_training_inputs() で train_df を作り、その train_df に対して\n",
    "    (target_model, alg) の bundle を使って予測/FI を出力する。\n",
    "\n",
    "    これにより「bundle の index 体系」と「train_df の index 体系」を揃えられる。\n",
    "    \"\"\"\n",
    "    os.makedirs(oof_path, exist_ok=True)\n",
    "    os.makedirs(fi_path, exist_ok=True)\n",
    "\n",
    "    for target_model in property_types:\n",
    "        key = (target_model, alg)\n",
    "        print('\\n' + '#' * 100)\n",
    "        print(f'[RUN] target_model={target_model} | alg={alg}')\n",
    "        print('#' * 100)\n",
    "\n",
    "        if key not in all_bundles:\n",
    "            print(f'[SKIP] bundle not found: {key}')\n",
    "            continue\n",
    "\n",
    "        bundle = all_bundles[key]\n",
    "        if 'cv_fixed' not in bundle or 'results_by_split' not in bundle['cv_fixed']:\n",
    "            print(f'[SKIP] no cv_fixed/results_by_split in bundle: {key}')\n",
    "            continue\n",
    "\n",
    "        # target_model ごとに train_df を作る（ここが重要）\n",
    "        train_df, fe_cols, cat_cols, idx_dict = prepare_training_inputs(\n",
    "            target_model=target_model,\n",
    "            alg=alg,\n",
    "        )\n",
    "\n",
    "        cv_out = bundle['cv_fixed']['results_by_split']\n",
    "        prefix = f'{target_model}_{alg}_v{training_ver}'\n",
    "\n",
    "        # =========================\n",
    "        # 予測: split横断で集約 → train_dfへ結合\n",
    "        # =========================\n",
    "        oof_pred_log = _collect_pred_series_try_index_then_idx_keys(cv_out, 'oof_pred_log', train_df.index)\n",
    "        ho_pred_log = _collect_pred_series_try_index_then_idx_keys(cv_out, 'ho_pred_log', train_df.index)\n",
    "\n",
    "        col_oof_log = f'{target_model}_{alg}_oof_pred_log'\n",
    "        col_ho_log = f'{target_model}_{alg}_ho_pred_log'\n",
    "\n",
    "        out_df = train_df.copy()\n",
    "        out_df[col_oof_log] = oof_pred_log\n",
    "        out_df[col_ho_log] = ho_pred_log\n",
    "\n",
    "        pred_cols = [col_oof_log, col_ho_log]\n",
    "\n",
    "        if include_exp_preds:\n",
    "            col_oof = f'{target_model}_{alg}_oof_pred'\n",
    "            col_ho = f'{target_model}_{alg}_ho_pred'\n",
    "            out_df[col_oof] = np.exp(out_df[col_oof_log])\n",
    "            out_df[col_ho] = np.exp(out_df[col_ho_log])\n",
    "            pred_cols += [col_oof, col_ho]\n",
    "\n",
    "        if include_feature_cols:\n",
    "            fe_cols_use = [c for c in fe_cols if c in out_df.columns]\n",
    "            keep_cols = list(dict.fromkeys(fe_cols_use + pred_cols + [target_col]))\n",
    "            out_df = out_df.loc[:, keep_cols]\n",
    "\n",
    "        if debug:\n",
    "            nn_oof = int(out_df[col_oof_log].notna().sum())\n",
    "            nn_ho = int(out_df[col_ho_log].notna().sum())\n",
    "            print(f'  pred filled: oof={nn_oof}/{len(out_df)} ho={nn_ho}/{len(out_df)}')\n",
    "\n",
    "        out_df.to_csv(f'{oof_path}/train_with_pred_{prefix}.csv', index=False)\n",
    "\n",
    "        # =========================\n",
    "        # FI: split内集約 + 全体stats\n",
    "        # =========================\n",
    "        fi_all_list: list[pd.DataFrame] = []\n",
    "        for split_key, res in cv_out.items():\n",
    "            fi_raw = res.get('fi')\n",
    "            if fi_raw is None or len(fi_raw) == 0:\n",
    "                continue\n",
    "\n",
    "            fi_agg = (\n",
    "                fi_raw.groupby(feature_col, as_index=False)[importance_col]\n",
    "                .agg(fi_agg_how)\n",
    "                .sort_values(importance_col, ascending=False)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "            fi_agg.to_csv(\n",
    "                f'{fi_path}/fi_{target_model}_{alg}_{split_key}_v{training_ver}.csv',\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            tmp = fi_agg.copy()\n",
    "            tmp['split'] = split_key\n",
    "            fi_all_list.append(tmp)\n",
    "\n",
    "        if fi_all_list:\n",
    "            fi_all = pd.concat(fi_all_list, axis=0, ignore_index=True)\n",
    "            fi_stats = (\n",
    "                fi_all.groupby(feature_col)[importance_col]\n",
    "                .agg(['mean', 'std', 'count'])\n",
    "                .reset_index()\n",
    "                .sort_values('mean', ascending=False)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            fi_stats['cv'] = fi_stats['std'] / fi_stats['mean'].replace(0, np.nan)\n",
    "            fi_stats.to_csv(\n",
    "                f'{fi_path}/fi_{target_model}_{alg}_ALL_v{training_ver}_stats.csv',\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "        print(f'[EXPORTED] {prefix}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4960ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################################\n",
      "[RUN] target_model=residential | alg=lgb\n",
      "####################################################################################################\n",
      "  pred filled: oof=147954/195154 ho=47200/195154\n",
      "[EXPORTED] residential_lgb_v8\n"
     ]
    }
   ],
   "source": [
    "export_cv_outputs_for_each_property_type(\n",
    "    all_bundles=all_bundles,\n",
    "    property_types=property_types,\n",
    "    alg=alg,\n",
    "    prepare_training_inputs=prepare_training_inputs,\n",
    "    oof_path=oof_path,\n",
    "    fi_path=fi_path,\n",
    "    training_ver=training_ver,\n",
    "    include_feature_cols=True,\n",
    "    include_exp_preds=True,\n",
    "    fi_agg_how='mean',\n",
    "    debug=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
