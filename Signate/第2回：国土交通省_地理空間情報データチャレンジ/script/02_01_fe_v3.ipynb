{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ed3091",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7375f2",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b518e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの取り扱いに関するライブラリ\n",
    "import numpy as np # 高速計算\n",
    "import pandas as pd # 表データの扱い\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import common_func as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29fd42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自身がファイルを格納したディレクトリを指定\n",
    "intermediate_path = '../output/intermediate_file/'\n",
    "\n",
    "# スクリプトのバージョン指定\n",
    "preprocessing_ver = 4\n",
    "geo_ver = 2\n",
    "fe_ver = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bd4b4",
   "metadata": {},
   "source": [
    "## File Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae27961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = pd.read_parquet(f'{intermediate_path}train_df_preprocessed_v{preprocessing_ver}.parquet')\n",
    "test_df_fe = pd.read_parquet(f'{intermediate_path}test_df_preprocessed_v{preprocessing_ver}.parquet')\n",
    "\n",
    "fe_cols = test_df_fe.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63cbbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = 'target_ym'\n",
    "target_col = 'money_room'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c61dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe['y_log'] = np.log(train_df_fe[target_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32856b",
   "metadata": {},
   "source": [
    "## 国土数値情報と結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78cbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_geo = pd.read_parquet(f'{intermediate_path}train_df_geo_v{geo_ver}.parquet')\n",
    "test_df_geo = pd.read_parquet(f'{intermediate_path}test_df_geo_v{geo_ver}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3ebbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkey_cols = ['target_ym', 'building_id', 'unit_id']\n",
    "\n",
    "train_df_fe = train_df_fe.merge(train_df_geo, on=pkey_cols)\n",
    "test_df_fe = test_df_fe.merge(test_df_geo, on=pkey_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea447671",
   "metadata": {},
   "source": [
    "## 都道府県・市区町村情報のTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004e3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'Prefecture name_te', 'City/town/village name_te'\n",
    "adress_cols = ['Prefecture name', 'City/town/village name']\n",
    "\n",
    "global_mean_log = train_df_fe['y_log'].mean()\n",
    "\n",
    "for col in adress_cols:\n",
    "    stats = (\n",
    "        train_df_fe\n",
    "        .groupby(col)['y_log']\n",
    "        .agg(['mean', 'count'])\n",
    "    )\n",
    "\n",
    "    smoothing = 50  # ハイパラ\n",
    "    smooth_mean = (\n",
    "        (stats['mean'] * stats['count'] + global_mean_log * smoothing) /\n",
    "        (stats['count'] + smoothing)\n",
    "    )\n",
    "\n",
    "    train_df_fe[col + '_te'] = train_df_fe[col].map(smooth_mean).fillna(global_mean_log)\n",
    "    test_df_fe[col + '_te']  = test_df_fe[col].map(smooth_mean).fillna(global_mean_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3279abb9",
   "metadata": {},
   "source": [
    "## 面積比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1764bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'area_ratio'\n",
    "area_ratio_train = train_df_fe['senyu_area'] / train_df_fe['nobeyuka_area']\n",
    "area_ratio_test = test_df_fe['senyu_area'] / test_df_fe['nobeyuka_area']\n",
    "\n",
    "train_df_fe['area_ratio'] = area_ratio_train.clip(upper=1.5)\n",
    "test_df_fe['area_ratio'] = area_ratio_test.clip(upper=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235525f",
   "metadata": {},
   "source": [
    "## 相対階数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ca24824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地下は明示的にフラグにする\n",
    "train_df_fe['is_basement'] = (train_df_fe['room_floor'] < 0).astype('int8')\n",
    "test_df_fe['is_basement']  = (test_df_fe['room_floor'] < 0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a608aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'relative_floor'\n",
    "train_df_fe['relative_floor'] = (\n",
    "    train_df_fe['room_floor'] / train_df_fe['floor_count']\n",
    ").clip(lower=0, upper=1)\n",
    "\n",
    "test_df_fe['relative_floor'] = (\n",
    "    test_df_fe['room_floor'] / test_df_fe['floor_count']\n",
    ").clip(lower=0, upper=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da822b0",
   "metadata": {},
   "source": [
    "## 密度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19fd3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'unit_land_density', 'area_per_room'\n",
    "for df in [train_df_fe, test_df_fe]:\n",
    "    # 2) 敷地あたり専有面積密度: 専有面積 / 区画面積\n",
    "    df['unit_land_density_raw'] = df['senyu_area'] / df['kukaku_area']\n",
    "    df['unit_land_density'] = df['unit_land_density_raw'].clip(upper=1.5)\n",
    "    df.loc[df['kukaku_area'] <= 0, 'unit_land_density'] = np.nan\n",
    "    df['unit_land_density_over1'] = (df['unit_land_density_raw'] > 1).astype('int8')\n",
    "\n",
    "    # 3) 面積 / 部屋数: 1部屋あたり専有面積\n",
    "    df['area_per_room_raw'] = df['senyu_area'] / df['room_count']\n",
    "    df['area_per_room'] = df['area_per_room_raw'].clip(upper=50)\n",
    "    df.loc[df['room_count'] <= 0, 'area_per_room'] = np.nan\n",
    "    df['area_per_room_log'] = np.log1p(df['area_per_room'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a780e",
   "metadata": {},
   "source": [
    "## 豪邸検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49c25945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'land_building_ratio'\n",
    "CAP = 20.0  # まずは 10〜30 の範囲で検討（後で分布見て調整）\n",
    "\n",
    "for df in [train_df_fe, test_df_fe]:\n",
    "    # 0/負・欠損は NaN に\n",
    "    df['land_building_ratio_raw'] = df['kukaku_area'] / df['nobeyuka_area']\n",
    "    df.loc[df['nobeyuka_area'] <= 0, 'land_building_ratio_raw'] = np.nan\n",
    "\n",
    "    # 極端値を抑制\n",
    "    df['land_building_ratio'] = df['land_building_ratio_raw'].clip(upper=CAP)\n",
    "\n",
    "    # 極端に大きい（≒分母が小さすぎる/定義ブレ）をフラグ化\n",
    "    df['land_building_ratio_hi'] = (df['land_building_ratio_raw'] > CAP).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3867a5",
   "metadata": {},
   "source": [
    "## 面積と築年の交互作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ed9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'senyu_area_x_built_diff', 'area_per_room_x_built_diff'\n",
    "for df in [train_df_fe, test_df_fe]:\n",
    "    # 2) 専有面積 × 築年数\n",
    "    df['senyu_area_x_built_diff'] = df['senyu_area'] * df['built_diff']\n",
    "\n",
    "    # 3) 1部屋あたり面積 × 築年数\n",
    "    #   → 同じ築年数でも「広くてゆとりのある間取り」のプレミアムを表現\n",
    "    df['area_per_room_x_built_diff'] = df['area_per_room'] * df['built_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d3678",
   "metadata": {},
   "source": [
    "## building_idごとの統合特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa45612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'building_senyu_area_median', 'building_room_floor_max', 'building_unit_count'\n",
    "# train のみで作る（リーク防止）\n",
    "base_units = (\n",
    "    train_df_fe\n",
    "    .dropna(subset=['unit_id'])\n",
    "    .drop_duplicates(subset=['building_id', 'unit_id'])\n",
    ")\n",
    "\n",
    "building_stats = base_units.groupby('building_id').agg(\n",
    "    building_senyu_area_median=('senyu_area_log', 'median'),\n",
    "    building_room_floor_max=('room_floor', 'max'),\n",
    "    building_unit_count=('unit_id', 'nunique'),\n",
    ")\n",
    "\n",
    "train_df_fe = train_df_fe.join(building_stats, on='building_id')\n",
    "test_df_fe  = test_df_fe.join(building_stats, on='building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3b9b0",
   "metadata": {},
   "source": [
    "## 近傍価格特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71fbae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def add_multi_radius_neighbor_features(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    *,\n",
    "    target_col: str = 'money_room',\n",
    "    lat_col: str = 'lat',\n",
    "    lon_col: str = 'lon',\n",
    "    building_id_col: str = 'building_id',\n",
    "    building_category_col: str = 'building_category',\n",
    "    radius_list_m: list[int] = [300, 500, 1000, 2000],\n",
    "):\n",
    "    \"\"\"\n",
    "    距離ごと（300m, 500m, 1km, 2km） × building_category別（house, mansion, all）\n",
    "    の近傍集計特徴量を追加する。\n",
    "\n",
    "    作る特徴量例：\n",
    "      - mean_price_300m, median_price_300m（実数）\n",
    "      - mean_price_300m_log, median_price_300m_log（log）\n",
    "      - std_price_300m, iqr_price_300m\n",
    "      - count_neighbors_300m\n",
    "\n",
    "      - mean_price_300m_house, mean_price_300m_house_log\n",
    "      - mean_price_300m_mansion, mean_price_300m_mansion_log\n",
    "      - …\n",
    "\n",
    "    注意：\n",
    "      test 側は train のみを近傍に使う。\n",
    "      train 側は「同じ building_id」は除外する。\n",
    "      最終学習向け（train全量でtarget依存特徴量を作り、testへ適用）。\n",
    "      注意: CV評価にはリークする。\n",
    "    \"\"\"\n",
    "\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "\n",
    "    # --- 必須列チェック ---\n",
    "    req_tr = [target_col, lat_col, lon_col, building_id_col, building_category_col]\n",
    "    for c in req_tr:\n",
    "        if c not in tr.columns:\n",
    "            raise KeyError(f'train_df missing column: {c}')\n",
    "    req_te = [lat_col, lon_col]\n",
    "    for c in req_te:\n",
    "        if c not in te.columns:\n",
    "            raise KeyError(f'test_df missing column: {c}')\n",
    "\n",
    "    # --- 数値化 & 欠損処理 ---\n",
    "    tr[lat_col] = pd.to_numeric(tr[lat_col], errors='coerce')\n",
    "    tr[lon_col] = pd.to_numeric(tr[lon_col], errors='coerce')\n",
    "    te[lat_col] = pd.to_numeric(te[lat_col], errors='coerce')\n",
    "    te[lon_col] = pd.to_numeric(te[lon_col], errors='coerce')\n",
    "\n",
    "    # 参照に使う train 側は、座標と target が揃っている行だけ\n",
    "    tr_ref = tr.dropna(subset=[target_col, lat_col, lon_col]).copy()\n",
    "    if len(tr_ref) == 0:\n",
    "        raise ValueError('No valid rows for neighbor reference (target/lat/lon all NaN).')\n",
    "\n",
    "    y_ref = pd.to_numeric(tr_ref[target_col], errors='coerce').astype(float).to_numpy()\n",
    "\n",
    "    cats = tr_ref[building_category_col].astype('string').fillna('missing').to_numpy()\n",
    "    bids = tr_ref[building_id_col].to_numpy()\n",
    "\n",
    "    train_coords = np.radians(tr_ref[[lat_col, lon_col]].to_numpy())\n",
    "    tree = BallTree(train_coords, metric='haversine')\n",
    "    R = 6371.0\n",
    "\n",
    "    # fallback stats（参照集合に対する統計）\n",
    "    g_mean = float(np.nanmean(y_ref))\n",
    "    g_median = float(np.nanmedian(y_ref))\n",
    "    g_std = float(np.nanstd(y_ref))\n",
    "    g_iqr = float(np.nanpercentile(y_ref, 75) - np.nanpercentile(y_ref, 25))\n",
    "\n",
    "    # 生成列一覧（学習列に足しやすくする）\n",
    "    created_cols: list[str] = []\n",
    "\n",
    "    def _compute_for_apply(df_apply: pd.DataFrame, exclude_same_building: bool) -> pd.DataFrame:\n",
    "        out = df_apply.copy()\n",
    "\n",
    "        apply_coords = np.radians(out[[lat_col, lon_col]].to_numpy())\n",
    "        n = len(out)\n",
    "\n",
    "        bids_apply = None\n",
    "        if exclude_same_building and building_id_col in out.columns:\n",
    "            bids_apply = out[building_id_col].to_numpy()\n",
    "\n",
    "        for r in radius_list_m:\n",
    "            r_rad = (r / 1000.0) / R\n",
    "            neigh_list = tree.query_radius(apply_coords, r=r_rad, return_distance=False)\n",
    "\n",
    "            mean_all = np.full(n, g_mean, dtype=float)\n",
    "            median_all = np.full(n, g_median, dtype=float)\n",
    "            std_all = np.full(n, g_std, dtype=float)\n",
    "            iqr_all = np.full(n, g_iqr, dtype=float)\n",
    "            cnt_all = np.zeros(n, dtype=int)\n",
    "\n",
    "            mean_house = np.full(n, g_mean, dtype=float)\n",
    "            mean_mansion = np.full(n, g_mean, dtype=float)\n",
    "            cnt_house = np.zeros(n, dtype=int)\n",
    "            cnt_mansion = np.zeros(n, dtype=int)\n",
    "\n",
    "            for i, neigh_idx in enumerate(neigh_list):\n",
    "                if len(neigh_idx) == 0:\n",
    "                    continue\n",
    "\n",
    "                if bids_apply is not None:\n",
    "                    # ref側のbuilding_idと、apply側のbuilding_idが一致するものを除外\n",
    "                    neigh_idx = neigh_idx[bids[neigh_idx] != bids_apply[i]]\n",
    "                    if len(neigh_idx) == 0:\n",
    "                        continue\n",
    "\n",
    "                prices = y_ref[neigh_idx]\n",
    "                mean_all[i] = float(prices.mean())\n",
    "                median_all[i] = float(np.median(prices))\n",
    "                cnt_all[i] = int(len(neigh_idx))\n",
    "\n",
    "                if len(neigh_idx) > 1:\n",
    "                    std_all[i] = float(prices.std())\n",
    "                    q75, q25 = np.percentile(prices, [75, 25])\n",
    "                    iqr_all[i] = float(q75 - q25)\n",
    "\n",
    "                neigh_cat = cats[neigh_idx]\n",
    "                idx_h = neigh_idx[neigh_cat == 'house']\n",
    "                if len(idx_h) > 0:\n",
    "                    p = y_ref[idx_h]\n",
    "                    mean_house[i] = float(p.mean())\n",
    "                    cnt_house[i] = int(len(idx_h))\n",
    "\n",
    "                idx_m = neigh_idx[neigh_cat == 'mansion']\n",
    "                if len(idx_m) > 0:\n",
    "                    p = y_ref[idx_m]\n",
    "                    mean_mansion[i] = float(p.mean())\n",
    "                    cnt_mansion[i] = int(len(idx_m))\n",
    "\n",
    "            # base（生集計）\n",
    "            out[f'mean_price_{r}m'] = mean_all\n",
    "            out[f'median_price_{r}m'] = median_all\n",
    "            out[f'std_price_{r}m'] = std_all\n",
    "            out[f'iqr_price_{r}m'] = iqr_all\n",
    "            out[f'count_neighbors_{r}m'] = cnt_all\n",
    "\n",
    "            out[f'mean_price_{r}m_house'] = mean_house\n",
    "            out[f'count_neighbors_{r}m_house'] = cnt_house\n",
    "\n",
    "            out[f'mean_price_{r}m_mansion'] = mean_mansion\n",
    "            out[f'count_neighbors_{r}m_mansion'] = cnt_mansion\n",
    "\n",
    "            # log列（生集計に対してlog1p）\n",
    "            out[f'mean_price_{r}m_log'] = np.log1p(np.clip(mean_all, 0.0, None))\n",
    "            out[f'median_price_{r}m_log'] = np.log1p(np.clip(median_all, 0.0, None))\n",
    "            out[f'mean_price_{r}m_house_log'] = np.log1p(np.clip(mean_house, 0.0, None))\n",
    "            out[f'mean_price_{r}m_mansion_log'] = np.log1p(np.clip(mean_mansion, 0.0, None))\n",
    "\n",
    "        return out\n",
    "\n",
    "    # train側: 参照集合(tr_ref)で計算して tr_ref に付与\n",
    "    tr_ref_feat = _compute_for_apply(tr_ref[[lat_col, lon_col, building_id_col]].copy(), exclude_same_building=True)\n",
    "    # 元 train にマージ（参照に使えなかった行はNaN→fallback or 欠損のまま）\n",
    "    for c in tr_ref_feat.columns:\n",
    "        if c in [lat_col, lon_col, building_id_col]:\n",
    "            continue\n",
    "        tr.loc[tr_ref.index, c] = tr_ref_feat[c].to_numpy()\n",
    "        created_cols.append(c)\n",
    "\n",
    "    # trainで参照に使えなかった行（座標/target欠損）には fallback を入れる（0ではなく統計値）\n",
    "    # ※ここは方針。欠損フラグも作るとさらに安定\n",
    "    for c in created_cols:\n",
    "        tr[c] = pd.to_numeric(tr[c], errors='coerce')\n",
    "        tr[c] = tr[c].fillna(tr_ref_feat[c].mean() if c in tr_ref_feat.columns else np.nan)\n",
    "\n",
    "    # test側: train参照で計算\n",
    "    te_feat = _compute_for_apply(te[[lat_col, lon_col]].copy(), exclude_same_building=False)\n",
    "    for c in te_feat.columns:\n",
    "        if c in [lat_col, lon_col]:\n",
    "            continue\n",
    "        te[c] = te_feat[c].to_numpy()\n",
    "\n",
    "    created_cols = sorted(set(created_cols))\n",
    "    return tr, te, created_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "429ed250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe, created_cols = add_multi_radius_neighbor_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f2357",
   "metadata": {},
   "source": [
    "## 交通情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaae259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_access_zone_features(df, far_thresh=5000, error_thresh=20000):\n",
    "    \"\"\"\n",
    "    交通系FEをまとめて付与する関数\n",
    "\n",
    "    作成する特徴量:\n",
    "      - access_zone           : 'walk', 'bus', 'car', 'error', 'unknown'\n",
    "      - door_to_station_min   : 駅までの実質アクセス時間（徒歩 + バス）\n",
    "      - door_to_station_min_log\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 元の距離を退避\n",
    "    df['walk_distance1_raw'] = df['walk_distance1']\n",
    "\n",
    "    # 基本フラグ\n",
    "    has_eki           = df['eki_name1'].notnull()\n",
    "    has_bus_stop      = df['bus_stop1'].notnull()\n",
    "    has_bus_time      = df['bus_time1'].notnull()\n",
    "    has_traffic_other = df['traffic_other'].notnull()\n",
    "\n",
    "    # =========================\n",
    "    # 1) access_zone の分類\n",
    "    # =========================\n",
    "    df['access_zone'] = 'unknown'\n",
    "\n",
    "    # 徒歩圏：駅あり & バス停なし\n",
    "    mask_walk = has_eki & ~has_bus_stop\n",
    "    df.loc[mask_walk, 'access_zone'] = 'walk'\n",
    "\n",
    "    # バス圏：バス停あり（駅あり/なしどちらも）\n",
    "    mask_bus = has_bus_stop & ~mask_walk\n",
    "    df.loc[mask_bus, 'access_zone'] = 'bus'\n",
    "\n",
    "    # 自動車圏候補：「駅までめっちゃ遠い」ケース\n",
    "    very_far = df['walk_distance1_raw'] >= far_thresh\n",
    "\n",
    "    # 1) traffic_other にコメントあり → 自動車圏\n",
    "    mask_car1 = very_far & has_traffic_other\n",
    "\n",
    "    # 2) 駅までの徒歩距離が far_thresh〜error_thresh 未満 → 自動車圏\n",
    "    mask_car2 = very_far & (df['walk_distance1_raw'] < error_thresh)\n",
    "\n",
    "    mask_car = (mask_car1 | mask_car2) & ~mask_walk & ~mask_bus\n",
    "\n",
    "    # walk / bus / unknown のうち、car 条件を満たすものを上書き\n",
    "    df.loc[mask_car, 'access_zone'] = 'car'\n",
    "\n",
    "    # 20,000m 以上は入力ミス疑い(駅の位置情報取れれば直接計算もできるが、、)\n",
    "    mask_error = df['walk_distance1_raw'] >= error_thresh\n",
    "    df.loc[mask_error, 'access_zone'] = 'error'\n",
    "\n",
    "    # =========================\n",
    "    # 2) 駅までの実質アクセス時間\n",
    "    #    (door_to_station_min)\n",
    "    # =========================\n",
    "    # 自宅→徒歩時間（分）\n",
    "    walk_min1 = df['walk_distance1_raw'] / 80\n",
    "\n",
    "    # 初期化\n",
    "    df['door_to_station_min'] = np.nan\n",
    "\n",
    "    # パターンA：駅あり + バス停あり + バス時間あり（徒歩＋バス）\n",
    "    mask_A = has_eki & has_bus_stop & has_bus_time\n",
    "    df.loc[mask_A, 'door_to_station_min'] = (\n",
    "        walk_min1[mask_A] + df.loc[mask_A, 'bus_time1']\n",
    "    )\n",
    "\n",
    "    # パターンB：駅のみ → 徒歩のみ\n",
    "    mask_B = has_eki & ~has_bus_stop\n",
    "    df.loc[mask_B, 'door_to_station_min'] = walk_min1[mask_B]\n",
    "\n",
    "    # パターンC（駅なし＋バスのみ）は NaN のまま\n",
    "    # → bus_only_flag などで別途対処可能\n",
    "\n",
    "    # 非線形吸収用ログ特徴量\n",
    "    df['door_to_station_min_log'] = np.log1p(df['door_to_station_min'])\n",
    "\n",
    "    bins = [-1, 300, 700, 1500, 5000]\n",
    "    labels = ['0-300', '300-700', '700-1500', '1500-5000']\n",
    "  \n",
    "    df['walk_distance_bin'] = pd.cut(\n",
    "        df['walk_distance1_raw'],\n",
    "        bins=bins,\n",
    "        labels=labels\n",
    "    ).astype('category')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958f6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_access_zone_features(train_df_fe)\n",
    "test_df_fe  = add_access_zone_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a325be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_te_cols = ['eki_name1', 'eki_name2', 'rosen_name1', 'rosen_name2']\n",
    "\n",
    "global_mean_log = float(train_df_fe['y_log'].mean())\n",
    "\n",
    "for col in traffic_te_cols:\n",
    "    mapping = train_df_fe.groupby(col)['y_log'].mean()\n",
    "\n",
    "    train_df_fe[col + '_te'] = train_df_fe[col].map(mapping).fillna(global_mean_log)\n",
    "    test_df_fe[col + '_te']  = test_df_fe[col].map(mapping).fillna(global_mean_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a2978",
   "metadata": {},
   "source": [
    "## 建物情報の拡充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "315a9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_building_area_features(df):\n",
    "    \"\"\"\n",
    "    建物規模系の追加特徴量を作成する\n",
    "    - density_floor_area\n",
    "    - senyu_area_range\n",
    "    - senyu_area_range_log\n",
    "    - has_senyu_area_range\n",
    "    - empty_ratio\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) 延床面積密度\n",
    "    df['density_floor_area'] = df['nobeyuka_area'] / df['tochi_area']\n",
    "    df.loc[df['tochi_area'] <= 0, 'density_floor_area'] = np.nan\n",
    "\n",
    "    # 2) 専有面積レンジ\n",
    "    df['senyu_area_range'] = df['unit_area_max'] - df['unit_area_min']\n",
    "    df.loc[df['unit_count'] <= 1, 'senyu_area_range'] = 0.0\n",
    "\n",
    "    # レンジが存在するか（unit_count > 1）\n",
    "    df['has_senyu_area_range'] = (df['senyu_area_range'] > 0).astype('int8')\n",
    "\n",
    "    # log1p（下限0を保証）\n",
    "    df['senyu_area_range_log'] = np.log1p(df['senyu_area_range'].clip(lower=0))\n",
    "\n",
    "    # 3) 空室率\n",
    "    df['empty_ratio'] = df['empty_number'] / df['unit_count']\n",
    "    df.loc[df['unit_count'] <= 0, 'empty_ratio'] = np.nan\n",
    "    df.loc[df['empty_number'] > df['unit_count'], 'empty_ratio'] = np.nan\n",
    "    df['empty_ratio'] = df['empty_ratio'].clip(0, 1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba43ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_building_area_features(train_df_fe)\n",
    "test_df_fe  = add_building_area_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1719bd0",
   "metadata": {},
   "source": [
    "## リフォーム・リノベ情報の拡充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b83100ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_effective_age(df, train_year):\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- 2) 日付列\n",
    "    date_cols = [\n",
    "        'renovation_date',\n",
    "        'reform_interior_date',\n",
    "        'reform_wet_area_date',\n",
    "        'reform_exterior_date'\n",
    "    ]\n",
    "\n",
    "    for c in date_cols:\n",
    "        df[c] = pd.to_datetime(df[c], errors='coerce')\n",
    "\n",
    "    # --- 3) 最後の改修年\n",
    "    df['last_reform_date'] = df[date_cols].max(axis=1)\n",
    "    df['last_reform_year'] = df['last_reform_date'].dt.year\n",
    "\n",
    "    # --- 4) 改修フラグ\n",
    "    df['has_renovation'] = df['last_reform_date'].notnull().astype('int8')\n",
    "\n",
    "    # --- 5) 改修からの経過年\n",
    "    df['renovation_recency'] = train_year - df['last_reform_year']\n",
    "    df.loc[df['renovation_recency'] < 0, 'renovation_recency'] = np.nan\n",
    "\n",
    "    # --- 6) 軽い補正（最大 -3年）\n",
    "    discount = np.exp(-df['renovation_recency'] / 5) * 3\n",
    "    discount = discount.fillna(0)\n",
    "\n",
    "    df['effective_age'] = df['built_diff'] - discount\n",
    "    df['effective_age'] = df['effective_age'].clip(lower=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fa12d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例：target_ym の最大値から基準年・月を決める\n",
    "train_max_ym = train_df_fe['target_ym'].max()  # 例: 202210\n",
    "train_year = train_max_ym // 100            # → 2022\n",
    "\n",
    "train_df_fe = add_effective_age(train_df_fe, train_year)\n",
    "test_df_fe  = add_effective_age(test_df_fe, train_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748bbbf7",
   "metadata": {},
   "source": [
    "## 掲載期間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e005cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する特徴量：'listing_months'\n",
    "def calculate_listing_months(df):\n",
    "\n",
    "    # 1) building_create_date を datetime へ（すでに datetime の場合はスキップ）\n",
    "    df['building_create_date'] = pd.to_datetime(df['building_create_date'], errors='coerce')\n",
    "\n",
    "    # 2) target_ym (例: 201901 → 2019-01-01) を datetime に変換\n",
    "    df['target_ym_date'] = pd.to_datetime(df['target_ym'].astype(str), format='%Y%m', errors='coerce')\n",
    "\n",
    "    # 3) 年月のみを使った '月数' 変換\n",
    "    b_y = df['building_create_date'].dt.year\n",
    "    b_m = df['building_create_date'].dt.month\n",
    "    t_y = df['target_ym_date'].dt.year\n",
    "    t_m = df['target_ym_date'].dt.month\n",
    "\n",
    "    # 4) 掲載期間（何ヶ月経っているか）を計算\n",
    "    df['listing_months'] = (t_y - b_y) * 12 + (t_m - b_m)\n",
    "    df['listing_months_log'] = np.log1p(df['listing_months'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "107c32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = calculate_listing_months(train_df_fe)\n",
    "test_df_fe  = calculate_listing_months(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf84bf1",
   "metadata": {},
   "source": [
    "## 地価の比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd7d6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_price_ratio_features_full(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    *,\n",
    "    clip_q_ratio: float = 0.999,   # ratio系の上側clip分位\n",
    "    clip_q_logdiff: float = 0.999, # log差分の上側clip分位（基本ratioと同じでOK）\n",
    "    eps: float = 1e-6,\n",
    "    add_flags: bool = True,\n",
    "    flag_thr_ratio: float = 5.0,   # gapフラグ用（必要に応じて調整）\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    作成する特徴量（例）:\n",
    "      - ratio_mean_land, ratio_weighted_land\n",
    "      - ratio_mean_land_clip, ratio_weighted_land_clip\n",
    "      - ratio_mean_land_log, ratio_weighted_land_log\n",
    "      - logdiff_mean_nearest, logdiff_median_weighted\n",
    "      - logdiff_*_clip\n",
    "      - (optional) is_land_price_gap_ratio_mean\n",
    "    \"\"\"\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "\n",
    "    def _calc_base(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # --- ratio（分母>0 & 分子notna）---\n",
    "        df['ratio_mean_land'] = np.nan\n",
    "        mask_mean = (df['nearest_land_price'] > 0) & df['mean_price_1000m'].notna()\n",
    "        df.loc[mask_mean, 'ratio_mean_land'] = (\n",
    "            df.loc[mask_mean, 'mean_price_1000m'].astype(float)\n",
    "            / np.maximum(df.loc[mask_mean, 'nearest_land_price'].astype(float), eps)\n",
    "        )\n",
    "\n",
    "        df['ratio_weighted_land'] = np.nan\n",
    "        mask_w = (df['weighted_land_price_3'] > 0) & df['median_price_1000m'].notna()\n",
    "        df.loc[mask_w, 'ratio_weighted_land'] = (\n",
    "            df.loc[mask_w, 'median_price_1000m'].astype(float)\n",
    "            / np.maximum(df.loc[mask_w, 'weighted_land_price_3'].astype(float), eps)\n",
    "        )\n",
    "\n",
    "        # --- log差分（log比）---\n",
    "        # log(mean/nearest) = log(mean+1) - log(nearest+1) では厳密な比ではないが安定で効きやすい\n",
    "        df['logdiff_mean_nearest'] = df['mean_price_1000m_log'] - df['log_land_price']\n",
    "        df['logdiff_median_weighted'] = df['median_price_1000m_log'] - df['log_weighted_land_price_3']\n",
    "\n",
    "        return df\n",
    "\n",
    "    tr = _calc_base(tr)\n",
    "    te = _calc_base(te)\n",
    "\n",
    "    # ==========\n",
    "    # 1) ratio系 clip/log（clip閾値はtrainから固定）\n",
    "    # ==========\n",
    "    if tr['ratio_mean_land'].notna().any():\n",
    "        ratio_mean_clip = float(tr['ratio_mean_land'].dropna().quantile(clip_q_ratio))\n",
    "    else:\n",
    "        ratio_mean_clip = np.nan\n",
    "\n",
    "    if tr['ratio_weighted_land'].notna().any():\n",
    "        ratio_w_clip = float(tr['ratio_weighted_land'].dropna().quantile(clip_q_ratio))\n",
    "    else:\n",
    "        ratio_w_clip = np.nan\n",
    "\n",
    "    tr['ratio_mean_land_clip'] = tr['ratio_mean_land'].clip(upper=ratio_mean_clip) if np.isfinite(ratio_mean_clip) else tr['ratio_mean_land']\n",
    "    te['ratio_mean_land_clip'] = te['ratio_mean_land'].clip(upper=ratio_mean_clip) if np.isfinite(ratio_mean_clip) else te['ratio_mean_land']\n",
    "\n",
    "    tr['ratio_weighted_land_clip'] = tr['ratio_weighted_land'].clip(upper=ratio_w_clip) if np.isfinite(ratio_w_clip) else tr['ratio_weighted_land']\n",
    "    te['ratio_weighted_land_clip'] = te['ratio_weighted_land'].clip(upper=ratio_w_clip) if np.isfinite(ratio_w_clip) else te['ratio_weighted_land']\n",
    "\n",
    "    tr['ratio_mean_land_log'] = np.log1p(np.maximum(tr['ratio_mean_land_clip'], 0))\n",
    "    te['ratio_mean_land_log'] = np.log1p(np.maximum(te['ratio_mean_land_clip'], 0))\n",
    "\n",
    "    tr['ratio_weighted_land_log'] = np.log1p(np.maximum(tr['ratio_weighted_land_clip'], 0))\n",
    "    te['ratio_weighted_land_log'] = np.log1p(np.maximum(te['ratio_weighted_land_clip'], 0))\n",
    "\n",
    "    # ==========\n",
    "    # 2) log差分 clip（外れ値を抑える。こちらもtrainから固定）\n",
    "    # ==========\n",
    "    if tr['logdiff_mean_nearest'].notna().any():\n",
    "        ld_m_clip = float(tr['logdiff_mean_nearest'].dropna().quantile(clip_q_logdiff))\n",
    "    else:\n",
    "        ld_m_clip = np.nan\n",
    "\n",
    "    if tr['logdiff_median_weighted'].notna().any():\n",
    "        ld_w_clip = float(tr['logdiff_median_weighted'].dropna().quantile(clip_q_logdiff))\n",
    "    else:\n",
    "        ld_w_clip = np.nan\n",
    "\n",
    "    tr['logdiff_mean_nearest_clip'] = tr['logdiff_mean_nearest'].clip(upper=ld_m_clip) if np.isfinite(ld_m_clip) else tr['logdiff_mean_nearest']\n",
    "    te['logdiff_mean_nearest_clip'] = te['logdiff_mean_nearest'].clip(upper=ld_m_clip) if np.isfinite(ld_m_clip) else te['logdiff_mean_nearest']\n",
    "\n",
    "    tr['logdiff_median_weighted_clip'] = tr['logdiff_median_weighted'].clip(upper=ld_w_clip) if np.isfinite(ld_w_clip) else tr['logdiff_median_weighted']\n",
    "    te['logdiff_median_weighted_clip'] = te['logdiff_median_weighted'].clip(upper=ld_w_clip) if np.isfinite(ld_w_clip) else te['logdiff_median_weighted']\n",
    "\n",
    "    # ==========\n",
    "    # 3) 追加フラグ（任意）\n",
    "    # ==========\n",
    "    if add_flags:\n",
    "        tr['is_land_price_gap_ratio_mean'] = (tr['ratio_mean_land'] > flag_thr_ratio).astype('int8')\n",
    "        te['is_land_price_gap_ratio_mean'] = (te['ratio_mean_land'] > flag_thr_ratio).astype('int8')\n",
    "\n",
    "        tr['is_land_price_gap_ratio_weighted'] = (tr['ratio_weighted_land'] > flag_thr_ratio).astype('int8')\n",
    "        te['is_land_price_gap_ratio_weighted'] = (te['ratio_weighted_land'] > flag_thr_ratio).astype('int8')\n",
    "\n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b87e1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_land_price_ratio_features_full(\n",
    "    train_df_fe,\n",
    "    test_df_fe,\n",
    "    clip_q_ratio=0.999,\n",
    "    clip_q_logdiff=0.999,\n",
    "    add_flags=True,\n",
    "    flag_thr_ratio=5.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465e5a3",
   "metadata": {},
   "source": [
    "## 共益費・修繕費関連"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e3e200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fee_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    共益費・修繕積立の特徴量:\n",
    "      - kyoueki_per_m2, shuuzen_per_m2\n",
    "      - kyoueki_per_unit, shuuzen_per_unit\n",
    "      - has_kyoueki, has_shuuzen\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    house = func._as_numeric(out.get('senyu_area'))\n",
    "    unit_cnt = func._as_numeric(out.get('unit_count'))\n",
    "    kyoueki = func._as_numeric(out.get('money_kyoueki_std'))\n",
    "    shuuzen = func._as_numeric(out.get('money_shuuzen'))\n",
    "\n",
    "    # 1) 面積あたり\n",
    "    if (house is not None) and (kyoueki is not None):\n",
    "        out['kyoueki_per_m2'] = np.where(house > 0, kyoueki / house, np.nan)\n",
    "\n",
    "    if (house is not None) and (shuuzen is not None):\n",
    "        out['shuuzen_per_m2'] = np.where(house > 0, shuuzen / house, np.nan)\n",
    "\n",
    "    # 2) 戸数あたり\n",
    "    if (unit_cnt is not None) and (kyoueki is not None):\n",
    "        out['kyoueki_per_unit'] = np.where(unit_cnt > 0, kyoueki / unit_cnt, np.nan)\n",
    "\n",
    "    if (unit_cnt is not None) and (shuuzen is not None):\n",
    "        out['shuuzen_per_unit'] = np.where(unit_cnt > 0, shuuzen / unit_cnt, np.nan)\n",
    "\n",
    "    # 3) 有無フラグ（欠損は 0 扱いにする方針）\n",
    "    if kyoueki is not None:\n",
    "        out['has_kyoueki'] = (kyoueki.fillna(0) > 0).astype('Int8')\n",
    "\n",
    "    if shuuzen is not None:\n",
    "        out['has_shuuzen'] = (shuuzen.fillna(0) > 0).astype('Int8')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb0d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_fee_features(train_df_fe)\n",
    "test_df_fe = add_fee_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22949d98",
   "metadata": {},
   "source": [
    "## 地価のギャップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc2afbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_gap_flags(df: pd.DataFrame,\n",
    "                       cheap_th: float = 0.8,\n",
    "                       expensive_th: float = 1.2,\n",
    "                       ratio_col: str = 'ratio_mean_land') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    地価ギャップ由来のフラグ:\n",
    "      - land_cheap_flag\n",
    "      - land_expensive_flag\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    if ratio_col in out.columns:\n",
    "        ratio = func._as_numeric(out[ratio_col])\n",
    "        out['land_cheap_flag'] = (ratio < cheap_th).astype('Int8')\n",
    "        out['land_expensive_flag'] = (ratio > expensive_th).astype('Int8')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "577bb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_land_gap_flags(train_df_fe)\n",
    "test_df_fe = add_land_gap_flags(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd78f540",
   "metadata": {},
   "source": [
    "## 理論土地価格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41514dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_theoretical_price_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    理論土地価格 (= 地価 × 土地面積) を log1p で作る:\n",
    "      - land_theoretical_price                  (nearest_land_price)\n",
    "      - land_theoretical_price_weighted         (weighted_land_price_3)\n",
    "      - land_theoretical_price_within1km_mp     (mean_price_1000m)\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    land_area = func._as_numeric(out.get('kukaku_area'))\n",
    "    nearest_lp = func._as_numeric(out.get('nearest_land_price'))\n",
    "    weighted_lp = func._as_numeric(out.get('weighted_land_price_3'))\n",
    "    within1km_mp = func._as_numeric(out.get('mean_price_1000m'))\n",
    "\n",
    "    if land_area is None:\n",
    "        return out\n",
    "\n",
    "    valid_area = land_area > 0\n",
    "\n",
    "    if nearest_lp is not None:\n",
    "        out['land_theoretical_price'] = np.where(\n",
    "            valid_area,\n",
    "            np.log1p(nearest_lp * land_area),\n",
    "            np.nan\n",
    "        )\n",
    "        out['land_theoretical_price_x_senyu'] = (\n",
    "            out['land_theoretical_price'] * out['senyu_area_log']\n",
    "        )\n",
    "        out['senyu_to_land_value_ratio'] = (\n",
    "            out['senyu_area_log'] - out['land_theoretical_price']\n",
    "        )\n",
    "\n",
    "    if weighted_lp is not None:\n",
    "        out['land_theoretical_price_weighted'] = np.where(\n",
    "            valid_area,\n",
    "            np.log1p(weighted_lp * land_area),\n",
    "            np.nan\n",
    "        )\n",
    "        out['land_theoretical_price_weighted_x_senyu'] = (\n",
    "            out['land_theoretical_price_weighted'] * out['senyu_area_log']\n",
    "        )\n",
    "\n",
    "    if within1km_mp is not None:\n",
    "        out['land_theoretical_price_within1km_mp'] = np.where(\n",
    "            valid_area,\n",
    "            np.log1p(within1km_mp * land_area),\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60cfe05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe= add_land_theoretical_price_features(train_df_fe)\n",
    "test_df_fe= add_land_theoretical_price_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4311c",
   "metadata": {},
   "source": [
    "## 周辺施設カテゴリ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e3e33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_life_convenience_features(\n",
    "    train_df_fe: pd.DataFrame,\n",
    "    test_df_fe: pd.DataFrame,\n",
    "    amenity_cols: list[str] | None = None,\n",
    "    thresholds: tuple[int, ...] = (500, 1000),\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train = train_df_fe.copy()\n",
    "    test = test_df_fe.copy()\n",
    "\n",
    "    combined = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "    if amenity_cols is None:\n",
    "        amenity_cols = [\n",
    "            c for c in [\n",
    "                'convenience_distance',\n",
    "                'super_distance',\n",
    "                'hospital_distance',\n",
    "                'park_distance',\n",
    "                'drugstore_distance',\n",
    "                'bank_distance',\n",
    "                'shopping_street_distance',\n",
    "                'est_other_distance',\n",
    "            ]\n",
    "            if c in combined.columns\n",
    "        ]\n",
    "\n",
    "    if len(amenity_cols) == 0:\n",
    "        print('[add_life_convenience_features] amenity_cols is empty. Skip.')\n",
    "        return train_df_fe, test_df_fe\n",
    "\n",
    "    # 距離を数値化（欠損は遠い扱い）\n",
    "    dist = combined[amenity_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    dist = dist.clip(lower=0).fillna(np.inf)\n",
    "\n",
    "    # thresholds ごとに「施設カテゴリ数」のみ作成\n",
    "    for th in thresholds:\n",
    "        combined[f'amenity_count_within_{th}m'] = (dist <= th).sum(axis=1).astype('int16')\n",
    "\n",
    "    n_train = len(train_df_fe)\n",
    "    train_out = combined.iloc[:n_train].reset_index(drop=True)\n",
    "    test_out = combined.iloc[n_train:].reset_index(drop=True)\n",
    "\n",
    "    return train_out, test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c27bafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_life_convenience_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574b4d6",
   "metadata": {},
   "source": [
    "## 現況・引渡し、管理スコアなど"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a9ba997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する特徴量：'genkyo_flex_score', 'usable_status_score', 'usable_months_delay', 'has_management_association', 'management_form_score', 'manager_presence_score', 'management_total_score',\n",
    "def add_status_and_management_features(\n",
    "    train_df_fe: pd.DataFrame,\n",
    "    test_df_fe: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    現況(genkyo_code)、引渡し(usable_status, usable_date)、\n",
    "    管理状態(management_form, management_association_flg, house_kanrinin)\n",
    "    を再整理 & スコア化して特徴量追加。\n",
    "    \"\"\"\n",
    "\n",
    "    combined = pd.concat([train_df_fe, test_df_fe], ignore_index=True)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 1) 現況 (genkyo_code)\n",
    "    # ---------------------------\n",
    "    genkyo = combined.get('genkyo_code', pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "\n",
    "    # 自由度スコア\n",
    "    flex_map = {\n",
    "        1: 0.5,   # 居住中 or 更地（兼ねるので控えめ）\n",
    "        2: 1.5,   # 空家\n",
    "        3: 0.0,   # 賃貸中 → 自由度低い\n",
    "        4: 1.0,   # 未完成\n",
    "        10: 1.5,  # 古屋あり更地引渡可\n",
    "    }\n",
    "    combined['genkyo_flex_score'] = genkyo.map(flex_map).fillna(0.0)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 2) 引渡し (usable_status, usable_date)\n",
    "    # ---------------------------\n",
    "    usable_status = combined.get('usable_status', pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    usable_date   = combined.get('usable_date',   pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    target_ym     = combined.get('target_ym',     pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "\n",
    "    # フラグ\n",
    "    combined['usable_immediate_flag']   = (usable_status == 1).astype(int)\n",
    "    combined['usable_fixed_date_flag']  = (usable_status == 3).astype(int)\n",
    "\n",
    "    # スコア: 即時 > 期日指定 > 相談・未定\n",
    "    usable_score_map = {\n",
    "        1: 2.0,   # 即時\n",
    "        3: 1.0,   # 期日指定\n",
    "        2: 0.5,   # 相談\n",
    "        4: 0.0,   # 未定\n",
    "    }\n",
    "    combined['usable_status_score'] = usable_status.map(usable_score_map).fillna(0.0)\n",
    "\n",
    "    # yyyymm 同士の差分 → おおざっぱに「ヶ月差」とみなす\n",
    "    # 例: target_ym=202201, usable_date=202204 → 3 ヶ月\n",
    "    usable_months_delay = np.nan\n",
    "\n",
    "    if 'usable_date' in combined.columns and 'target_ym' in combined.columns:\n",
    "        # 年月を整数に分解\n",
    "        u = usable_date.copy()\n",
    "        t = target_ym.copy()\n",
    "\n",
    "        u_year  = (u // 100).astype('Int64')\n",
    "        u_month = (u % 100).astype('Int64')\n",
    "\n",
    "        t_year  = (t // 100).astype('Int64')\n",
    "        t_month = (t % 100).astype('Int64')\n",
    "\n",
    "        usable_months_delay = (u_year - t_year) * 12 + (u_month - t_month)\n",
    "\n",
    "    combined['usable_months_delay'] = usable_months_delay\n",
    "\n",
    "    # ---------------------------\n",
    "    # 3) 管理状態\n",
    "    # ---------------------------\n",
    "    management_form          = combined.get('management_form',          pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    management_association   = combined.get('management_association_flg', pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    house_kanrinin           = combined.get('house_kanrinin',          pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "\n",
    "    # 管理組合あり\n",
    "    combined['has_management_association'] = (management_association == 2).astype(int)\n",
    "\n",
    "    # プロ管理（委託あり）\n",
    "    combined['has_professional_management'] = management_form.isin([2, 3]).astype(int)\n",
    "\n",
    "    # 管理人あり\n",
    "    combined['has_manager'] = house_kanrinin.isin([1, 2, 3, 5]).astype(int)\n",
    "\n",
    "    # 管理形態スコア\n",
    "    management_form_score_map = {\n",
    "        1: 1.0,   # 自主管理\n",
    "        2: 2.0,   # 一部委託\n",
    "        3: 3.0,   # 全部委託\n",
    "    }\n",
    "    combined['management_form_score'] = management_form.map(management_form_score_map).fillna(0.0)\n",
    "\n",
    "    # 管理人スコア\n",
    "    manager_score_map = {\n",
    "        4: 0.0,   # 無\n",
    "        5: 0.5,   # 非常駐\n",
    "        3: 1.0,   # 巡回\n",
    "        2: 1.5,   # 日勤\n",
    "        1: 2.0,   # 常駐\n",
    "    }\n",
    "    combined['manager_presence_score'] = house_kanrinin.map(manager_score_map).fillna(0.0)\n",
    "\n",
    "    # 合計管理スコア\n",
    "    combined['management_total_score'] = (\n",
    "        combined['management_form_score']\n",
    "        + combined['manager_presence_score']\n",
    "        + combined['has_management_association'] * 0.5  # 管理組合ありに少し加点\n",
    "    )\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4) train/test に戻す\n",
    "    # ---------------------------\n",
    "    n_train = len(train_df_fe)\n",
    "    train_out = combined.iloc[:n_train].reset_index(drop=True)\n",
    "    test_out  = combined.iloc[n_train:].reset_index(drop=True)\n",
    "\n",
    "    return train_out, test_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5452a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_status_and_management_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1470f",
   "metadata": {},
   "source": [
    "## 持分比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a8a8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mochibun_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 持分割合（欠損は 100% 所有とみなす）\n",
    "    df['mochibun_ratio'] = df['land_mochibun_b'] / df['land_mochibun_a']\n",
    "    df['mochibun_ratio'] = df['mochibun_ratio'].replace([np.inf, -np.inf], np.nan)\n",
    "    df['mochibun_ratio'] = df['mochibun_ratio'].fillna(1.0)\n",
    "\n",
    "    # フラグ\n",
    "    df['has_mochibun'] = (df['mochibun_ratio'] < 1.0).astype(int)\n",
    "\n",
    "    # 実効面積（土地面積が存在する場合のみ）\n",
    "    if 'tochi_area' in df.columns:\n",
    "        df['mochibun_area'] = df['tochi_area'] * df['mochibun_ratio']\n",
    "    else:\n",
    "        df['mochibun_area'] = np.nan\n",
    "\n",
    "    df['mochibun_area_log'] = np.log1p(df['mochibun_area'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7df17fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = make_mochibun_features(train_df_fe)\n",
    "test_df_fe = make_mochibun_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846b21",
   "metadata": {},
   "source": [
    "## 私道比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4549cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shidou_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 私道負担面積（欠損＝0）\n",
    "    df['shidou_area_eff'] = df['snapshot_land_shidou'].fillna(0)\n",
    "\n",
    "    # 私道負担割合（分子 / 分母）\n",
    "    df['land_shidou_ratio'] = (\n",
    "        df['land_shidou_b'] / df['land_shidou_a']\n",
    "    )\n",
    "    df['land_shidou_ratio'] = df['land_shidou_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    # フラグ\n",
    "    df['has_shidou'] = (df['shidou_area_eff'] > 0).astype(int)\n",
    "\n",
    "    # 土地面積比率\n",
    "    if 'tochi_area' in df.columns:\n",
    "        df['shidou_area_ratio'] = df['shidou_area_eff'] / df['tochi_area']\n",
    "        df['shidou_area_ratio'] = df['shidou_area_ratio'].fillna(0).clip(0, 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "284fab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = make_shidou_features(train_df_fe)\n",
    "test_df_fe = make_shidou_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630becf8",
   "metadata": {},
   "source": [
    "## 住みやすさスコア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9c39630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "TAG_RULES = {\n",
    "    'bonus': {\n",
    "        '環境プレミアム_コンビニ 400ｍ以内': 2.0,\n",
    "        '環境プレミアム_スーパー 800ｍ以内': 3.0,\n",
    "        '環境プレミアム_総合病院 800ｍ以内': 2.0,\n",
    "        '環境プレミアム_公園 400ｍ以内': 1.5,\n",
    "        '環境プレミアム_子育てに嬉しい環境': 2.0,\n",
    "        '建物構造・性能_オートロック': 2.0,\n",
    "        '建物構造・性能_宅配ボックス': 2.5,\n",
    "        '建物構造・性能_防犯カメラ': 1.5,\n",
    "        '建物構造・性能_エレベーター': 1.0,\n",
    "        '建物構造・性能_管理人常駐': 1.5,\n",
    "        '建物構造・性能_免震構造': 2.0,\n",
    "        '建物構造・性能_耐震・制震・免震構造': 2.0,\n",
    "        '専有部分設備_浴室・洗面_浴室乾燥機': 1.5,\n",
    "        '専有部分設備_浴室・洗面_追焚機能': 1.5,\n",
    "        '専有部分設備_浴室・洗面_洗面所独立': 1.0,\n",
    "        '専有部分設備_キッチン_システムキッチン': 1.5,\n",
    "        '専有部分設備_キッチン_食器洗い乾燥機': 1.5,\n",
    "        '専有部分設備_収納_ウォークインクローゼット': 1.5,\n",
    "        '専有部分設備_収納_全居室収納': 1.0,\n",
    "        '専有部分設備_空調・暖房_床暖房': 2.0,\n",
    "    },\n",
    "    'penalty': {\n",
    "        '専有部分設備_トイレ_トイレなし': -10.0,\n",
    "        '専有部分設備_浴室・洗面_バスなし': -10.0,\n",
    "        '専有部分設備_トイレ_共同トイレ': -5.0,\n",
    "        '専有部分設備_浴室・洗面_共同バス': -5.0,\n",
    "        '建物設備（給排水・インフラ）_汲取': -3.0,\n",
    "        '建物設備（給排水・インフラ）_浄化槽': -2.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "def compute_tag_rule_score(df: pd.DataFrame, rules: dict = TAG_RULES) -> pd.Series:\n",
    "    score = pd.Series(0.0, index=df.index)\n",
    "    for col, w in rules.get('bonus', {}).items():\n",
    "        if col in df.columns:\n",
    "            score += df[col].fillna(0).astype(float) * float(w)\n",
    "    for col, w in rules.get('penalty', {}).items():\n",
    "        if col in df.columns:\n",
    "            score += df[col].fillna(0).astype(float) * float(w)\n",
    "    return score\n",
    "\n",
    "def _add_tag_score(df: pd.DataFrame, prefixes: list[str], new_col: str) -> pd.DataFrame:\n",
    "    cols = [c for c in df.columns if any(c.startswith(p) for p in prefixes)]\n",
    "    if not cols:\n",
    "        df[new_col] = 0.0\n",
    "    else:\n",
    "        df[new_col] = df[cols].mean(axis=1).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "def _standardize_train_apply_test(\n",
    "    train_s: pd.Series,\n",
    "    test_s: pd.Series,\n",
    "    fill_value: float = 0.0,\n",
    ") -> tuple[pd.Series, pd.Series]:\n",
    "    tr = train_s.astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "    te = test_s.astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    mu = tr.mean(skipna=True)\n",
    "    sd = tr.std(skipna=True)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        return (\n",
    "            pd.Series(0.0, index=train_s.index),\n",
    "            pd.Series(0.0, index=test_s.index),\n",
    "        )\n",
    "\n",
    "    tr_z = (tr - mu) / sd\n",
    "    te_z = (te - mu) / sd\n",
    "    return tr_z.fillna(fill_value), te_z.fillna(fill_value)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ① urban_score\n",
    "# =========================================================\n",
    "\n",
    "def make_urban_score(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    urban_features: list[str] | None = None,\n",
    "    impute_strategy: str = 'median',\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "\n",
    "    if urban_features is None:\n",
    "        candidate_cols = [\n",
    "            'count_neighbors_1000m',\n",
    "            'door_to_station_min_log',\n",
    "            'tochi_area_log',\n",
    "            'shikichi_area_log',\n",
    "        ]\n",
    "        urban_features = [c for c in candidate_cols if c in train_df.columns]\n",
    "\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    if not urban_features:\n",
    "        train_df['urban_score'] = 0.0\n",
    "        test_df['urban_score'] = 0.0\n",
    "        return train_df, test_df, {'scaler': None, 'pca': None, 'urban_features': []}\n",
    "\n",
    "    combined = pd.concat(\n",
    "        [train_df[urban_features], test_df[urban_features]],\n",
    "        axis=0, ignore_index=True\n",
    "    ).astype(float)\n",
    "\n",
    "    combined = combined.replace([np.inf, -np.inf], np.nan)\n",
    "    used_features = [c for c in combined.columns if combined[c].notna().any()]\n",
    "    combined = combined[used_features]\n",
    "\n",
    "    if not used_features:\n",
    "        train_df['urban_score'] = 0.0\n",
    "        test_df['urban_score'] = 0.0\n",
    "        return train_df, test_df, {'scaler': None, 'pca': None, 'urban_features': []}\n",
    "\n",
    "    if impute_strategy == 'median':\n",
    "        fill_values = combined.median(numeric_only=True)\n",
    "    elif impute_strategy == 'mean':\n",
    "        fill_values = combined.mean(numeric_only=True)\n",
    "    else:\n",
    "        raise ValueError('impute_strategy must be \\'median\\' or \\'mean\\'')\n",
    "\n",
    "    combined_imputed = combined.fillna(fill_values)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    combined_scaled = scaler.fit_transform(combined_imputed)\n",
    "\n",
    "    pca = PCA(n_components=1, random_state=42)\n",
    "    urban_component = pca.fit_transform(combined_scaled).ravel()\n",
    "\n",
    "    n_train = len(train_df)\n",
    "    train_df['urban_score'] = urban_component[:n_train]\n",
    "    test_df['urban_score'] = urban_component[n_train:]\n",
    "\n",
    "    meta = {\n",
    "        'scaler': scaler,\n",
    "        'pca': pca,\n",
    "        'urban_features': used_features,\n",
    "        'impute_values': fill_values.to_dict(),\n",
    "    }\n",
    "    return train_df, test_df, meta\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ② livability subscores（KSI + land_road_cond 統合版）\n",
    "# =========================================================\n",
    "\n",
    "def make_livability_subscores_ksi(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    use_rule_tags: bool = True,\n",
    "    rule_weight_in_daily: float = 0.6,\n",
    "    rule_weight_in_building: float = 0.8,\n",
    "    # KSI をどこまで使うか\n",
    "    use_ksi_access: bool = True,\n",
    "    use_ksi_zoning: bool = True,\n",
    "    use_ksi_geo_risk: bool = True,\n",
    "    ksi_access_weight: float = 0.7,\n",
    "    ksi_zoning_weight: float = 0.6,\n",
    "    ksi_geo_risk_weight: float = 0.5,\n",
    "    # === land_road_cond: 追加 ===\n",
    "    use_land_road_cond: bool = True,\n",
    "    land_road_weight: float = 0.6,\n",
    "    land_road_map: dict[int, float] | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    # ---------- タグ系スコア ----------\n",
    "    tag_groups = {\n",
    "        'tag_land': ['土地価格_'],\n",
    "        'tag_unit': ['専有部分設備_'],\n",
    "        'tag_building': ['建物構造・性能_'],\n",
    "        'tag_infra': ['建物設備（給排水・インフラ）_'],\n",
    "        'tag_env': ['環境プレミアム_'],\n",
    "        'tag_cert': ['用途・投資セグメント_不動産の証明書・性能評価_'],\n",
    "    }\n",
    "\n",
    "    for name, prefixes in tag_groups.items():\n",
    "        train_df = _add_tag_score(train_df, prefixes, f'{name}_score')\n",
    "        test_df = _add_tag_score(test_df, prefixes, f'{name}_score')\n",
    "\n",
    "    # ---------- ルールベースタグ ----------\n",
    "    if use_rule_tags:\n",
    "        train_df['tag_rule_score_raw'] = compute_tag_rule_score(train_df)\n",
    "        test_df['tag_rule_score_raw'] = compute_tag_rule_score(test_df)\n",
    "\n",
    "        tr_z, te_z = _standardize_train_apply_test(\n",
    "            train_df['tag_rule_score_raw'],\n",
    "            test_df['tag_rule_score_raw'],\n",
    "            fill_value=0.0,\n",
    "        )\n",
    "        train_df['tag_rule_score'] = tr_z\n",
    "        test_df['tag_rule_score'] = te_z\n",
    "    else:\n",
    "        train_df['tag_rule_score'] = 0.0\n",
    "        test_df['tag_rule_score'] = 0.0\n",
    "\n",
    "    # ---------- 数値系（駅近 / 密度 / 面積） ----------\n",
    "    def _add_base_numeric_scores(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if 'door_to_station_min_log' in df.columns:\n",
    "            df['access_station_score'] = func._zscore(-df['door_to_station_min_log'].astype(float))\n",
    "        else:\n",
    "            df['access_station_score'] = 0.0\n",
    "\n",
    "        if 'count_neighbors_1000m' in df.columns:\n",
    "            df['neighbor_density_score'] = func._zscore(df['count_neighbors_1000m'].astype(float))\n",
    "        else:\n",
    "            df['neighbor_density_score'] = 0.0\n",
    "\n",
    "        numeric_area_cols = [\n",
    "            c for c in df.columns\n",
    "            if any(k in c for k in ['senyu_area_log', 'area_per_room', 'nobeyuka_area_log'])\n",
    "        ]\n",
    "        df['room_space_score'] = func._safe_mean(df, numeric_area_cols)\n",
    "        if df['room_space_score'].std() > 0:\n",
    "            df['room_space_score'] = func._zscore(df['room_space_score'])\n",
    "        else:\n",
    "            df['room_space_score'] = 0.0\n",
    "\n",
    "        return df\n",
    "\n",
    "    train_df = _add_base_numeric_scores(train_df)\n",
    "    test_df = _add_base_numeric_scores(test_df)\n",
    "\n",
    "    # =====================================================\n",
    "    # === land_road_cond: 接道条件スコア化 ===\n",
    "    # =====================================================\n",
    "    if land_road_map is None:\n",
    "        # あなたの定義に基づく「素朴な序列」スコア\n",
    "        # 一方(1)を基準0、角地(2)や二方(5)を加点、三方(3)・四方(4)は強加点、接道なし(10)は強減点\n",
    "        land_road_map = {\n",
    "            1: 0.0,   # 一方\n",
    "            2: 0.7,   # 角地\n",
    "            5: 0.6,   # 二方(除角地)\n",
    "            3: 0.9,   # 三方\n",
    "            4: 1.0,   # 四方\n",
    "            10: -2.0, # 接道なし（強減点）\n",
    "        }\n",
    "\n",
    "    if use_land_road_cond and 'land_road_cond' in train_df.columns and 'land_road_cond' in test_df.columns:\n",
    "        tr_code = train_df['land_road_cond'].copy()\n",
    "        te_code = test_df['land_road_cond'].copy()\n",
    "\n",
    "        # 数値変換（その他・欠損は NaN → map で埋まらないので 0 扱いへ）\n",
    "        tr_code = pd.to_numeric(tr_code, errors='coerce')\n",
    "        te_code = pd.to_numeric(te_code, errors='coerce')\n",
    "\n",
    "        tr_raw = tr_code.map(land_road_map).fillna(0.0)\n",
    "        te_raw = te_code.map(land_road_map).fillna(0.0)\n",
    "\n",
    "        tr_z, te_z = _standardize_train_apply_test(tr_raw, te_raw, fill_value=0.0)\n",
    "        train_df['land_road_cond_score'] = tr_z\n",
    "        test_df['land_road_cond_score'] = te_z\n",
    "    else:\n",
    "        train_df['land_road_cond_score'] = 0.0\n",
    "        test_df['land_road_cond_score'] = 0.0\n",
    "\n",
    "    # =====================================================\n",
    "    # KSI: Access（道路近接）\n",
    "    # =====================================================\n",
    "    if use_ksi_access:\n",
    "        tr_dist_major = func._get_or_zeros(train_df, 'dist_to_road_major_m')\n",
    "        te_dist_major = func._get_or_zeros(test_df, 'dist_to_road_major_m')\n",
    "\n",
    "        tr_len_den = func._get_or_zeros(train_df, 'road_len_density')\n",
    "        te_len_den = func._get_or_zeros(test_df, 'road_len_density')\n",
    "\n",
    "        tr_cnt_major_300 = func._get_or_zeros(train_df, 'road_cnt_major_in_300m')\n",
    "        te_cnt_major_300 = func._get_or_zeros(test_df, 'road_cnt_major_in_300m')\n",
    "\n",
    "        tr_dist_z, te_dist_z = _standardize_train_apply_test(-tr_dist_major, -te_dist_major)\n",
    "        tr_den_z, te_den_z = _standardize_train_apply_test(tr_len_den, te_len_den)\n",
    "        tr_cnt_z, te_cnt_z = _standardize_train_apply_test(tr_cnt_major_300, te_cnt_major_300)\n",
    "\n",
    "        train_df['ksi_road_access_score'] = (tr_dist_z + tr_den_z + 0.5 * tr_cnt_z) / 2.5\n",
    "        test_df['ksi_road_access_score'] = (te_dist_z + te_den_z + 0.5 * te_cnt_z) / 2.5\n",
    "    else:\n",
    "        train_df['ksi_road_access_score'] = 0.0\n",
    "        test_df['ksi_road_access_score'] = 0.0\n",
    "\n",
    "    # =====================================================\n",
    "    # KSI: Zoning\n",
    "    # =====================================================\n",
    "    if use_ksi_zoning:\n",
    "        tr_zone_rank = func._get_or_zeros(train_df, 'zone_residential_rank')\n",
    "        te_zone_rank = func._get_or_zeros(test_df, 'zone_residential_rank')\n",
    "\n",
    "        tr_lowrise = func._get_or_zeros(train_df, 'is_lowrise_residential')\n",
    "        te_lowrise = func._get_or_zeros(test_df, 'is_lowrise_residential')\n",
    "\n",
    "        tr_kenpei = func._get_or_zeros(train_df, 'kenpei')\n",
    "        te_kenpei = func._get_or_zeros(test_df, 'kenpei')\n",
    "\n",
    "        tr_youseki = func._get_or_zeros(train_df, 'youseki')\n",
    "        te_youseki = func._get_or_zeros(test_df, 'youseki')\n",
    "\n",
    "        tr_zone_z, te_zone_z = _standardize_train_apply_test(tr_zone_rank, te_zone_rank)\n",
    "        tr_k_z, te_k_z = _standardize_train_apply_test(tr_kenpei, te_kenpei)\n",
    "        tr_y_z, te_y_z = _standardize_train_apply_test(tr_youseki, te_youseki)\n",
    "\n",
    "        train_df['ksi_zoning_score'] = (tr_zone_z + 0.7 * tr_lowrise + 0.2 * tr_k_z + 0.2 * tr_y_z) / 2.1\n",
    "        test_df['ksi_zoning_score'] = (te_zone_z + 0.7 * te_lowrise + 0.2 * te_k_z + 0.2 * te_y_z) / 2.1\n",
    "    else:\n",
    "        train_df['ksi_zoning_score'] = 0.0\n",
    "        test_df['ksi_zoning_score'] = 0.0\n",
    "\n",
    "    # =====================================================\n",
    "    # KSI: Geo-risk\n",
    "    # =====================================================\n",
    "    if use_ksi_geo_risk:\n",
    "        tr_slope_mean = func._get_or_zeros(train_df, 'slope_mean')\n",
    "        te_slope_mean = func._get_or_zeros(test_df, 'slope_mean')\n",
    "\n",
    "        tr_elev_range = func._get_or_zeros(train_df, 'elev_range')\n",
    "        te_elev_range = func._get_or_zeros(test_df, 'elev_range')\n",
    "\n",
    "        tr_slope_max = func._get_or_zeros(train_df, 'slope_max')\n",
    "        te_slope_max = func._get_or_zeros(test_df, 'slope_max')\n",
    "\n",
    "        tr_disaster = func._get_or_zeros(train_df, 'is_disaster_prevention_block')\n",
    "        te_disaster = func._get_or_zeros(test_df, 'is_disaster_prevention_block')\n",
    "\n",
    "        tr_sm_z, te_sm_z = _standardize_train_apply_test(tr_slope_mean, te_slope_mean)\n",
    "        tr_er_z, te_er_z = _standardize_train_apply_test(tr_elev_range, te_elev_range)\n",
    "        tr_sx_z, te_sx_z = _standardize_train_apply_test(tr_slope_max, te_slope_max)\n",
    "\n",
    "        train_df['ksi_geo_risk_score'] = - (0.5 * tr_sm_z + 0.3 * tr_er_z + 0.2 * tr_sx_z + 0.6 * tr_disaster)\n",
    "        test_df['ksi_geo_risk_score'] = - (0.5 * te_sm_z + 0.3 * te_er_z + 0.2 * te_sx_z + 0.6 * te_disaster)\n",
    "    else:\n",
    "        train_df['ksi_geo_risk_score'] = 0.0\n",
    "        test_df['ksi_geo_risk_score'] = 0.0\n",
    "\n",
    "    # =====================================================\n",
    "    # 4つのサブスコア（KSI + land_road_cond 注入）\n",
    "    # =====================================================\n",
    "    def _calc_subscores(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df['score_access'] = func._safe_mean(df, [\n",
    "            'access_station_score',\n",
    "            'neighbor_density_score',\n",
    "            'tag_env_score',\n",
    "        ]) + ksi_access_weight * df['ksi_road_access_score'] + land_road_weight * df['land_road_cond_score']\n",
    "\n",
    "        df['score_daily'] = func._safe_mean(df, [\n",
    "            'tag_env_score',\n",
    "            'tag_land_score',\n",
    "        ]) + rule_weight_in_daily * df['tag_rule_score'] + ksi_geo_risk_weight * df['ksi_geo_risk_score']\n",
    "\n",
    "        df['score_room'] = func._safe_mean(df, [\n",
    "            'tag_unit_score',\n",
    "            'room_space_score',\n",
    "        ])\n",
    "\n",
    "        df['score_building'] = func._safe_mean(df, [\n",
    "            'tag_building_score',\n",
    "            'tag_infra_score',\n",
    "            'tag_cert_score',\n",
    "        ]) + rule_weight_in_building * df['tag_rule_score'] + ksi_zoning_weight * df['ksi_zoning_score']\n",
    "\n",
    "        return df\n",
    "\n",
    "    train_df = _calc_subscores(train_df)\n",
    "    test_df = _calc_subscores(test_df)\n",
    "\n",
    "    meta = {\n",
    "        'tag_groups': tag_groups,\n",
    "        'subscores': ['score_access', 'score_daily', 'score_room', 'score_building'],\n",
    "        'use_rule_tags': use_rule_tags,\n",
    "        'rule_weights': {\n",
    "            'daily': rule_weight_in_daily,\n",
    "            'building': rule_weight_in_building,\n",
    "        },\n",
    "        'ksi': {\n",
    "            'use_ksi_access': use_ksi_access,\n",
    "            'use_ksi_zoning': use_ksi_zoning,\n",
    "            'use_ksi_geo_risk': use_ksi_geo_risk,\n",
    "            'weights': {\n",
    "                'ksi_access_weight': ksi_access_weight,\n",
    "                'ksi_zoning_weight': ksi_zoning_weight,\n",
    "                'ksi_geo_risk_weight': ksi_geo_risk_weight,\n",
    "            },\n",
    "            'scores_added': [\n",
    "                'ksi_road_access_score',\n",
    "                'ksi_zoning_score',\n",
    "                'ksi_geo_risk_score',\n",
    "            ],\n",
    "        },\n",
    "        'land_road_cond': {\n",
    "            'use_land_road_cond': use_land_road_cond,\n",
    "            'land_road_weight': land_road_weight,\n",
    "            'land_road_map': land_road_map,\n",
    "            'score_col': 'land_road_cond_score',\n",
    "        },\n",
    "        'rule_tags_used': {\n",
    "            'bonus': [k for k in TAG_RULES['bonus'].keys() if k in train_df.columns],\n",
    "            'penalty': [k for k in TAG_RULES['penalty'].keys() if k in train_df.columns],\n",
    "        },\n",
    "    }\n",
    "    return train_df, test_df, meta\n",
    "\n",
    "\n",
    "def fit_livability_weight_model(\n",
    "    train_df: pd.DataFrame,\n",
    "    target_col: str = 'money_room',\n",
    "    alpha: float = 1.0,\n",
    ") -> tuple[Ridge, list[str]]:\n",
    "\n",
    "    required_cols = ['urban_score', 'score_access', 'score_daily', 'score_room', 'score_building']\n",
    "    for c in required_cols + [target_col]:\n",
    "        if c not in train_df.columns:\n",
    "            raise KeyError(f'必要な列が存在しません: {c}')\n",
    "\n",
    "    df = train_df.dropna(subset=[target_col]).copy()\n",
    "    y = df[target_col].astype(float)\n",
    "\n",
    "    y_std = (y - y.mean()) / y.std()\n",
    "\n",
    "    X_parts = []\n",
    "    feature_names = []\n",
    "\n",
    "    X_parts.append(df[required_cols].astype(float).values)\n",
    "    feature_names.extend(required_cols)\n",
    "\n",
    "    for col in ['score_access', 'score_daily', 'score_room', 'score_building']:\n",
    "        inter_name = f'{col}_x_urban'\n",
    "        X_parts.append((df[col] * df['urban_score']).values.reshape(-1, 1))\n",
    "        feature_names.append(inter_name)\n",
    "\n",
    "    X = np.hstack(X_parts)\n",
    "\n",
    "    model = Ridge(alpha=alpha, random_state=42)\n",
    "    model.fit(X, y_std)\n",
    "\n",
    "    return model, feature_names\n",
    "\n",
    "\n",
    "def apply_livability_score(\n",
    "    df: pd.DataFrame,\n",
    "    model: Ridge,\n",
    "    train_min: float,\n",
    "    train_max: float,\n",
    ") -> pd.Series:\n",
    "\n",
    "    base_cols = ['urban_score', 'score_access', 'score_daily', 'score_room', 'score_building']\n",
    "\n",
    "    X_parts = [df[base_cols].astype(float).values]\n",
    "    for col in ['score_access', 'score_daily', 'score_room', 'score_building']:\n",
    "        X_parts.append((df[col] * df['urban_score']).values.reshape(-1, 1))\n",
    "    X = np.hstack(X_parts)\n",
    "\n",
    "    liv_raw = model.predict(X)\n",
    "\n",
    "    if train_max == train_min:\n",
    "        return pd.Series(50.0, index=df.index)\n",
    "\n",
    "    liv_scaled = (liv_raw - train_min) / (train_max - train_min)\n",
    "    liv_scaled = liv_scaled.clip(0, 1) * 100.0\n",
    "    return pd.Series(liv_scaled, index=df.index)\n",
    "\n",
    "\n",
    "def add_livability_features_ksi(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    target_col: str = 'money_room',\n",
    "    alpha: float = 1.0,\n",
    "    use_rule_tags: bool = True,\n",
    "    rule_weight_in_daily: float = 0.6,\n",
    "    rule_weight_in_building: float = 0.8,\n",
    "    use_ksi_access: bool = True,\n",
    "    use_ksi_zoning: bool = True,\n",
    "    use_ksi_geo_risk: bool = True,\n",
    "    ksi_access_weight: float = 0.7,\n",
    "    ksi_zoning_weight: float = 0.6,\n",
    "    ksi_geo_risk_weight: float = 0.5,\n",
    "    # === land_road_cond: 追加 ===\n",
    "    use_land_road_cond: bool = True,\n",
    "    land_road_weight: float = 0.6,\n",
    "    land_road_map: dict[int, float] | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "\n",
    "    train_u, test_u, urban_meta = make_urban_score(train_df, test_df)\n",
    "\n",
    "    train_s, test_s, subs_meta = make_livability_subscores_ksi(\n",
    "        train_u,\n",
    "        test_u,\n",
    "        use_rule_tags=use_rule_tags,\n",
    "        rule_weight_in_daily=rule_weight_in_daily,\n",
    "        rule_weight_in_building=rule_weight_in_building,\n",
    "        use_ksi_access=use_ksi_access,\n",
    "        use_ksi_zoning=use_ksi_zoning,\n",
    "        use_ksi_geo_risk=use_ksi_geo_risk,\n",
    "        ksi_access_weight=ksi_access_weight,\n",
    "        ksi_zoning_weight=ksi_zoning_weight,\n",
    "        ksi_geo_risk_weight=ksi_geo_risk_weight,\n",
    "        use_land_road_cond=use_land_road_cond,\n",
    "        land_road_weight=land_road_weight,\n",
    "        land_road_map=land_road_map,\n",
    "    )\n",
    "\n",
    "    model, feature_names = fit_livability_weight_model(\n",
    "        train_s, target_col=target_col, alpha=alpha\n",
    "    )\n",
    "\n",
    "    base_cols = ['urban_score', 'score_access', 'score_daily', 'score_room', 'score_building']\n",
    "    raw_tmp = model.predict(np.hstack([\n",
    "        train_s[base_cols].astype(float).values,\n",
    "        (train_s['score_access'] * train_s['urban_score']).values.reshape(-1, 1),\n",
    "        (train_s['score_daily'] * train_s['urban_score']).values.reshape(-1, 1),\n",
    "        (train_s['score_room'] * train_s['urban_score']).values.reshape(-1, 1),\n",
    "        (train_s['score_building'] * train_s['urban_score']).values.reshape(-1, 1),\n",
    "    ]))\n",
    "    train_min = float(np.nanmin(raw_tmp))\n",
    "    train_max = float(np.nanmax(raw_tmp))\n",
    "\n",
    "    train_s['livability_score'] = apply_livability_score(train_s, model, train_min, train_max)\n",
    "    test_s['livability_score'] = apply_livability_score(test_s, model, train_min, train_max)\n",
    "\n",
    "    meta = {\n",
    "        'urban_meta': urban_meta,\n",
    "        'subscores_meta': subs_meta,\n",
    "        'model': model,\n",
    "        'feature_names': feature_names,\n",
    "        'train_min': train_min,\n",
    "        'train_max': train_max,\n",
    "    }\n",
    "    return train_s, test_s, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "682696fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe, meta = add_livability_features_ksi(\n",
    "    train_df=train_df_fe,\n",
    "    test_df=test_df_fe,\n",
    "    target_col='money_room',\n",
    "    use_land_road_cond=True,\n",
    "    land_road_weight=0.6,  # 強すぎたら 0.3 へ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d814fa",
   "metadata": {},
   "source": [
    "## 道路関連"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7950c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df_fe, test_df_fe]:\n",
    "    df['is_no_road'] = (df['land_road_cond'] == 10).astype('int8')\n",
    "    df['road_len_density_x_no_road'] = (df['road_len_density'] * df['is_no_road']).astype('float32')\n",
    "    df['road_narrow_ratio_gap_x_no_road'] = (df['road_narrow_ratio_gap'] * df['is_no_road']).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002e392",
   "metadata": {},
   "source": [
    "## 用途地域関連"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20839c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_max_floor_area_features(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    tochi_area_col: str = 'tochi_area',\n",
    "    youseki_col: str = 'youseki',\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # 数値化（列が無ければ作って NaN）\n",
    "    if tochi_area_col not in out.columns:\n",
    "        out[tochi_area_col] = np.nan\n",
    "    if youseki_col not in out.columns:\n",
    "        out[youseki_col] = np.nan\n",
    "\n",
    "    out[tochi_area_col] = pd.to_numeric(out[tochi_area_col], errors='coerce')\n",
    "    out[youseki_col] = pd.to_numeric(out[youseki_col], errors='coerce')\n",
    "\n",
    "    # invalid: 容積率<=0 or 土地<=0 or どちらか欠損\n",
    "    invalid = (\n",
    "        out[youseki_col].isna() | (out[youseki_col] <= 0) |\n",
    "        out[tochi_area_col].isna() | (out[tochi_area_col] <= 0)\n",
    "    )\n",
    "\n",
    "    out['max_floor_area'] = out[tochi_area_col] * out[youseki_col] / 100.0\n",
    "    out.loc[invalid, 'max_floor_area'] = np.nan\n",
    "\n",
    "    # log1p: NaN は NaN のまま（欠損=0にしない）\n",
    "    out['max_floor_area_log'] = np.where(\n",
    "        out['max_floor_area'].notna(),\n",
    "        np.log1p(out['max_floor_area']),\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "    out['max_floor_area_missing'] = out['max_floor_area'].isna().astype('int8')\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_lowrise_station_interaction(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    lowrise_col: str = 'is_lowrise_residential',\n",
    "    station_min_col: str = 'door_to_station_min_log',\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    low = out[lowrise_col] if lowrise_col in out.columns else 0\n",
    "    sta = out[station_min_col] if station_min_col in out.columns else 0.0\n",
    "\n",
    "    low = pd.to_numeric(low, errors='coerce').fillna(0).astype('int8')\n",
    "    sta = pd.to_numeric(sta, errors='coerce')\n",
    "\n",
    "    # 欠損は 0 に寄せる（interaction は「情報なし→影響なし」にする）\n",
    "    out['lowrise_x_station_log'] = low * sta.fillna(0.0)\n",
    "    out['lowrise_x_station_missing'] = (low.eq(1) & sta.isna()).astype('int8')\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_lowrise_landprice_interaction(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    lowrise_col: str = 'is_lowrise_residential',\n",
    "    land_price_log_col: str = 'log_land_price',\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    low = out[lowrise_col] if lowrise_col in out.columns else 0\n",
    "    lp = out[land_price_log_col] if land_price_log_col in out.columns else 0.0\n",
    "\n",
    "    low = pd.to_numeric(low, errors='coerce').fillna(0).astype('int8')\n",
    "    lp = pd.to_numeric(lp, errors='coerce')\n",
    "\n",
    "    out['lowrise_x_landprice_log'] = low * lp.fillna(0.0)\n",
    "    out['lowrise_x_landprice_missing'] = (low.eq(1) & lp.isna()).astype('int8')\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_house_key_interactions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out = add_max_floor_area_features(out)\n",
    "    out = add_lowrise_station_interaction(out)\n",
    "    out = add_lowrise_landprice_interaction(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fa3e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_house_key_interactions(train_df_fe)\n",
    "test_df_fe = add_house_key_interactions(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f0b6c",
   "metadata": {},
   "source": [
    "## 都市計画関連"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5313efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cityplan_interactions(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    land_price_log_col: str = 'log_land_price',\n",
    "    max_floor_area_log_col: str = 'max_floor_area_log',\n",
    "    station_log_col: str = 'door_to_station_min_log',\n",
    "    youseki_col: str = 'youseki',\n",
    "    is_urban_control_col: str = 'is_urban_control_area',\n",
    "    is_fireproof_col: str = 'is_fireproof_area',\n",
    "    has_district_plan_col: str = 'has_district_plan',\n",
    "    is_high_util_col: str = 'is_high_utilization_area',\n",
    "    has_height_limit_col: str = 'has_height_limit',\n",
    "    is_urban_renaissance_col: str = 'is_urban_renaissance_area',\n",
    "    clip_youseki: float | None = None,\n",
    "    station_sign: int = -1,          # -1: 近いほどプラス, +1: 遠いほどプラス\n",
    "    youseki_scale: str = 'ratio',    # 'raw' | 'ratio' | 'log'\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # station（方向を揃える）\n",
    "    station = func._num0(out, station_log_col) * float(station_sign)\n",
    "\n",
    "    # youseki（スケール調整）\n",
    "    y = func._num0(out, youseki_col)\n",
    "    if clip_youseki is not None:\n",
    "        y = y.clip(upper=float(clip_youseki))\n",
    "    if youseki_scale == 'ratio':\n",
    "        y = y / 100.0\n",
    "    elif youseki_scale == 'log':\n",
    "        y = np.log1p(y)\n",
    "    elif youseki_scale != 'raw':\n",
    "        raise ValueError('youseki_scale must be one of: raw, ratio, log')\n",
    "\n",
    "    if is_urban_control_col in out.columns and land_price_log_col in out.columns:\n",
    "        func._add(out, 'urban_control_x_land_price_log', func._flag(out, is_urban_control_col) * func._num0(out, land_price_log_col))\n",
    "\n",
    "    if is_fireproof_col in out.columns and max_floor_area_log_col in out.columns:\n",
    "        func._add(out, 'fireproof_x_max_floor_area_log', func._flag(out, is_fireproof_col) * func._num0(out, max_floor_area_log_col))\n",
    "\n",
    "    if has_district_plan_col in out.columns and station_log_col in out.columns:\n",
    "        func._add(out, 'district_plan_x_station_log', func._flag(out, has_district_plan_col) * station)\n",
    "\n",
    "    if is_high_util_col in out.columns and youseki_col in out.columns:\n",
    "        func._add(out, 'high_util_x_youseki', func._flag(out, is_high_util_col) * y)\n",
    "\n",
    "    if has_height_limit_col in out.columns and max_floor_area_log_col in out.columns:\n",
    "        func._add(out, 'height_limit_x_max_floor_area_log', func._flag(out, has_height_limit_col) * func._num0(out, max_floor_area_log_col))\n",
    "\n",
    "    if is_urban_renaissance_col in out.columns and station_log_col in out.columns:\n",
    "        func._add(out, 'urban_renaissance_x_station_log', func._flag(out, is_urban_renaissance_col) * station)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ec03fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fireproof_x_structure_cat_both(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    *,\n",
    "    is_fireproof_col: str = 'is_fireproof_area',\n",
    "    structure_col: str = 'building_structure',\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "\n",
    "    # 欠損列があっても落ちないように用意\n",
    "    if is_fireproof_col not in tr.columns:\n",
    "        tr[is_fireproof_col] = 0\n",
    "    if is_fireproof_col not in te.columns:\n",
    "        te[is_fireproof_col] = 0\n",
    "    if structure_col not in tr.columns:\n",
    "        tr[structure_col] = 'missing'\n",
    "    if structure_col not in te.columns:\n",
    "        te[structure_col] = 'missing'\n",
    "\n",
    "    fire_tr = pd.to_numeric(tr[is_fireproof_col], errors='coerce').fillna(0).astype('int8')\n",
    "    fire_te = pd.to_numeric(te[is_fireproof_col], errors='coerce').fillna(0).astype('int8')\n",
    "\n",
    "    # string dtypeにして欠損を埋める（NAを残さない）\n",
    "    s_tr = tr[structure_col].astype('string').fillna('missing')\n",
    "    s_te = te[structure_col].astype('string').fillna('missing')\n",
    "\n",
    "    # 'fire' / 'nonfire' を Series として作る\n",
    "    prefix_tr = pd.Series(np.where(fire_tr.to_numpy() == 1, 'fire', 'nonfire'), index=tr.index, dtype='string')\n",
    "    prefix_te = pd.Series(np.where(fire_te.to_numpy() == 1, 'fire', 'nonfire'), index=te.index, dtype='string')\n",
    "\n",
    "    # pandas の文字列結合（dtype事故回避）\n",
    "    tr_col = prefix_tr.str.cat(s_tr, sep='_')\n",
    "    te_col = prefix_te.str.cat(s_te, sep='_')\n",
    "\n",
    "    # カテゴリ集合を統一（train+test）\n",
    "    cats = pd.Index(pd.concat([tr_col, te_col], axis=0).unique())\n",
    "\n",
    "    tr['fireproof_x_structure'] = pd.Categorical(tr_col, categories=cats)\n",
    "    te['fireproof_x_structure'] = pd.Categorical(te_col, categories=cats)\n",
    "\n",
    "    return tr, te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f4d2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_cityplan_interactions(train_df_fe, clip_youseki=800, station_sign=-1, youseki_scale='ratio')\n",
    "test_df_fe  = add_cityplan_interactions(test_df_fe,  clip_youseki=800, station_sign=-1, youseki_scale='ratio')\n",
    "\n",
    "train_df_fe, test_df_fe = add_fireproof_x_structure_cat_both(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b4d07",
   "metadata": {},
   "source": [
    "## セットバック比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f84152cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df_fe, test_df_fe]:\n",
    "    denom = df['shikichi_area'].fillna(df['tochi_area']).fillna(df['kukaku_area'])\n",
    "    df['setback_ratio'] = df['land_setback_clean'] / denom\n",
    "    df.loc[denom <= 0, 'setback_ratio'] = np.nan\n",
    "    df['setback_ratio'] = df['setback_ratio'].clip(0, 1)  # 物理的におかしい比率を抑制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99167965",
   "metadata": {},
   "source": [
    "## 土地制約・再建築リスクスコア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bdd49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_constraint_score(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    score = 0.0\n",
    "\n",
    "    # 建ぺい率・容積率（低いほど制約が強い）\n",
    "    if 'kenpei' in out:\n",
    "        score += (100 - out['kenpei'].clip(0, 100)) / 100\n",
    "\n",
    "    if 'youseki' in out:\n",
    "        score += (200 - out['youseki'].clip(0, 200)) / 200\n",
    "\n",
    "    # 接道・セットバック\n",
    "    score += out.get('has_setback', 0) * 1.0\n",
    "    score += out.get('land_setback_log', 0).fillna(0) * 0.3\n",
    "    score += out.get('setback_ratio', 0).fillna(0) * 2.0\n",
    "    score += out.get('is_no_road', 0) * 2.0\n",
    "\n",
    "    # 私道負担\n",
    "    if 'shidou_area_ratio' in out:\n",
    "        score += out['shidou_area_ratio'].fillna(0).clip(0, 1)\n",
    "\n",
    "    out['land_constraint_score'] = score\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37b10bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_land_constraint_score(train_df_fe)\n",
    "test_df_fe = add_land_constraint_score(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581361d",
   "metadata": {},
   "source": [
    "## premium 設備カウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b8ec410",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREMIUM_EQUIP_COLS = [\n",
    "    '専有部分設備_空調・暖房_床暖房',\n",
    "    '専有部分設備_キッチン_食器洗い乾燥機',\n",
    "    '専有部分設備_浴室・洗面_浴室乾燥機',\n",
    "    '専有部分設備_収納_ウォークインクローゼット',\n",
    "]\n",
    "\n",
    "def add_premium_equipment_count(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    cols = [c for c in PREMIUM_EQUIP_COLS if c in out.columns]\n",
    "    out['premium_equipment_count'] = out[cols].sum(axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8f81378",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_premium_equipment_count(train_df_fe)\n",
    "test_df_fe = add_premium_equipment_count(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6ab29",
   "metadata": {},
   "source": [
    "## 地価関連の交互作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "062f7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_price_interactions(\n",
    "    df: pd.DataFrame,\n",
    "    land_log_cols: tuple[str, ...] = (\n",
    "        'log_land_price',\n",
    "        'log_weighted_land_price_3',\n",
    "        'land_theoretical_price',\n",
    "        'land_theoretical_price_weighted',\n",
    "        'land_theoretical_price_within1km_mp',\n",
    "    ),\n",
    "    age_col: str = 'effective_age',\n",
    "    livability_col: str = 'livability_score',\n",
    "    urban_col: str = 'urban_score',\n",
    "    structure_col: str = 'building_structure',\n",
    "    taus: tuple[float, ...] = (30.0,),\n",
    "    max_age_clip: float = 200.0,\n",
    "    add_structure_interactions: bool = True,\n",
    "    add_structure_group_cat: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    土地価格（log系）× 建物属性 interaction（v2：building_structure が数値コード前提）\n",
    "\n",
    "    building_structure コード:\n",
    "      1:木造 2:ブロック 3:鉄骨造 4:RC 5:SRC 6:PC 7:HPC 9:その他\n",
    "      10:軽量鉄骨 11:ALC 12:鉄筋ブロック 13:CFT\n",
    "\n",
    "    追加（代表）\n",
    "      - {land}_x_effective_age\n",
    "      - {land}_x_age_decay_{tau}\n",
    "      - {land}_x_livability_score / {land}_x_urban_score\n",
    "      - {land}_x_is_wood / _x_is_steel / _x_is_rcsrc / _x_is_precast / _x_is_block / _x_is_other\n",
    "      - （任意）structure_group（カテゴリ）も付与\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # --- age ---\n",
    "    age = func._as_numeric(out.get(age_col))\n",
    "    if age is None:\n",
    "        return out\n",
    "    age_log1p = func._safe_log1p(age)\n",
    "\n",
    "    age_decay_map: dict[int, pd.Series] = {}\n",
    "    for tau in taus:\n",
    "        t = int(float(tau))\n",
    "        decay = np.exp(-age / float(t)).astype(float)\n",
    "        out[f'age_decay_{t}'] = decay\n",
    "        age_decay_map[t] = decay\n",
    "\n",
    "    # --- other continuous ---\n",
    "    liv = func._as_numeric(out.get(livability_col))\n",
    "    urb = func._as_numeric(out.get(urban_col))\n",
    "\n",
    "    # --- structure flags from code ---\n",
    "    struct = func._as_numeric(out.get(structure_col))\n",
    "    if add_structure_interactions and struct is not None:\n",
    "        # 主要グループに集約（必要なら調整）\n",
    "        is_wood = (struct == 1).astype('int8')\n",
    "\n",
    "        # 鉄骨系：鉄骨造(3) + 軽量鉄骨(10) + CFT(13)\n",
    "        is_steel = (struct.isin([3, 10, 13])).astype('int8')\n",
    "\n",
    "        # RC/SRC\n",
    "        is_rcsrc = (struct.isin([4, 5])).astype('int8')\n",
    "\n",
    "        # プレキャスト系：PC(6) + HPC(7)\n",
    "        is_precast = (struct.isin([6, 7])).astype('int8')\n",
    "\n",
    "        # ブロック系：ブロック(2) + 鉄筋ブロック(12)\n",
    "        is_block = (struct.isin([2, 12])).astype('int8')\n",
    "\n",
    "        # その他（欠損含めて別途フラグ化したいなら）\n",
    "        is_other = (struct.isin([9, 11])).astype('int8')  # 9:その他, 11:ALC\n",
    "\n",
    "        out['is_wood'] = is_wood\n",
    "        out['is_steel'] = is_steel\n",
    "        out['is_rcsrc'] = is_rcsrc\n",
    "        out['is_precast'] = is_precast\n",
    "        out['is_block'] = is_block\n",
    "        out['is_other_structure'] = is_other\n",
    "\n",
    "        if add_structure_group_cat:\n",
    "            # カテゴリ（CatBoostでそのまま使う/LightGBMならカテゴリ扱い可）\n",
    "            # 優先順位で割り当て（複数に該当しない設計だが念のため）\n",
    "            group = pd.Series('missing', index=out.index, dtype='string')\n",
    "            group = group.mask(is_wood == 1, 'wood')\n",
    "            group = group.mask(is_rcsrc == 1, 'rcsrc')\n",
    "            group = group.mask(is_steel == 1, 'steel')\n",
    "            group = group.mask(is_precast == 1, 'precast')\n",
    "            group = group.mask(is_block == 1, 'block')\n",
    "            group = group.mask(is_other == 1, 'other')\n",
    "            out['structure_group'] = group\n",
    "\n",
    "    # --- land cols ---\n",
    "    used_land_cols = [c for c in land_log_cols if c in out.columns]\n",
    "    if not used_land_cols:\n",
    "        return out\n",
    "\n",
    "    for lc in used_land_cols:\n",
    "        landv = func._as_numeric(out.get(lc))\n",
    "        if landv is None:\n",
    "            continue\n",
    "\n",
    "        # 土地×築年数（線形/対数）\n",
    "        out[f'{lc}_x_effective_age'] = landv * age\n",
    "        out[f'{lc}_x_age_log1p'] = landv * age_log1p\n",
    "\n",
    "        # 土地×築年数（減衰）\n",
    "        for t, decay in age_decay_map.items():\n",
    "            out[f'{lc}_x_age_decay_{t}'] = landv * decay\n",
    "\n",
    "        # 土地×都市性\n",
    "        if liv is not None:\n",
    "            out[f'{lc}_x_{livability_col}'] = landv * liv\n",
    "        if urb is not None:\n",
    "            out[f'{lc}_x_{urban_col}'] = landv * urb\n",
    "\n",
    "        # 土地×構造（グループフラグ）\n",
    "        if add_structure_interactions and struct is not None:\n",
    "            out[f'{lc}_x_is_wood'] = landv * out['is_wood']\n",
    "            out[f'{lc}_x_is_steel'] = landv * out['is_steel']\n",
    "            out[f'{lc}_x_is_rcsrc'] = landv * out['is_rcsrc']\n",
    "            out[f'{lc}_x_is_precast'] = landv * out['is_precast']\n",
    "            out[f'{lc}_x_is_block'] = landv * out['is_block']\n",
    "            out[f'{lc}_x_is_other_structure'] = landv * out['is_other_structure']\n",
    "\n",
    "    return out\n",
    "\n",
    "def add_land_x_area_interactions(\n",
    "    df: pd.DataFrame,\n",
    "    land_log_cols: tuple[str, ...] = (\n",
    "        'land_theoretical_price',\n",
    "        'land_theoretical_price_weighted',\n",
    "        'land_theoretical_price_within1km_mp',\n",
    "        'log_land_price',\n",
    "        'log_weighted_land_price_3',\n",
    "    ),\n",
    "    senyu_area_log_col: str = 'senyu_area_log',\n",
    "    kukaku_area_log_col: str = 'kukaku_area_log',\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    低コストで当たりやすい「土地価格（log）× 面積（log）」を追加。\n",
    "    - {land_col}_x_senyu_area_log\n",
    "    - {land_col}_x_kukaku_area_log\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    senyu = func._as_numeric(out.get(senyu_area_log_col))\n",
    "    kukaku = func._as_numeric(out.get(kukaku_area_log_col))\n",
    "\n",
    "    used_land_cols = [c for c in land_log_cols if c in out.columns]\n",
    "    if len(used_land_cols) == 0:\n",
    "        return out\n",
    "\n",
    "    for lc in used_land_cols:\n",
    "        landv = func._as_numeric(out.get(lc))\n",
    "        if landv is None:\n",
    "            continue\n",
    "        if senyu is not None:\n",
    "            out[f'{lc}_x_{senyu_area_log_col}'] = landv * senyu\n",
    "        if kukaku is not None:\n",
    "            out[f'{lc}_x_{kukaku_area_log_col}'] = landv * kukaku\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_land_interactions(\n",
    "    df: pd.DataFrame,\n",
    "    taus: tuple[float, ...] = (30.0,),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    まず試す用のまとめ関数（必要最低限）。\n",
    "    - 土地×築年数（linear + decay）\n",
    "    - 土地×livability / urban\n",
    "    - 土地×面積（senyu / kukaku）\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    out = add_land_price_interactions(\n",
    "        out,\n",
    "        taus=taus,\n",
    "        add_structure_interactions=True,\n",
    "        add_structure_group_cat=True,\n",
    "    )\n",
    "    # out = add_land_x_area_interactions(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06a27e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_land_interactions(train_df_fe, taus=(30.0,))\n",
    "test_df_fe = add_land_interactions(test_df_fe, taus=(30.0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257b8f4",
   "metadata": {},
   "source": [
    "## 駅力スコアの交互作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9e81191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_station_power_x_land(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     out = df.copy()\n",
    "\n",
    "#     land_cols = [\n",
    "#         'log_weighted_land_price_3',\n",
    "#         'land_theoretical_price_weighted',\n",
    "#     ]\n",
    "\n",
    "#     for lc in land_cols:\n",
    "#         if lc in out.columns:\n",
    "#             out[f'station_power_max3_x_{lc}'] = (\n",
    "#                 out['station_power_max3'] * out[lc]\n",
    "#             )\n",
    "#             out[f'station_power_sum3_x_{lc}'] = (\n",
    "#                 out['station_power_sum3'] * out[lc]\n",
    "#             )\n",
    "\n",
    "#     return out\n",
    "\n",
    "# def add_station_power_x_age(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     out = df.copy()\n",
    "\n",
    "#     if 'age_decay_30' in out.columns:\n",
    "#         out['station_power_max3_x_age_decay_30'] = (\n",
    "#             out['station_power_max3'] * out['age_decay_30']\n",
    "#         )\n",
    "\n",
    "#     return out\n",
    "\n",
    "# def add_station_power_x_livability(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     out = df.copy()\n",
    "\n",
    "#     if 'livability_score' in out.columns:\n",
    "#         out['station_power_max3_x_livability'] = (\n",
    "#             out['station_power_max3'] * out['livability_score']\n",
    "#         )\n",
    "\n",
    "#     return out\n",
    "\n",
    "# def add_station_power_x_structure(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     out = df.copy()\n",
    "\n",
    "#     for g in ['is_wood', 'is_rcsrc']:\n",
    "#         if g in out.columns:\n",
    "#             out[f'station_power_max3_x_{g}'] = (\n",
    "#                 out['station_power_max3'] * out[g]\n",
    "#             )\n",
    "\n",
    "#     return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d9f7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_fe = add_station_power_x_land(train_df_fe)\n",
    "# test_df_fe = add_station_power_x_land(test_df_fe)\n",
    "\n",
    "# train_df_fe = add_station_power_x_age(train_df_fe)\n",
    "# test_df_fe = add_station_power_x_age(test_df_fe)\n",
    "\n",
    "# train_df_fe = add_station_power_x_livability(train_df_fe)\n",
    "# test_df_fe = add_station_power_x_livability(test_df_fe)\n",
    "\n",
    "# train_df_fe = add_station_power_x_structure(train_df_fe)\n",
    "# test_df_fe = add_station_power_x_structure(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4eb8c",
   "metadata": {},
   "source": [
    "## タグ情報の集約"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b67d86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_price_improving_features_from_tags(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    keep_original_cols: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    タグ系（0/1想定）から、価格決定構造に沿った集約特徴量を作成する。\n",
    "\n",
    "    目的：\n",
    "      - 過剰予測を抑えるための「ディスカウント理由」を明示\n",
    "      - 列数を爆増させずに、意味単位のスコアへ圧縮\n",
    "      - 存在する列だけで安全に動く\n",
    "\n",
    "    想定：\n",
    "      - タグ列は 0/1 (または True/False) が基本\n",
    "      - df は train/test どちらでも可（タグが無ければ0埋め）\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1) 強ディスカウント（個別保持）\n",
    "    # ----------------------------\n",
    "    hard_penalty_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '専有部分設備_トイレ_トイレなし',\n",
    "            '専有部分設備_浴室・洗面_バスなし',\n",
    "            '専有部分設備_トイレ_共同トイレ',\n",
    "            '専有部分設備_浴室・洗面_共同バス',\n",
    "            '建物設備（給排水・インフラ）_汲取',\n",
    "            '建物設備（給排水・インフラ）_浄化槽',\n",
    "        ],\n",
    "    )\n",
    "    # 個別列は keep_original_cols=False のとき落とす可能性があるため、\n",
    "    # 集約フラグも作っておく\n",
    "    out['hard_penalty_any'] = func._any_cols(out, hard_penalty_cols, 'hard_penalty_any')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2) 土地タグ：形状・接道プレミアム/ペナルティ\n",
    "    # ----------------------------\n",
    "    land_premium_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '土地価格_角地',\n",
    "            '土地価格_南道路',\n",
    "            '土地価格_整形地',\n",
    "            '土地価格_低層住宅地',\n",
    "        ],\n",
    "    )\n",
    "    land_penalty_cols = func._existing_cols(out, ['土地価格_敷地延長・変形地'])\n",
    "\n",
    "    out['tag_land_premium_score'] = func._sum_cols(out, land_premium_cols, 'tag_land_premium_score')\n",
    "    out['tag_land_penalty_flag'] = func._any_cols(out, land_penalty_cols, 'tag_land_penalty_flag')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3) キッチングレード（階層化）\n",
    "    # ----------------------------\n",
    "    kitchen_base_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '専有部分設備_キッチン_システムキッチン',\n",
    "            '専有部分設備_キッチン_カウンターキッチン',\n",
    "            '専有部分設備_キッチン_食器洗い乾燥機',\n",
    "            '専有部分設備_キッチン_ディスポーザー',\n",
    "            '専有部分設備_キッチン_浄水器・活水器',\n",
    "            '専有部分設備_キッチン_冷蔵庫あり',\n",
    "            '専有部分設備_キッチン_IHコンロ',\n",
    "            '専有部分設備_キッチン_ガスコンロ',\n",
    "            '専有部分設備_キッチン_電気コンロ',\n",
    "            '専有部分設備_キッチン_給湯',\n",
    "        ],\n",
    "    )\n",
    "    # 口数は順序を入れる（存在する列だけ評価）\n",
    "    burner_map = {\n",
    "        '専有部分設備_キッチン_コンロ一口': 0,\n",
    "        '専有部分設備_キッチン_コンロ二口': 1,\n",
    "        '専有部分設備_キッチン_コンロ三口': 2,\n",
    "        '専有部分設備_キッチン_コンロ四口以上': 3,\n",
    "    }\n",
    "    burner_cols = func._existing_cols(out, burner_map.keys())\n",
    "\n",
    "    out['kitchen_upgrade_count'] = func._sum_cols(out, kitchen_base_cols, 'kitchen_upgrade_count')\n",
    "\n",
    "    if burner_cols:\n",
    "        # 0/1列のうち「該当している口数」を値として取り出す（複数立つことは通常ない想定）\n",
    "        burner_score = np.zeros(len(out), dtype=np.float32)\n",
    "        for c in burner_cols:\n",
    "            burner_score = np.maximum(burner_score, out[c].fillna(0).astype('float32') * burner_map[c])\n",
    "        out['kitchen_burner_score'] = burner_score\n",
    "    else:\n",
    "        out['kitchen_burner_score'] = 0.0\n",
    "\n",
    "    # 総合（重みは軽め。強くしたいなら後で調整）\n",
    "    out['kitchen_grade_score'] = (\n",
    "        out['kitchen_upgrade_count'].astype('float32') + out['kitchen_burner_score'].astype('float32')\n",
    "    )\n",
    "\n",
    "    # 低グレードシグナル（MAPEで過剰予測抑制に効きやすい）\n",
    "    out['kitchen_low_flag'] = func._any_cols(out, func._existing_cols(out, ['専有部分設備_キッチン_コンロ一口']), 'kitchen_low_flag')\n",
    "    out['kitchen_high_flag'] = (\n",
    "        (out['kitchen_grade_score'].astype('float32') >= 3.0).astype('int8')\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4) 水回り（浴室・洗面）グレード\n",
    "    # ----------------------------\n",
    "    wet_positive_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '専有部分設備_浴室・洗面_追焚機能',\n",
    "            '専有部分設備_浴室・洗面_浴室乾燥機',\n",
    "            '専有部分設備_浴室・洗面_浴室暖房',\n",
    "            '専有部分設備_浴室・洗面_オートバス',\n",
    "            '専有部分設備_浴室・洗面_洗面所独立',\n",
    "            '専有部分設備_浴室・洗面_シャワー付洗面化粧台',\n",
    "            '専有部分設備_浴室・洗面_浴室TV',\n",
    "            '専有部分設備_浴室・洗面_高温差湯式',\n",
    "            '専有部分設備_浴室・洗面_浴室1.6×1.8M以上',\n",
    "            '専有部分設備_浴室・洗面_浴室1.6×2.0M以上',\n",
    "        ],\n",
    "    )\n",
    "    wet_separation_cols = func._existing_cols(out, ['専有部分設備_浴室・洗面_バス・トイレ別'])\n",
    "    # バスなし/共同バスは hard_penalty で個別保持済み\n",
    "\n",
    "    out['wet_area_upgrade_count'] = func._sum_cols(out, wet_positive_cols, 'wet_area_upgrade_count')\n",
    "    out['wet_area_separation_flag'] = func._any_cols(out, wet_separation_cols, 'wet_area_separation_flag')\n",
    "    out['wet_area_grade_score'] = (\n",
    "        out['wet_area_upgrade_count'].astype('float32') + 1.0 * out['wet_area_separation_flag'].astype('float32')\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5) トイレグレード（温水洗浄便座など）\n",
    "    # ----------------------------\n",
    "    toilet_positive_cols = func._existing_cols(out, ['専有部分設備_トイレ_温水洗浄便座', '専有部分設備_トイレ_専用トイレ'])\n",
    "    out['toilet_upgrade_count'] = func._sum_cols(out, toilet_positive_cols, 'toilet_upgrade_count')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 6) 収納スコア\n",
    "    # ----------------------------\n",
    "    storage_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '専有部分設備_収納_ウォークインクローゼット',\n",
    "            '専有部分設備_収納_シューズインクローゼット',\n",
    "            '専有部分設備_収納_シューズクローク',\n",
    "            '専有部分設備_収納_パントリー',\n",
    "            '専有部分設備_収納_トランクルーム',\n",
    "            '専有部分設備_収納_全居室収納',\n",
    "            '専有部分設備_収納_床下収納',\n",
    "            '専有部分設備_収納_クローゼット',\n",
    "            '専有部分設備_収納_シューズボックス',\n",
    "        ],\n",
    "    )\n",
    "    out['storage_score'] = func._sum_cols(out, storage_cols, 'storage_score')\n",
    "    out['storage_high_flag'] = (out['storage_score'].astype('float32') >= 3.0).astype('int8')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 7) 空調・暖房（床暖房は強め）\n",
    "    # ----------------------------\n",
    "    hvac_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '専有部分設備_空調・暖房_エアコン',\n",
    "            '専有部分設備_空調・暖房_冷房',\n",
    "            '専有部分設備_空調・暖房_ガス暖房',\n",
    "            '専有部分設備_空調・暖房_石油暖房',\n",
    "            '専有部分設備_空調・暖房_床暖房',\n",
    "        ],\n",
    "    )\n",
    "    out['hvac_count'] = func._sum_cols(out, hvac_cols, 'hvac_count')\n",
    "    if '専有部分設備_空調・暖房_床暖房' in out.columns:\n",
    "        out['hvac_grade_score'] = out['hvac_count'].astype('float32') + out['専有部分設備_空調・暖房_床暖房'].fillna(0).astype('float32')\n",
    "    else:\n",
    "        out['hvac_grade_score'] = out['hvac_count'].astype('float32')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 8) 通信・ネット（集約）\n",
    "    # ----------------------------\n",
    "    net_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '専有部分設備_通信_インターネット対応',\n",
    "            '専有部分設備_通信_光ファイバー',\n",
    "            '専有部分設備_通信_高速インターネット',\n",
    "            '専有部分設備_通信_インターネット使用料無料',\n",
    "            '専有部分設備_通信_CATV',\n",
    "            '専有部分設備_通信_CATV利用料無料',\n",
    "            '専有部分設備_通信_BSアンテナ',\n",
    "            '専有部分設備_通信_CSアンテナ',\n",
    "            '専有部分設備_通信_有線放送',\n",
    "        ],\n",
    "    )\n",
    "    out['net_ready_score'] = func._sum_cols(out, net_cols, 'net_ready_score')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 9) セキュリティ・共用設備（マンション寄り要素は圧縮して保持）\n",
    "    # ----------------------------\n",
    "    security_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '建物構造・性能_オートロック',\n",
    "            '建物構造・性能_防犯カメラ',\n",
    "            '建物構造・性能_TVモニタ付インターホン',\n",
    "            '建物構造・性能_セキュリティ会社加入済み',\n",
    "            '建物構造・性能_セキュリティー充実',\n",
    "            '建物構造・性能_24時間有人管理',\n",
    "            '建物構造・性能_管理人常駐',\n",
    "        ],\n",
    "    )\n",
    "    service_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '建物構造・性能_コンシェルジュサービス',\n",
    "            '建物構造・性能_フロントサービス',\n",
    "            '建物構造・性能_内廊下',\n",
    "            '建物構造・性能_宅配ボックス',\n",
    "            '建物構造・性能_ごみ出し24時間OK',\n",
    "            '建物構造・性能_キッズルーム',\n",
    "            '建物構造・性能_ゲストルーム',\n",
    "        ],\n",
    "    )\n",
    "    out['security_score'] = func._sum_cols(out, security_cols, 'security_score')\n",
    "    out['shared_service_score'] = func._sum_cols(out, service_cols, 'shared_service_score')\n",
    "\n",
    "    # 高級マンションっぽさ（house ではノイズになりやすいのでフラグ1本で）\n",
    "    luxury_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '建物構造・性能_タワーマンション',\n",
    "            '建物構造・性能_ハイグレードマンション',\n",
    "            '建物構造・性能_リゾートマンション',\n",
    "            '建物構造・性能_内廊下',\n",
    "            '建物構造・性能_コンシェルジュサービス',\n",
    "        ],\n",
    "    )\n",
    "    out['luxury_mansion_flag'] = func._any_cols(out, luxury_cols, 'luxury_mansion_flag')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 10) インフラ（ディスカウント/モダン）\n",
    "    # ----------------------------\n",
    "    infra_penalty_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '建物設備（給排水・インフラ）_汲取',\n",
    "            '建物設備（給排水・インフラ）_浄化槽',\n",
    "            '建物設備（給排水・インフラ）_井戸',\n",
    "            '建物設備（給排水・インフラ）_プロパンガス',\n",
    "            '建物設備（給排水・インフラ）_ガスその他',\n",
    "            '建物設備（給排水・インフラ）_排水その他',\n",
    "            '建物設備（給排水・インフラ）_水道その他',\n",
    "        ],\n",
    "    )\n",
    "    infra_modern_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '建物設備（給排水・インフラ）_都市ガス',\n",
    "            '建物設備（給排水・インフラ）_下水',\n",
    "            '建物設備（給排水・インフラ）_公営水道',\n",
    "            '建物設備（給排水・インフラ）_オール電化',\n",
    "            '建物設備（給排水・インフラ）_太陽光発電システム',\n",
    "            '建物設備（給排水・インフラ）_家庭用燃料電池',\n",
    "        ],\n",
    "    )\n",
    "    out['infra_penalty_score'] = func._sum_cols(out, infra_penalty_cols, 'infra_penalty_score')\n",
    "    out['infra_modern_score'] = func._sum_cols(out, infra_modern_cols, 'infra_modern_score')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 11) 環境プレミアム（livability_score と被るので圧縮して保持）\n",
    "    # ----------------------------\n",
    "    env400_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '環境プレミアム_コンビニ 400ｍ以内',\n",
    "            '環境プレミアム_保育園・幼稚園 400m以内',\n",
    "            '環境プレミアム_公園 400ｍ以内',\n",
    "        ],\n",
    "    )\n",
    "    env800_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '環境プレミアム_コンビニ 800ｍ以内',\n",
    "            '環境プレミアム_スーパー 800ｍ以内',\n",
    "            '環境プレミアム_フィットネス施設（プール含む）800m以内',\n",
    "            '環境プレミアム_中学校 800m以内',\n",
    "            '環境プレミアム_小学校 800ｍ以内',\n",
    "            '環境プレミアム_総合病院 800ｍ以内',\n",
    "            '環境プレミアム_子育てに嬉しい環境',\n",
    "        ],\n",
    "    )\n",
    "    out['env_premium_count_400m'] = func._sum_cols(out, env400_cols, 'env_premium_count_400m')\n",
    "    out['env_premium_count_800m'] = func._sum_cols(out, env800_cols, 'env_premium_count_800m')\n",
    "    out['env_premium_weighted'] = (\n",
    "        2.0 * out['env_premium_count_400m'].astype('float32') + 1.0 * out['env_premium_count_800m'].astype('float32')\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 12) 証明書・性能評価・記録（品質担保の代理）\n",
    "    # ----------------------------\n",
    "    cert_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_インスペクション（建物検査）報告書',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_住宅性能保証制度証明書',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_修繕・点検の記録',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_地盤調査済',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_建築確認完了検査済証',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_建設住宅性能評価書（新築時）',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_建設住宅性能評価書（既存住宅）',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_新築時・増改築時の設計図書',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_瑕疵保証（不動産会社独自）付',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_瑕疵保険（国交省指定）による保証付',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_瑕疵保険（国交省指定）による保証利用可',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_耐震基準適合証明書',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_設計住宅性能評価書',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_長期優良住宅認定通知書',\n",
    "        ],\n",
    "    )\n",
    "    out['cert_score'] = func._sum_cols(out, cert_cols, 'cert_score')\n",
    "    # 強い証明の有無（事故を減らす）\n",
    "    cert_strong_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_建築確認完了検査済証',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_地盤調査済',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_建設住宅性能評価書（既存住宅）',\n",
    "            '用途・投資セグメント_不動産の証明書・性能評価_建設住宅性能評価書（新築時）',\n",
    "        ],\n",
    "    )\n",
    "    out['cert_strong_flag'] = func._any_cols(out, cert_strong_cols, 'cert_strong_flag')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 13) 売買ステータス・投資セグメント\n",
    "    # ----------------------------\n",
    "    out['is_rented_full_flag'] = func._any_cols(\n",
    "        out,\n",
    "        func._existing_cols(out, ['用途・投資セグメント_売買ステータス_満室賃貸中']),\n",
    "        'is_rented_full_flag',\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 14) リフォーム（reform_* は数で持つのが強い）\n",
    "    # ----------------------------\n",
    "    reform_interior_cols = func._existing_cols(out, [f'reform_interior {i}' for i in range(1, 7)])\n",
    "    reform_exterior_cols = func._existing_cols(out, [c for c in ['reform_exterior 1', 'reform_exterior 1 ', 'reform_exterior 2'] if c in out.columns])\n",
    "    reform_wet_cols = func._existing_cols(out, [f'reform_wet_area {i}' for i in range(1, 7)])\n",
    "\n",
    "    out['reform_interior_cnt'] = func._sum_cols(out, reform_interior_cols, 'reform_interior_cnt')\n",
    "    out['reform_exterior_cnt'] = func._sum_cols(out, reform_exterior_cols, 'reform_exterior_cnt')\n",
    "    out['reform_wet_cnt'] = func._sum_cols(out, reform_wet_cols, 'reform_wet_cnt')\n",
    "    out['reform_total_cnt'] = (\n",
    "        out['reform_interior_cnt'].astype('float32')\n",
    "        + out['reform_exterior_cnt'].astype('float32')\n",
    "        + out['reform_wet_cnt'].astype('float32')\n",
    "    )\n",
    "    out['reform_any_flag'] = (out['reform_total_cnt'].astype('float32') > 0).astype('int8')\n",
    "    out['reform_wet_heavy_flag'] = (out['reform_wet_cnt'].astype('float32') >= 2).astype('int8')\n",
    "\n",
    "    # ----------------------------\n",
    "    # 15) 最終：設備総合（高級/準高級/ディスカウントの三段構え）\n",
    "    # ----------------------------\n",
    "    # 既にあなたが作っている premium_equipment_count がある前提でも、無くても動くようにする\n",
    "    if 'premium_equipment_count' not in out.columns:\n",
    "        premium_cols = func._existing_cols(\n",
    "            out,\n",
    "            [\n",
    "                '専有部分設備_空調・暖房_床暖房',\n",
    "                '専有部分設備_キッチン_食器洗い乾燥機',\n",
    "                '専有部分設備_浴室・洗面_浴室乾燥機',\n",
    "                '専有部分設備_収納_ウォークインクローゼット',\n",
    "            ],\n",
    "        )\n",
    "        out['premium_equipment_count'] = func._sum_cols(out, premium_cols, 'premium_equipment_count')\n",
    "\n",
    "    # 準プレミアム：高級ほどではないが差が出やすい要素\n",
    "    semi_premium_cols = func._existing_cols(\n",
    "        out,\n",
    "        [\n",
    "            '専有部分設備_浴室・洗面_追焚機能',\n",
    "            '専有部分設備_浴室・洗面_洗面所独立',\n",
    "            '専有部分設備_キッチン_システムキッチン',\n",
    "            '建物構造・性能_宅配ボックス',\n",
    "            '建物構造・性能_オートロック',\n",
    "        ],\n",
    "    )\n",
    "    out['semi_premium_count'] = func._sum_cols(out, semi_premium_cols, 'semi_premium_count')\n",
    "\n",
    "    # ディスカウントをまとめる（過剰予測抑制）\n",
    "    out['discount_pressure_score'] = (\n",
    "        2.0 * out['hard_penalty_any'].astype('float32')\n",
    "        + 1.0 * out['infra_penalty_score'].astype('float32')\n",
    "        + 1.0 * out['tag_land_penalty_flag'].astype('float32')\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 16) 必要なら元タグ列を落とす\n",
    "    # ----------------------------\n",
    "    if not keep_original_cols:\n",
    "        drop_cols = set(\n",
    "            hard_penalty_cols\n",
    "            + land_premium_cols\n",
    "            + land_penalty_cols\n",
    "            + kitchen_base_cols\n",
    "            + burner_cols\n",
    "            + wet_positive_cols\n",
    "            + wet_separation_cols\n",
    "            + toilet_positive_cols\n",
    "            + storage_cols\n",
    "            + hvac_cols\n",
    "            + net_cols\n",
    "            + security_cols\n",
    "            + service_cols\n",
    "            + luxury_cols\n",
    "            + infra_penalty_cols\n",
    "            + infra_modern_cols\n",
    "            + env400_cols\n",
    "            + env800_cols\n",
    "            + cert_cols\n",
    "            + cert_strong_cols\n",
    "            + reform_interior_cols\n",
    "            + reform_exterior_cols\n",
    "            + reform_wet_cols\n",
    "            + semi_premium_cols\n",
    "        )\n",
    "        out = out.drop(columns=[c for c in drop_cols if c in out.columns])\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "caf4b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_price_improving_features_from_tags(train_df_fe, keep_original_cols=True)\n",
    "test_df_fe = add_price_improving_features_from_tags(test_df_fe, keep_original_cols=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11570191",
   "metadata": {},
   "source": [
    "## 面積・地価の共通特徴量の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "841046df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_effective_area_log(df: pd.DataFrame) -> pd.Series:\n",
    "    eff = np.full(len(df), np.nan, dtype='float64')\n",
    "    g = df['property_group']\n",
    "\n",
    "    # residential: 専有面積\n",
    "    idx = g == 'residential'\n",
    "    eff[idx] = df.loc[idx, 'senyu_area_log']\n",
    "\n",
    "    # house: 建物延床 + 土地\n",
    "    idx = g == 'house'\n",
    "    a = df.loc[idx, 'nobeyuka_area_log']\n",
    "    l = df.loc[idx, 'tochi_area_log']\n",
    "\n",
    "    eff[idx] = (\n",
    "        0.7 * a + 0.3 * l\n",
    "    )\n",
    "    eff[idx] = np.where(\n",
    "        np.isnan(eff[idx]),\n",
    "        np.where(np.isnan(a), l, a),\n",
    "        eff[idx]\n",
    "    )\n",
    "\n",
    "    # other: 延床優先、なければ土地\n",
    "    idx = g == 'other'\n",
    "    eff[idx] = df.loc[idx, 'nobeyuka_area_log']\n",
    "    eff[idx] = np.where(\n",
    "        np.isnan(eff[idx]),\n",
    "        df.loc[idx, 'tochi_area_log'],\n",
    "        eff[idx]\n",
    "    )\n",
    "\n",
    "    return eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02c8bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe['effective_area_log'] = make_effective_area_log(train_df_fe)\n",
    "test_df_fe['effective_area_log']  = make_effective_area_log(test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "abf249eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "def add_effective_land_price_with_group_calibration(\n",
    "    train_df_fe: pd.DataFrame,\n",
    "    test_df_fe: pd.DataFrame,\n",
    "    *,\n",
    "    group_col: str = 'property_group',\n",
    "    groups_to_fit: tuple[str, ...] = ('house', 'other'),\n",
    "    use_quantile_for_urban: bool = True,\n",
    "    urban_clip: tuple[float, float] | None = (-5.0, 5.0),\n",
    "    ridge_alpha: float = 1.0,\n",
    "    random_state: int = 42,\n",
    "    area_clip: tuple[float, float] = (0.0, 500.0),\n",
    "    clip_calibrated: bool = True,\n",
    "    clip_quantiles: tuple[float, float] = (0.001, 0.999),\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "    tr = train_df_fe.copy()\n",
    "    te = test_df_fe.copy()\n",
    "\n",
    "    # =========\n",
    "    # 0) flags\n",
    "    # =========\n",
    "    for df in [tr, te]:\n",
    "        df['has_land_theoretical_price'] = (~df['land_theoretical_price_weighted'].isna()).astype('int8')\n",
    "        df['has_eki2'] = (~df['eki_name2'].isna()).astype('int8')\n",
    "        df['has_density'] = (~df['unit_land_density'].isna()).astype('int8')\n",
    "\n",
    "    # ============================\n",
    "    # 1) urban_score のスケーリング\n",
    "    # ============================\n",
    "    tr_u = tr['urban_score'].astype('float64')\n",
    "    te_u = te['urban_score'].astype('float64')\n",
    "\n",
    "    if urban_clip is not None:\n",
    "        lo, hi = urban_clip\n",
    "        tr_u = tr_u.clip(lo, hi)\n",
    "        te_u = te_u.clip(lo, hi)\n",
    "\n",
    "    if use_quantile_for_urban:\n",
    "        qt = QuantileTransformer(\n",
    "            n_quantiles=min(2000, max(10, int(tr_u.notna().sum()))),\n",
    "            output_distribution='uniform',\n",
    "            subsample=int(1e9),\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        fill_val = tr_u.median()\n",
    "        tr_u_2d = tr_u.fillna(fill_val).to_numpy().reshape(-1, 1)\n",
    "        te_u_2d = te_u.fillna(fill_val).to_numpy().reshape(-1, 1)\n",
    "\n",
    "        tr['urban_score_scaled'] = qt.fit_transform(tr_u_2d).ravel()\n",
    "        te['urban_score_scaled'] = qt.transform(te_u_2d).ravel()\n",
    "    else:\n",
    "        u_min = np.nanmin(tr_u.to_numpy())\n",
    "        u_max = np.nanmax(tr_u.to_numpy())\n",
    "        denom = (u_max - u_min) if (u_max - u_min) != 0 else 1.0\n",
    "        tr['urban_score_scaled'] = ((tr_u - u_min) / denom).fillna(0.5).clip(0.0, 1.0)\n",
    "        te['urban_score_scaled'] = ((te_u - u_min) / denom).fillna(0.5).clip(0.0, 1.0)\n",
    "\n",
    "    # ==================================\n",
    "    # 2) proxy 用の面積 area_for_proxy（property_group 対応）\n",
    "    # ==================================\n",
    "    def build_area_for_proxy(df: pd.DataFrame) -> pd.Series:\n",
    "        area = df.get('area_per_room')\n",
    "        area = area.astype('float64') if area is not None else pd.Series(np.nan, index=df.index, dtype='float64')\n",
    "\n",
    "        if group_col in df.columns:\n",
    "            g = df[group_col].astype('string')\n",
    "            is_res = g.eq('residential')\n",
    "            is_house = g.eq('house')\n",
    "            is_other = g.eq('other')\n",
    "        else:\n",
    "            is_res = pd.Series(False, index=df.index)\n",
    "            is_house = pd.Series(False, index=df.index)\n",
    "            is_other = pd.Series(False, index=df.index)\n",
    "\n",
    "        # residential: area_per_room -> senyu_area（専有面積）へフォールバック\n",
    "        if 'senyu_area' in df.columns:\n",
    "            area = area.where(~(is_res & area.isna()), df['senyu_area'].astype('float64'))\n",
    "\n",
    "        # house: 土地面積系 -> house_area -> nobeyuka_area/total_floor_area の順\n",
    "        for c in ['shikichi_area', 'tochi_area', 'kukaku_area', 'house_area', 'nobeyuka_area', 'total_floor_area']:\n",
    "            if c in df.columns:\n",
    "                area = area.where(~(is_house & area.isna()), df[c].astype('float64'))\n",
    "\n",
    "        # other: 延床/建物 -> 土地面積系の順（混在に強いフォールバック）\n",
    "        for c in ['nobeyuka_area', 'total_floor_area', 'house_area', 'shikichi_area', 'tochi_area', 'kukaku_area']:\n",
    "            if c in df.columns:\n",
    "                area = area.where(~(is_other & area.isna()), df[c].astype('float64'))\n",
    "\n",
    "        lo, hi = area_clip\n",
    "        area = area.clip(lower=lo, upper=hi)\n",
    "        return area\n",
    "\n",
    "    tr['area_for_proxy'] = build_area_for_proxy(tr)\n",
    "    te['area_for_proxy'] = build_area_for_proxy(te)\n",
    "\n",
    "    tr['has_area_for_proxy'] = (~tr['area_for_proxy'].isna()).astype('int8')\n",
    "    te['has_area_for_proxy'] = (~te['area_for_proxy'].isna()).astype('int8')\n",
    "\n",
    "    area_fill = tr['area_for_proxy'].median()\n",
    "    tr['area_for_proxy_filled'] = tr['area_for_proxy'].fillna(area_fill)\n",
    "    te['area_for_proxy_filled'] = te['area_for_proxy'].fillna(area_fill)\n",
    "\n",
    "    # ==================================\n",
    "    # 3) 校正用X（3次元）を作る\n",
    "    # ==================================\n",
    "    def build_calib_X(df: pd.DataFrame) -> np.ndarray:\n",
    "        sps = df['station_power_sum3'].astype('float64').to_numpy()\n",
    "        sps = np.where(np.isfinite(sps), sps, 0.0)\n",
    "\n",
    "        ups = df['urban_score_scaled'].astype('float64').to_numpy()\n",
    "        ups = np.where(np.isfinite(ups), ups, 0.5)\n",
    "\n",
    "        area = df['area_for_proxy_filled'].astype('float64').to_numpy()\n",
    "        area = np.where(np.isfinite(area), area, 0.0)\n",
    "\n",
    "        x1 = np.log1p(np.clip(sps, 0.0, None))\n",
    "        x2 = ups\n",
    "        x3 = np.log1p(np.clip(area, 0.0, None))\n",
    "        return np.vstack([x1, x2, x3]).T\n",
    "\n",
    "    X_tr_all = build_calib_X(tr)\n",
    "    X_te_all = build_calib_X(te)\n",
    "\n",
    "    # ==================================\n",
    "    # 4) 用途別 Ridge 校正（property_group）\n",
    "    # ==================================\n",
    "    tr_pred = np.full(len(tr), np.nan, dtype='float64')\n",
    "    te_pred = np.full(len(te), np.nan, dtype='float64')\n",
    "\n",
    "    models = {}\n",
    "    fit_stats = {}\n",
    "\n",
    "    y_all = tr['land_theoretical_price_weighted'].to_numpy()\n",
    "    m_y = np.isfinite(y_all)\n",
    "\n",
    "    def fit_one(mask_fit: np.ndarray, key: str) -> Ridge | None:\n",
    "        if int(mask_fit.sum()) < 200:\n",
    "            return None\n",
    "\n",
    "        X = X_tr_all[mask_fit]\n",
    "        y = y_all[mask_fit]\n",
    "        ok = np.all(np.isfinite(X), axis=1) & np.isfinite(y)\n",
    "        X = X[ok]\n",
    "        y = y[ok]\n",
    "\n",
    "        if len(y) < 200:\n",
    "            return None\n",
    "\n",
    "        model = Ridge(alpha=ridge_alpha, random_state=random_state)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        fit_stats[key] = {\n",
    "            'n_fit': int(len(y)),\n",
    "            'coef': model.coef_.astype('float64').tolist(),\n",
    "            'intercept': float(model.intercept_),\n",
    "        }\n",
    "        return model\n",
    "\n",
    "    # 全体モデル（フォールバック）\n",
    "    model_all = fit_one(m_y, 'all')\n",
    "    if model_all is None:\n",
    "        raise ValueError('全体校正モデルの学習に失敗しました（有効行が少ない/特徴量が壊れている可能性）。')\n",
    "    models['all'] = model_all\n",
    "\n",
    "    if group_col in tr.columns and group_col in te.columns:\n",
    "        for g in groups_to_fit:\n",
    "            mask_g = tr[group_col].astype('string').to_numpy() == g\n",
    "            mask_fit = mask_g & m_y\n",
    "            model_g = fit_one(mask_fit, g)\n",
    "\n",
    "            if model_g is None:\n",
    "                models[g] = model_all\n",
    "                fit_stats[g] = {\n",
    "                    'fallback_to': 'all',\n",
    "                    'n_fit': int(mask_fit.sum()),\n",
    "                }\n",
    "            else:\n",
    "                models[g] = model_g\n",
    "\n",
    "        g_tr = tr[group_col].astype('string').to_numpy()\n",
    "        g_te = te[group_col].astype('string').to_numpy()\n",
    "\n",
    "        # groups_to_fit の行はそれぞれのモデルで予測\n",
    "        for g, model in models.items():\n",
    "            if g == 'all':\n",
    "                continue\n",
    "\n",
    "            idx_tr = np.where(g_tr == g)[0]\n",
    "            if len(idx_tr) > 0:\n",
    "                tr_pred[idx_tr] = model.predict(X_tr_all[idx_tr])\n",
    "\n",
    "            idx_te = np.where(g_te == g)[0]\n",
    "            if len(idx_te) > 0:\n",
    "                te_pred[idx_te] = model.predict(X_te_all[idx_te])\n",
    "\n",
    "        # それ以外（residential など）は全体モデルで埋める\n",
    "        idx_tr_nan = np.where(~np.isfinite(tr_pred))[0]\n",
    "        if len(idx_tr_nan) > 0:\n",
    "            tr_pred[idx_tr_nan] = model_all.predict(X_tr_all[idx_tr_nan])\n",
    "\n",
    "        idx_te_nan = np.where(~np.isfinite(te_pred))[0]\n",
    "        if len(idx_te_nan) > 0:\n",
    "            te_pred[idx_te_nan] = model_all.predict(X_te_all[idx_te_nan])\n",
    "    else:\n",
    "        tr_pred = model_all.predict(X_tr_all)\n",
    "        te_pred = model_all.predict(X_te_all)\n",
    "\n",
    "    tr['proxy_land_price_calibrated'] = tr_pred\n",
    "    te['proxy_land_price_calibrated'] = te_pred\n",
    "\n",
    "    # =========================================\n",
    "    # 4.5) 外挿の抑制：校正値クリップ（任意・推奨）\n",
    "    # =========================================\n",
    "    clip_lo = None\n",
    "    clip_hi = None\n",
    "    if clip_calibrated:\n",
    "        q_lo, q_hi = clip_quantiles\n",
    "        y_fit = tr.loc[m_y, 'land_theoretical_price_weighted'].to_numpy()\n",
    "        clip_lo = float(np.quantile(y_fit, q_lo))\n",
    "        clip_hi = float(np.quantile(y_fit, q_hi))\n",
    "\n",
    "        tr['proxy_land_price_calibrated'] = tr['proxy_land_price_calibrated'].clip(clip_lo, clip_hi)\n",
    "        te['proxy_land_price_calibrated'] = te['proxy_land_price_calibrated'].clip(clip_lo, clip_hi)\n",
    "\n",
    "    # =========================================\n",
    "    # 5) effective_land_price の作成（切り替え）\n",
    "    # =========================================\n",
    "    for df in [tr, te]:\n",
    "        df['effective_land_price'] = np.where(\n",
    "            df['has_land_theoretical_price'].to_numpy() == 1,\n",
    "            df['land_theoretical_price_weighted'].to_numpy(),\n",
    "            df['proxy_land_price_calibrated'].to_numpy(),\n",
    "        ).astype('float64')\n",
    "\n",
    "    info = {\n",
    "        'urban_scaler': 'quantile' if use_quantile_for_urban else 'minmax',\n",
    "        'urban_clip': urban_clip,\n",
    "        'ridge_alpha': ridge_alpha,\n",
    "        'area_clip': area_clip,\n",
    "        'area_fill': float(area_fill) if np.isfinite(area_fill) else None,\n",
    "        'groups_to_fit': list(groups_to_fit),\n",
    "        'fit_stats': fit_stats,\n",
    "        'clip_calibrated': clip_calibrated,\n",
    "        'clip_quantiles': clip_quantiles,\n",
    "        'clip_lo': clip_lo,\n",
    "        'clip_hi': clip_hi,\n",
    "    }\n",
    "    return tr, te, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1f9444a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': {'n_fit': 165577, 'coef': [0.5629432991025102, 0.8627245482313626, 0.2807017472547172], 'intercept': 14.026545512863272}, 'house': {'n_fit': 153455, 'coef': [0.5017758790242636, 0.6778290018119314, 0.5156742585140934], 'intercept': 13.452951307726979}, 'other': {'n_fit': 12122, 'coef': [1.0863762732953717, 2.2266349104538605, -0.44849790127655187], 'intercept': 15.595617187477462}}\n",
      "       effective_land_price  proxy_land_price_calibrated  \\\n",
      "count         363924.000000                363924.000000   \n",
      "mean              16.572026                    16.572026   \n",
      "std                0.561901                     0.360342   \n",
      "min               11.262605                    14.267928   \n",
      "25%               16.315927                    16.383697   \n",
      "50%               16.638352                    16.618029   \n",
      "75%               16.826680                    16.781873   \n",
      "max               24.439706                    19.803590   \n",
      "\n",
      "       land_theoretical_price_weighted  \n",
      "count                    165577.000000  \n",
      "mean                         16.424558  \n",
      "std                           0.757909  \n",
      "min                          11.262605  \n",
      "25%                          15.936034  \n",
      "50%                          16.350343  \n",
      "75%                          16.822831  \n",
      "max                          24.439706  \n"
     ]
    }
   ],
   "source": [
    "train_df_fe, test_df_fe, cal_info = add_effective_land_price_with_group_calibration(\n",
    "    train_df_fe,\n",
    "    test_df_fe,\n",
    "    group_col='property_group',\n",
    "    groups_to_fit=('house', 'other'),\n",
    "    use_quantile_for_urban=True,\n",
    "    urban_clip=(-5.0, 5.0),\n",
    "    ridge_alpha=1.0,\n",
    ")\n",
    "\n",
    "print(cal_info['fit_stats'])\n",
    "print(train_df_fe[['effective_land_price', 'proxy_land_price_calibrated', 'land_theoretical_price_weighted']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d55285",
   "metadata": {},
   "source": [
    "## 土砂災害"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2f16ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISASTER_RAW_COLS = [\n",
    "    'keikai_dist_m',\n",
    "    'kyuusha_dist_m',\n",
    "    'dosham_in',\n",
    "    'dosham_A30a5_005_max',\n",
    "    'dosham_A30a5_006_max',\n",
    "    'dosham_A30a5_007_max',\n",
    "    'dosham_A30a5_008_max',\n",
    "    'dosham_A30a5_009_max',\n",
    "    'dosham_A30a5_010_max',\n",
    "    'dosham_phen_gake',\n",
    "    'dosham_phen_doseki',\n",
    "    'dosham_phen_jisuberi',\n",
    "    'dosham_phen_nadare',\n",
    "]\n",
    "\n",
    "def _add_dist_pack(df: pd.DataFrame, dist_col: str, prefix: str, clip_m: float = 10000.0) -> pd.DataFrame:\n",
    "    if dist_col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    d = pd.to_numeric(df[dist_col], errors='coerce').astype('float32')\n",
    "\n",
    "    # NaN（近傍なし）は遠い扱いに寄せる：学習/推論で安定\n",
    "    d2 = d.fillna(clip_m).clip(lower=0, upper=clip_m)\n",
    "\n",
    "    df[f'{prefix}_dist_clip'] = d2.astype('float32')\n",
    "    df[f'{prefix}_dist_log1p'] = np.log1p(d2).astype('float32')\n",
    "\n",
    "    # 閾値フラグ（多くのケースで生distより安定して効く）\n",
    "    for thr in [100, 300, 1000, 5000]:\n",
    "        df[f'{prefix}_within_{thr}m'] = (d2 <= thr).astype('int8')\n",
    "\n",
    "    # 近傍なしフラグ（NaNだったこと自体が情報になることがある）\n",
    "    df[f'{prefix}_no_near'] = d.isna().astype('int8')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _add_mesh_num_pack(df: pd.DataFrame, col: str, prefix: str) -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    x = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
    "    df[f'{prefix}_{col}_has'] = x.notna().astype('int8')\n",
    "\n",
    "    # マイナスは想定外なので0に寄せる\n",
    "    x2 = x.fillna(0.0).clip(lower=0)\n",
    "    df[f'{prefix}_{col}_log1p'] = np.log1p(x2).astype('float32')\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_disaster_features_other(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # 距離：生distはモデルに入れず、圧縮パックに置換する\n",
    "    df = _add_dist_pack(df, 'keikai_dist_m', prefix='keikai', clip_m=10000.0)\n",
    "    df = _add_dist_pack(df, 'kyuusha_dist_m', prefix='kyuusha', clip_m=10000.0)\n",
    "\n",
    "    # メッシュ：雨量（A30a5_005/006）中心。勾配(A30a5_007)は任意で追加\n",
    "    df = _add_mesh_num_pack(df, 'dosham_A30a5_005_max', prefix='dosham')\n",
    "    df = _add_mesh_num_pack(df, 'dosham_A30a5_006_max', prefix='dosham')\n",
    "    df = _add_mesh_num_pack(df, 'dosham_A30a5_007_max', prefix='dosham')\n",
    "\n",
    "    # dosham_in はそのまま使う（なければ作らない）\n",
    "    if 'dosham_in' in df.columns:\n",
    "        df['dosham_in'] = pd.to_numeric(df['dosham_in'], errors='coerce').fillna(0).astype('int8')\n",
    "\n",
    "    # phen は、重要度が立っていた gake のみ残す（他はノイズ源になりやすい）\n",
    "    if 'dosham_phen_gake' in df.columns:\n",
    "        df['dosham_phen_gake'] = pd.to_numeric(df['dosham_phen_gake'], errors='coerce').fillna(0).astype('int8')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c45cbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_disaster_features_other(train_df_fe)\n",
    "test_df_fe = add_disaster_features_other(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15789285",
   "metadata": {},
   "source": [
    "## 一軒家の築古物件へのディスカウント特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad3d4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_house_error_fix_features(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    train = train_df.copy()\n",
    "    test = test_df.copy()\n",
    "    combined = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "    # =====================\n",
    "    # 1. 築年数 piecewise\n",
    "    # =====================\n",
    "    # 1) 築年 piecewise（連続）\n",
    "    age = pd.to_numeric(combined.get('effective_age'), errors='coerce')\n",
    "    combined['effective_age_missing'] = age.isna().astype('int8')\n",
    "    age_fill = age.fillna(0.0).clip(lower=0.0)\n",
    "\n",
    "    def _piece(x, start, width):\n",
    "        return (x - start).clip(lower=0, upper=width)\n",
    "\n",
    "    combined['age_0_10']    = _piece(age_fill, 0, 10)\n",
    "    combined['age_10_20']   = _piece(age_fill, 10, 10)\n",
    "    combined['age_20_30']   = _piece(age_fill, 20, 10)\n",
    "    combined['age_30_40']   = _piece(age_fill, 30, 10)\n",
    "    combined['age_40_60']   = _piece(age_fill, 40, 20)\n",
    "    combined['age_60_plus'] = (age_fill - 60).clip(lower=0, upper=80)\n",
    "\n",
    "    combined['age_40_over'] = (age >= 40).astype('int8')\n",
    "    combined['age_60_over'] = (age >= 60).astype('int8')\n",
    "\n",
    "    # =====================\n",
    "    # 2. 構造 × 築古\n",
    "    # =====================\n",
    "    if 'is_wood' in combined.columns:\n",
    "        is_wood = pd.to_numeric(combined['is_wood'], errors='coerce').fillna(0).astype('int8')\n",
    "        combined['age_40_over_x_is_wood'] = combined['age_40_over'].gt(0).astype('int8') * is_wood\n",
    "        combined['age_60_over_x_is_wood'] = combined['age_60_over'].gt(0).astype('int8') * is_wood\n",
    "\n",
    "    # =====================\n",
    "    # 3. リフォーム無し × 築古\n",
    "    # =====================\n",
    "    if 'renovation_recency' in combined.columns:\n",
    "        no_renov = combined['renovation_recency'].isna().astype('int8')\n",
    "    else:\n",
    "        no_renov = pd.Series(1, index=combined.index, dtype='int8')  # 列が無いなら全て「不明」扱い\n",
    "    combined['no_renovation_flag'] = no_renov\n",
    "    combined['age_40_over_x_no_renov'] = combined['age_40_over'].gt(0).astype('int8') * no_renov\n",
    "    combined['age_60_over_x_no_renov'] = combined['age_60_over'].gt(0).astype('int8') * no_renov\n",
    "\n",
    "    # =====================\n",
    "    # split back\n",
    "    # =====================\n",
    "    train_out = combined.iloc[:len(train)].reset_index(drop=True)\n",
    "    test_out  = combined.iloc[len(train):].reset_index(drop=True)\n",
    "\n",
    "    return train_out, test_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19c78957",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_house_error_fix_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b7b61",
   "metadata": {},
   "source": [
    "## 土地支配スコア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ad856dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_dominance_proxy_features(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    train = train_df.copy()\n",
    "    test = test_df.copy()\n",
    "    combined = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "    # =========================\n",
    "    # 1. 理論建物価値 proxy\n",
    "    # =========================\n",
    "    area = combined['senyu_area']\n",
    "    age  = combined['effective_age']\n",
    "\n",
    "    # --- 構造係数（雑でOK）\n",
    "    structure_coef = np.ones(len(combined))\n",
    "\n",
    "    if 'is_wood' in combined.columns:\n",
    "        structure_coef += combined['is_wood'] * (-0.3)\n",
    "\n",
    "    if 'is_rcsrc' in combined.columns:\n",
    "        structure_coef += combined['is_rcsrc'] * (0.2)\n",
    "\n",
    "    # --- 築年減価\n",
    "    age_decay = np.exp(-age / 40).clip(0.05, 1.0)\n",
    "\n",
    "    # --- リフォーム補正\n",
    "    renov = combined['renovation_recency']\n",
    "    renov_factor = np.where(\n",
    "        renov.notna(),\n",
    "        np.exp(-renov / 30),\n",
    "        0.6\n",
    "    )\n",
    "\n",
    "    combined['theoretical_building_value'] = (\n",
    "        area\n",
    "        * structure_coef\n",
    "        * age_decay\n",
    "        * renov_factor\n",
    "    ).fillna(0)\n",
    "\n",
    "    # =========================\n",
    "    # 2. 土地支配スコア\n",
    "    # =========================\n",
    "    land_price = combined['land_theoretical_price_weighted']\n",
    "\n",
    "    combined['land_dominance_score'] = (\n",
    "        land_price / (combined['theoretical_building_value'] + 1e-6)\n",
    "    ).clip(0, 10)\n",
    "    combined['land_dominance_score_log'] = np.log1p(combined['land_dominance_score'])\n",
    "\n",
    "    combined['land_dominant_flag'] = (\n",
    "        combined['land_dominance_score'] > 2 # NOTE: ここは工夫の余地あり？（時間はなさそう）\n",
    "    ).astype('int8')\n",
    "\n",
    "    # =========================\n",
    "    # split back\n",
    "    # =========================\n",
    "    train_out = combined.iloc[:len(train)].reset_index(drop=True)\n",
    "    test_out  = combined.iloc[len(train):].reset_index(drop=True)\n",
    "\n",
    "    return train_out, test_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be7b3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_land_dominance_proxy_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3921ab",
   "metadata": {},
   "source": [
    "## building_id単位の近傍物件カウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "888222f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def add_neighbor_count_features_by_building(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    *,\n",
    "    building_id_col: str = 'building_id',\n",
    "    lat_col: str = 'lat',\n",
    "    lon_col: str = 'lon',\n",
    "    radii_m: tuple[int, ...] = (300, 500, 1000, 2000),\n",
    "    prefix: str = 'nb_build_cnt',\n",
    "    agg: str = 'mean',  # 'mean' or 'first'\n",
    "    fillna_value: int = 0,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, list[str]]:\n",
    "    \"\"\"\n",
    "    building_id をユニークにした代表点でBallTreeを作り、近傍“建物数”を数える。\n",
    "    自分自身の建物は除外（-1）。\n",
    "    目的変数は一切使わない。\n",
    "    \"\"\"\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    combined = pd.concat([tr, te], ignore_index=True)\n",
    "\n",
    "    # 数値化\n",
    "    combined[lat_col] = pd.to_numeric(combined[lat_col], errors='coerce')\n",
    "    combined[lon_col] = pd.to_numeric(combined[lon_col], errors='coerce')\n",
    "\n",
    "    if building_id_col not in combined.columns:\n",
    "        raise KeyError(f'{building_id_col} not found in dataframe.')\n",
    "\n",
    "    # 座標がある行だけで building 代表点を作る\n",
    "    valid = combined[[building_id_col, lat_col, lon_col]].notna().all(axis=1)\n",
    "    base = combined.loc[valid, [building_id_col, lat_col, lon_col]].copy()\n",
    "\n",
    "    if base.empty:\n",
    "        raise ValueError('No valid rows with building_id and lat/lon.')\n",
    "\n",
    "    if agg == 'mean':\n",
    "        bld = base.groupby(building_id_col, as_index=False)[[lat_col, lon_col]].mean()\n",
    "    elif agg == 'first':\n",
    "        bld = base.groupby(building_id_col, as_index=False)[[lat_col, lon_col]].first()\n",
    "    else:\n",
    "        raise ValueError(\"agg must be 'mean' or 'first'.\")\n",
    "\n",
    "    # BallTree は building 代表点で作る\n",
    "    coords = np.radians(bld[[lat_col, lon_col]].to_numpy())\n",
    "    tree = BallTree(coords, metric='haversine')\n",
    "    r_earth = 6_371_000.0\n",
    "\n",
    "    created_cols: list[str] = []\n",
    "    for r_m in radii_m:\n",
    "        r_rad = r_m / r_earth\n",
    "        cnt = tree.query_radius(coords, r=r_rad, count_only=True) - 1  # self除外\n",
    "        col = f'{prefix}_{r_m}m'\n",
    "        bld[col] = cnt.astype('int32')\n",
    "        created_cols.append(col)\n",
    "\n",
    "    # building_id で元の行に付与\n",
    "    combined = combined.merge(bld[[building_id_col] + created_cols], on=building_id_col, how='left')\n",
    "\n",
    "    # 座標/ID欠損などで付与できなかった行の扱い\n",
    "    for col in created_cols:\n",
    "        combined[col] = combined[col].fillna(fillna_value).astype('int32')\n",
    "\n",
    "    tr_out = combined.iloc[:len(tr)].reset_index(drop=True)\n",
    "    te_out = combined.iloc[len(tr):].reset_index(drop=True)\n",
    "    return tr_out, te_out, created_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2aaacf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe, created_cols = add_neighbor_count_features_by_building(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c81829ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_build_cnt_300m',\n",
       " 'nb_build_cnt_500m',\n",
       " 'nb_build_cnt_1000m',\n",
       " 'nb_build_cnt_2000m']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d073d0c",
   "metadata": {},
   "source": [
    "## geohash TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71da9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_geohash(train_df, test_df, precision=6, lat_col='lat', lon_col='lon'):\n",
    "    import pygeohash as pgh\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    gh_col = f'geohash_{precision}'\n",
    "    tr[gh_col] = [pgh.encode(a, b, precision=precision) for a, b in zip(tr[lat_col].astype(float), tr[lon_col].astype(float))]\n",
    "    te[gh_col] = [pgh.encode(a, b, precision=precision) for a, b in zip(te[lat_col].astype(float), te[lon_col].astype(float))]\n",
    "    return tr, te, gh_col\n",
    "\n",
    "def _te_map(s_cat, y, smoothing=200.0, min_samples_leaf=5):\n",
    "    prior = float(np.mean(y))\n",
    "    stats = pd.DataFrame({'cat': s_cat.astype('object'), 'y': y.astype(float)}).groupby('cat')['y'].agg(['mean', 'count'])\n",
    "    count = stats['count']\n",
    "    mean = stats['mean']\n",
    "    smooth = 1.0 / (1.0 + np.exp(-(count - min_samples_leaf) / smoothing))\n",
    "    te = prior * (1.0 - smooth) + mean * smooth\n",
    "    return te, prior\n",
    "\n",
    "def add_geohash_te_time_oof(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    y_log: pd.Series,\n",
    "    *,\n",
    "    target_year_col: str = 'target_year',\n",
    "    lat_col: str = 'lat',\n",
    "    lon_col: str = 'lon',\n",
    "    precision: int = 6,\n",
    "    out_col: str = 'geohash6_te_logy',\n",
    "    smoothing: float = 200.0,\n",
    "    min_samples_leaf: int = 5,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    tr, te, gh_col = make_geohash(train_df, test_df, precision=precision, lat_col=lat_col, lon_col=lon_col)\n",
    "\n",
    "    oof = np.zeros(len(tr), dtype=float)\n",
    "    years = np.sort(tr[target_year_col].dropna().unique())\n",
    "\n",
    "    # 年単位で「過去→未来」のTEを作る（未来情報を使わない）\n",
    "    for y in years:\n",
    "        va_mask = (tr[target_year_col] == y)\n",
    "        tr_mask = (tr[target_year_col] < y)\n",
    "        if tr_mask.sum() == 0:\n",
    "            # 最初の年は prior で埋める\n",
    "            oof[va_mask.values] = float(y_log.mean())\n",
    "            continue\n",
    "        te_map, prior = _te_map(tr.loc[tr_mask, gh_col], y_log.loc[tr_mask], smoothing=smoothing, min_samples_leaf=min_samples_leaf)\n",
    "        oof[va_mask.values] = tr.loc[va_mask, gh_col].map(te_map).fillna(prior).astype(float).values\n",
    "\n",
    "    tr[out_col] = oof\n",
    "    # test は train 全体でfit（最終学習用）\n",
    "    te_map_full, prior_full = _te_map(tr[gh_col], y_log, smoothing=smoothing, min_samples_leaf=min_samples_leaf)\n",
    "    te[out_col] = te[gh_col].map(te_map_full).fillna(prior_full).astype(float)\n",
    "\n",
    "    return tr, te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb5f92b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_geohash_te_time_oof(train_df_fe, test_df_fe, train_df_fe['y_log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e866d",
   "metadata": {},
   "source": [
    "## houseモデル用の特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "63fb2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_trend_interactions_house(train_df, test_df):\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    df = pd.concat([tr, te], ignore_index=True)\n",
    "\n",
    "    for c in ['land_price_dlog_w3', 'land_price_dlog_nearest', 'log_land_price', 'land_dominance_score', 'effective_age']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    if 'land_price_dlog_w3' in df.columns:\n",
    "        dlog = df['land_price_dlog_w3'].fillna(0)\n",
    "\n",
    "        if 'log_land_price' in df.columns:\n",
    "            df['dlog_w3_x_log_land_price'] = dlog * df['log_land_price'].fillna(0)\n",
    "\n",
    "        if 'land_dominance_score' in df.columns:\n",
    "            df['dlog_w3_x_land_dom'] = dlog * np.log1p(df['land_dominance_score'].fillna(0).clip(lower=0))\n",
    "\n",
    "        if 'age_40_over' in df.columns:\n",
    "            df['dlog_w3_x_age40'] = dlog * df['age_40_over']\n",
    "\n",
    "    tr_out = df.iloc[:len(tr)].reset_index(drop=True)\n",
    "    te_out = df.iloc[len(tr):].reset_index(drop=True)\n",
    "    return tr_out, te_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc8e02a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_land_trend_interactions_house(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e28bfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_house_mape_fix_features(df):\n",
    "    df['nobeyuka_area_x_age_40_over'] = (\n",
    "        df['nobeyuka_area'] * df['age_40_over']\n",
    "    )\n",
    "    df['nobeyuka_area_x_age_60_over'] = (\n",
    "        df['nobeyuka_area'] * df['age_60_plus']\n",
    "    )\n",
    "    \n",
    "    # suburban correction\n",
    "    df['log_land_price_x_nb_build'] = (\n",
    "        df['log_land_price'] * np.log1p(df['nb_build_cnt_1000m'])\n",
    "    )\n",
    "\n",
    "    # market liquidity\n",
    "    df['nb_build_cnt_500m_log'] = np.log1p(df['nb_build_cnt_500m'])\n",
    "    \n",
    "    # land × road (fallback to density)\n",
    "    df['land_x_road_density'] = df['log_land_price'] * df['road_len_density_gap']\n",
    "\n",
    "    df['over_divided'] = (df['area_per_room'] < 20).astype(int)\n",
    "\n",
    "    df['small_building'] = (df['nobeyuka_area'] < 50).astype(int)\n",
    "    df['small_x_old'] = df['small_building'] * df['age_40_over']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80fa7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_house_mape_fix_features(train_df_fe)\n",
    "test_df_fe  = add_house_mape_fix_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541007b",
   "metadata": {},
   "source": [
    "## otherモデル用の特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c9a94d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_other_tail_fix_features(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    df = pd.concat([tr, te], ignore_index=True)\n",
    "\n",
    "    # --- 安全な数値化\n",
    "    for c in ['max_floor_area', 'floor_count', 'infra_penalty_score', 'shidou_area_ratio', 'land_theoretical_price_weighted']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # --- 形状系\n",
    "    if {'max_floor_area', 'floor_count'}.issubset(df.columns):\n",
    "        floor = df['floor_count'].replace(0, np.nan)\n",
    "        df['floor_area_per_floor'] = (df['max_floor_area'] / floor).replace([np.inf, -np.inf], np.nan)\n",
    "        df['floor_area_per_floor'] = df['floor_area_per_floor'].fillna(df['floor_area_per_floor'].median())\n",
    "        df['floor_area_per_floor_log'] = np.log1p(df['floor_area_per_floor'].clip(lower=0))\n",
    "\n",
    "        df['is_midrise'] = df['floor_count'].between(3, 5).astype('int8')\n",
    "        df['is_highrise'] = (df['floor_count'] >= 10).astype('int8')\n",
    "        df['is_lowrise'] = (df['floor_count'] == 1).astype('int8')\n",
    "\n",
    "    # --- 地価×ペナルティ（低価格過大を抑える）\n",
    "    if 'land_theoretical_price_weighted' in df.columns:\n",
    "        df['land_tp_w_log'] = np.log1p(df['land_theoretical_price_weighted'].clip(lower=0))\n",
    "\n",
    "        if {'land_tp_w_log', 'max_floor_area'}.issubset(df.columns):\n",
    "            df['land_tp_w_log_x_max_floor_area_log'] = (\n",
    "                df['land_tp_w_log'] * np.log1p(df['max_floor_area'].clip(lower=0))\n",
    "            )\n",
    "        \n",
    "        if 'infra_penalty_score' in df.columns:\n",
    "            df['land_tp_w_log_x_infra_penalty'] = df['land_tp_w_log'] * df['infra_penalty_score'].fillna(0)\n",
    "\n",
    "        if 'tag_land_penalty_flag' in df.columns:\n",
    "            df['land_tp_w_log_x_land_penalty_flag'] = df['land_tp_w_log'] * df['tag_land_penalty_flag'].fillna(0)\n",
    "\n",
    "        if 'shidou_area_ratio' in df.columns:\n",
    "            df['land_tp_w_log_x_shidou_area_ratio'] = df['land_tp_w_log'] * df['shidou_area_ratio'].fillna(0)\n",
    "        \n",
    "    penalty_cols = [\n",
    "        'infra_penalty_score',\n",
    "        'tag_land_penalty_flag',\n",
    "        'shidou_area_ratio',\n",
    "    ]\n",
    "    exist = [c for c in penalty_cols if c in df.columns]\n",
    "    if exist:\n",
    "        df['penalty_any_flag'] = (df[exist].fillna(0).sum(axis=1) > 0).astype('int8')\n",
    "    \n",
    "    if 'is_midrise' in df.columns and 'penalty_any_flag' in df.columns:\n",
    "        df['is_midrise_x_penalty'] = df['is_midrise'] * df['penalty_any_flag']\n",
    "\n",
    "    tr_out = df.iloc[:len(tr)].reset_index(drop=True)\n",
    "    te_out = df.iloc[len(tr):].reset_index(drop=True)\n",
    "    return tr_out, te_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46e4d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_other_tail_fix_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca22963",
   "metadata": {},
   "source": [
    "## Residential用の特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "796a5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_other_tail_fix_features(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    df = pd.concat([tr, te], ignore_index=True)\n",
    "\n",
    "    # =====================================================\n",
    "    # 数値化（存在する列のみ）\n",
    "    # =====================================================\n",
    "    num_cols = [\n",
    "        'relative_floor', 'room_floor', 'floor_count',\n",
    "        'senyu_area', 'effective_age',\n",
    "        'door_to_station_min_log',\n",
    "        'kyoueki_per_m2', 'shuuzen_per_m2',\n",
    "        'money_kyoueki_std',\n",
    "        'elev_mean',\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # =====================================================\n",
    "    # 1) Floor premium（高価格過小を詰める）\n",
    "    # =====================================================\n",
    "    if 'relative_floor' in df.columns:\n",
    "        rf = df['relative_floor'].clip(0, 1)\n",
    "\n",
    "        df['rel_floor_sq'] = rf * rf\n",
    "        df['rel_floor_over_0_8'] = (rf >= 0.8).astype('int8')\n",
    "        df['rel_floor_over_0_9'] = (rf >= 0.9).astype('int8')\n",
    "\n",
    "        if 'floor_count' in df.columns:\n",
    "            fc = df['floor_count'].fillna(0)\n",
    "            df['is_tower_20'] = (fc >= 20).astype('int8')\n",
    "            df['floor_premium_interaction'] = rf * np.log1p(fc.clip(lower=0))\n",
    "\n",
    "    if {'room_floor', 'floor_count'}.issubset(df.columns):\n",
    "        rf_abs = df['room_floor']\n",
    "        fc = df['floor_count'].replace(0, np.nan)\n",
    "        df['is_top_floor'] = ((rf_abs == fc) & rf_abs.notna()).astype('int8')\n",
    "        df['is_high_floor_20'] = (rf_abs >= 20).fillna(False).astype('int8')\n",
    "\n",
    "    # =====================================================\n",
    "    # 2) 維持費負担（低価格過大を抑制）\n",
    "    # =====================================================\n",
    "    if ('kyoueki_per_m2' in df.columns) or ('shuuzen_per_m2' in df.columns):\n",
    "        kpm = df['kyoueki_per_m2'] if 'kyoueki_per_m2' in df.columns else 0\n",
    "        spm = df['shuuzen_per_m2'] if 'shuuzen_per_m2' in df.columns else 0\n",
    "\n",
    "        kpm = pd.to_numeric(kpm, errors='coerce').fillna(0)\n",
    "        spm = pd.to_numeric(spm, errors='coerce').fillna(0)\n",
    "\n",
    "        df['maint_per_m2_total'] = kpm + spm\n",
    "        df['maint_per_m2_total_log'] = np.log1p(df['maint_per_m2_total'].clip(lower=0))\n",
    "\n",
    "        if 'door_to_station_min_log' in df.columns:\n",
    "            df['maint_x_station'] = (\n",
    "                df['maint_per_m2_total_log'] * df['door_to_station_min_log'].fillna(0)\n",
    "            )\n",
    "\n",
    "        if 'effective_age' in df.columns:\n",
    "            age = df['effective_age'].fillna(df['effective_age'].median())\n",
    "            df['maint_x_age'] = df['maint_per_m2_total_log'] * np.log1p(age.clip(lower=0))\n",
    "\n",
    "        if 'money_kyoueki_std' in df.columns:\n",
    "            df['maint_x_kyoueki_std_log'] = (\n",
    "                df['maint_per_m2_total_log']\n",
    "                * np.log1p(df['money_kyoueki_std'].fillna(0).clip(lower=0))\n",
    "            )\n",
    "\n",
    "    # =====================================================\n",
    "    # 3) 建物グレード（フラグは必ず掛け算）\n",
    "    # =====================================================\n",
    "    # タワー\n",
    "    if '建物構造・性能_タワーマンション' in df.columns:\n",
    "        tower = df['建物構造・性能_タワーマンション'].astype('int8')\n",
    "        df['tower_x_relative_floor'] = tower * df.get('relative_floor', 0)\n",
    "        df['tower_x_high_floor'] = tower * df.get('is_high_floor_20', 0)\n",
    "\n",
    "    # ハイグレード\n",
    "    if '建物構造・性能_ハイグレードマンション' in df.columns:\n",
    "        hg = df['建物構造・性能_ハイグレードマンション'].astype('int8')\n",
    "        df['highgrade_x_maint'] = hg * df.get('maint_per_m2_total_log', 0)\n",
    "\n",
    "    # リゾート（1本だけ）\n",
    "    if '建物構造・性能_リゾートマンション' in df.columns and 'elev_mean' in df.columns:\n",
    "        rs = df['建物構造・性能_リゾートマンション'].astype('int8')\n",
    "        df['resort_x_elev'] = rs * np.log1p(df['elev_mean'].fillna(0).clip(lower=0))\n",
    "\n",
    "    # =====================================================\n",
    "    # split\n",
    "    # =====================================================\n",
    "    tr_out = df.iloc[:len(tr)].reset_index(drop=True)\n",
    "    te_out = df.iloc[len(tr):].reset_index(drop=True)\n",
    "    return tr_out, te_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce446019",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_other_tail_fix_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "989afa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_residential_luxury_maint_features(train_df, test_df):\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    df = pd.concat([tr, te], ignore_index=True)\n",
    "\n",
    "    for c in ['maint_per_m2_total_log', 'relative_floor', 'City/town/village name_te', 'log_land_price']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # 維持費高級フラグ（train+testで閾値決めるとリークが気になるなら train分位で決める）\n",
    "    if 'maint_per_m2_total_log' in df.columns:\n",
    "        th = df['maint_per_m2_total_log'].quantile(0.90)\n",
    "        df['is_luxury_fee_flag'] = (df['maint_per_m2_total_log'] >= th).astype('int8')\n",
    "\n",
    "    # 高価格エリアでの維持費＝プレミアムを表現\n",
    "    if 'maint_per_m2_total_log' in df.columns and 'City/town/village name_te' in df.columns:\n",
    "        df['maint_x_city_te'] = df['maint_per_m2_total_log'] * df['City/town/village name_te'].fillna(df['City/town/village name_te'].median())\n",
    "\n",
    "    if 'maint_per_m2_total_log' in df.columns and 'log_land_price' in df.columns:\n",
    "        df['maint_x_log_land_price'] = df['maint_per_m2_total_log'] * df['log_land_price'].fillna(df['log_land_price'].median())\n",
    "\n",
    "    # 上層×維持費（眺望・高級の共通シグナル）\n",
    "    if 'maint_per_m2_total_log' in df.columns and 'relative_floor' in df.columns:\n",
    "        rf = df['relative_floor'].clip(0, 1).fillna(0)\n",
    "        df['rel_floor_x_maint'] = rf * df['maint_per_m2_total_log'].fillna(0)\n",
    "\n",
    "    tr_out = df.iloc[:len(tr)].reset_index(drop=True)\n",
    "    te_out = df.iloc[len(tr):].reset_index(drop=True)\n",
    "    return tr_out, te_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "378dfe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_residential_luxury_maint_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7aaf3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_residential_rights_penalty_features(train_df, test_df):\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    df = pd.concat([tr, te], ignore_index=True)\n",
    "\n",
    "    for c in ['hard_penalty_any', 'infra_penalty_score', 'tag_land_penalty_flag',\n",
    "              'mochibun_ratio', 'has_mochibun', 'shidou_area_eff', 'has_shidou',\n",
    "              'log_land_price', 'City/town/village name_te']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    if 'mochibun_ratio' in df.columns:\n",
    "        mr = df['mochibun_ratio'].fillna(0)\n",
    "        df['mochibun_ratio_log'] = np.log1p(mr.clip(lower=0))\n",
    "        df['mochibun_anomaly_flag'] = (mr > 1.5).astype('int8')  # 要調整：>1が普通なら閾値上げる\n",
    "\n",
    "    # 相場×ペナルティ（低価格過大を落とす）\n",
    "    if 'log_land_price' in df.columns:\n",
    "        lp = df['log_land_price'].fillna(df['log_land_price'].median())\n",
    "        if 'infra_penalty_score' in df.columns:\n",
    "            df['infra_penalty_x_log_land_price'] = df['infra_penalty_score'].fillna(0) * lp\n",
    "        if 'hard_penalty_any' in df.columns:\n",
    "            df['hard_penalty_x_log_land_price'] = df['hard_penalty_any'].fillna(0) * lp\n",
    "        if 'has_shidou' in df.columns:\n",
    "            df['has_shidou_x_log_land_price'] = df['has_shidou'].fillna(0) * lp\n",
    "\n",
    "    tr_out = df.iloc[:len(tr)].reset_index(drop=True)\n",
    "    te_out = df.iloc[len(tr):].reset_index(drop=True)\n",
    "    return tr_out, te_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "77c34b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_residential_rights_penalty_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48653540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_residential_mape_boost_features(df):\n",
    "    # --- B. 建物内相対指標 ---\n",
    "    df['senyu_area_ratio_to_median'] = (\n",
    "        df['senyu_area'] /\n",
    "        (df['building_senyu_area_median'] + 1e-6)\n",
    "    )\n",
    "\n",
    "    df['area_per_room_x_senyu_diff'] = (\n",
    "        df['area_per_room'] *\n",
    "        (df['senyu_area'] - df['building_senyu_area_median'])\n",
    "    )\n",
    "\n",
    "    # --- C. 低価格帯プロキシ ---\n",
    "    df['low_price_proxy'] = (\n",
    "        (df['nearest_land_price'] < 60000) |\n",
    "        (df['senyu_area'] < 40)\n",
    "    ).astype('int8')\n",
    "\n",
    "    # --- D. 距離 × 利便性 ---\n",
    "    df['log_dist_x_livability'] = (\n",
    "        np.log1p(df['distance_to_landpoint_m'].clip(1, 3000)) *\n",
    "        df['livability_score']\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2603ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_residential_mape_boost_features(train_df_fe)\n",
    "test_df_fe  = add_residential_mape_boost_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad66507",
   "metadata": {},
   "source": [
    "## 都市スコア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6668883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 東京23区 ---\n",
    "TOKYO_23 = [\n",
    "    '千代田区', '中央区', '港区', '新宿区', '文京区', '台東区',\n",
    "    '墨田区', '江東区', '品川区', '目黒区', '大田区', '世田谷区',\n",
    "    '渋谷区', '中野区', '杉並区', '豊島区', '北区', '荒川区',\n",
    "    '板橋区', '練馬区', '足立区', '葛飾区', '江戸川区'\n",
    "]\n",
    "\n",
    "# --- 政令指定都市 ---\n",
    "SEIREI_CITIES = [\n",
    "    '札幌市', '仙台市', 'さいたま市', '千葉市', '横浜市', '川崎市', '相模原市',\n",
    "    '新潟市', '静岡市', '浜松市', '名古屋市',\n",
    "    '京都市', '大阪市', '堺市', '神戸市',\n",
    "    '岡山市', '広島市', '北九州市', '福岡市', '熊本市'\n",
    "]\n",
    "\n",
    "# --- 首都圏（都道府県） ---\n",
    "CAPITAL_PREFS = ['東京都', '神奈川県', '埼玉県', '千葉県']\n",
    "\n",
    "# --- 県庁所在地（市名のみ） ---\n",
    "PREF_CAPITALS = [\n",
    "    '札幌市','青森市','盛岡市','仙台市','秋田市','山形市','福島市',\n",
    "    '水戸市','宇都宮市','前橋市','さいたま市','千葉市','新宿区',\n",
    "    '横浜市','新潟市','富山市','金沢市','福井市','甲府市','長野市',\n",
    "    '岐阜市','静岡市','名古屋市','津市','大津市','京都市','大阪市',\n",
    "    '神戸市','奈良市','和歌山市','鳥取市','松江市','岡山市','広島市',\n",
    "    '山口市','徳島市','高松市','松山市','高知市','福岡市','佐賀市',\n",
    "    '長崎市','熊本市','大分市','宮崎市','鹿児島市','那覇市'\n",
    "]\n",
    "\n",
    "URBAN_SCORE_MAP = {\n",
    "    'main_city': 1.0,\n",
    "    'mid_city': 0.6,\n",
    "    'other': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "141c5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_urban_class(df: pd.DataFrame):\n",
    "    cond_main = (\n",
    "        ((df['Prefecture name'] == '東京都') &\n",
    "         (df['City/town/village name'].isin(TOKYO_23)))\n",
    "        |\n",
    "        (df['City/town/village name'].isin(['大阪市', '名古屋市']))\n",
    "    )\n",
    "\n",
    "    cond_mid = (\n",
    "        (\n",
    "            (df['Prefecture name'].isin(CAPITAL_PREFS))\n",
    "            &\n",
    "            ~(\n",
    "                (df['Prefecture name'] == '東京都') &\n",
    "                (df['City/town/village name'].isin(TOKYO_23))\n",
    "            )\n",
    "        )\n",
    "        |\n",
    "        (df['City/town/village name'].isin(SEIREI_CITIES))\n",
    "        |\n",
    "        (df['City/town/village name'].isin(PREF_CAPITALS))\n",
    "    )\n",
    "\n",
    "    df = df.copy()\n",
    "    df['UrbanClass'] = 'other'\n",
    "    df.loc[cond_mid, 'UrbanClass'] = 'mid_city'\n",
    "    df.loc[cond_main, 'UrbanClass'] = 'main_city'\n",
    "\n",
    "    df['UrbanClass'] = df['UrbanClass'].astype('category')\n",
    "\n",
    "    df['urban_class_score'] = (\n",
    "        df['UrbanClass']\n",
    "            .map(URBAN_SCORE_MAP)\n",
    "            .astype('float32')\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d543b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = assign_urban_class(train_df_fe)\n",
    "test_df_fe  = assign_urban_class(test_df_fe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47eef9f",
   "metadata": {},
   "source": [
    "## ディスカウントスコア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "706db05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_minmax(train_s):\n",
    "    mn = np.nanmin(train_s.values)\n",
    "    mx = np.nanmax(train_s.values)\n",
    "    return mn, mx\n",
    "\n",
    "def apply_minmax(s, mn, mx):\n",
    "    return (s - mn) / (mx - mn + 1e-9)\n",
    "\n",
    "# --- fit on train ---\n",
    "mm = {}\n",
    "cols_norm = [\n",
    "    'is_lowland',\n",
    "    'ame_depth_max_log1p',\n",
    "    'dosham_dosham_A30a5_005_max_log1p',\n",
    "    'listing_months_log',\n",
    "    'empty_number',\n",
    "    'mochibun_ratio',\n",
    "    'shidou_area_eff',\n",
    "    'money_shuuzenkikin',\n",
    "    # house追加に使うならこれも\n",
    "    'land_x_road_density',\n",
    "]\n",
    "\n",
    "for c in cols_norm:\n",
    "    mm[c] = fit_minmax(train_df_fe[c])\n",
    "\n",
    "def add_scores(df):\n",
    "    df['risk_disaster_score'] = (\n",
    "        0.4 * apply_minmax(df['is_lowland'], *mm['is_lowland']) +\n",
    "        0.3 * apply_minmax(df['ame_depth_max_log1p'], *mm['ame_depth_max_log1p']) +\n",
    "        0.3 * apply_minmax(df['dosham_dosham_A30a5_005_max_log1p'], *mm['dosham_dosham_A30a5_005_max_log1p'])\n",
    "    )\n",
    "\n",
    "    df['risk_liquidity_score'] = (\n",
    "        0.6 * apply_minmax(df['listing_months_log'], *mm['listing_months_log']) +\n",
    "        0.4 * apply_minmax(df['empty_number'], *mm['empty_number'])\n",
    "    )\n",
    "\n",
    "    df['risk_uncertainty_score'] = (\n",
    "        0.4 * apply_minmax(df['mochibun_ratio'], *mm['mochibun_ratio']) +\n",
    "        0.3 * apply_minmax(df['shidou_area_eff'], *mm['shidou_area_eff']) +\n",
    "        0.3 * apply_minmax(df['money_shuuzenkikin'], *mm['money_shuuzenkikin'])\n",
    "    )\n",
    "\n",
    "    df['discount_risk_score'] = (\n",
    "        0.4 * df['risk_disaster_score'] +\n",
    "        0.3 * df['risk_liquidity_score'] +\n",
    "        0.3 * df['risk_uncertainty_score']\n",
    "    )\n",
    "\n",
    "for _df in [train_df_fe, test_df_fe]:\n",
    "    add_scores(_df)\n",
    "\n",
    "# --- house専用追加（tanhではなく正規化を推奨） ---\n",
    "for _df in [train_df_fe, test_df_fe]:\n",
    "    _df['house_discount_score'] = (\n",
    "        0.4 * _df['over_divided'].astype('float32') +\n",
    "        0.3 * _df['small_x_old'].astype('float32') +\n",
    "        0.3 * apply_minmax(_df['land_x_road_density'], *mm['land_x_road_density'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09d88f",
   "metadata": {},
   "source": [
    "## 近傍価格の集約"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b5f0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_price_aggregate(df):\n",
    "    # 例：存在する列だけで組む（列名はあなたの実データに合わせて調整）\n",
    "    cols = [c for c in [\n",
    "        'mean_price_500m_house_log',\n",
    "        'mean_price_1000m_house_log',\n",
    "        'mean_price_2000m_house_log',\n",
    "    ] if c in df.columns]\n",
    "\n",
    "    # 水準：半径が大きい方をやや重め（安定）\n",
    "    w = np.array([0.2, 0.3, 0.5], dtype='float32')[:len(cols)]\n",
    "    w = w / w.sum()\n",
    "    df['nbhd_price_level'] = sum(wi * df[ci].astype('float32') for wi, ci in zip(w, cols))\n",
    "\n",
    "    # 勾配：局所−広域（局所が高い＝局所プレミアム）\n",
    "    if 'mean_price_500m_house_log' in df.columns and 'mean_price_2000m_house_log' in df.columns:\n",
    "        df['nbhd_price_local_premium'] = (\n",
    "            df['mean_price_500m_house_log'].astype('float32') - df['mean_price_2000m_house_log'].astype('float32')\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bd070b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = add_mean_price_aggregate(train_df_fe)\n",
    "test_df_fe  = add_mean_price_aggregate(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446b947",
   "metadata": {},
   "source": [
    "## 出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "97e13a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe.to_parquet(f'{intermediate_path}train_df_fe_v{fe_ver}.parquet')\n",
    "test_df_fe.to_parquet(f'{intermediate_path}test_df_fe_v{fe_ver}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a30a78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_ym',\n",
       " 'building_id',\n",
       " 'building_create_date',\n",
       " 'building_type',\n",
       " 'building_name',\n",
       " 'homes_building_name',\n",
       " 'unit_count',\n",
       " 'lon',\n",
       " 'lat',\n",
       " 'building_structure',\n",
       " 'total_floor_area',\n",
       " 'building_area',\n",
       " 'floor_count',\n",
       " 'basement_floor_count',\n",
       " 'year_built',\n",
       " 'building_land_area',\n",
       " 'land_area_all',\n",
       " 'unit_area_min',\n",
       " 'unit_area_max',\n",
       " 'building_land_chimoku',\n",
       " 'land_youto',\n",
       " 'land_toshi',\n",
       " 'land_chisei',\n",
       " 'land_area_kind',\n",
       " 'land_setback_flg',\n",
       " 'land_setback',\n",
       " 'land_kenpei',\n",
       " 'land_youseki',\n",
       " 'land_road_cond',\n",
       " 'land_seigen',\n",
       " 'building_area_kind',\n",
       " 'management_form',\n",
       " 'management_association_flg',\n",
       " 'reform_exterior_date',\n",
       " 'unit_id',\n",
       " 'room_floor',\n",
       " 'balcony_area',\n",
       " 'dwelling_unit_window_angle',\n",
       " 'room_count',\n",
       " 'unit_area',\n",
       " 'reform_date',\n",
       " 'reform_wet_area_date',\n",
       " 'reform_interior_date',\n",
       " 'renovation_date',\n",
       " 'snapshot_modify_date',\n",
       " 'bukken_type',\n",
       " 'flg_investment',\n",
       " 'empty_number',\n",
       " 'post1',\n",
       " 'post2',\n",
       " 'nl',\n",
       " 'el',\n",
       " 'rosen_name1',\n",
       " 'eki_name1',\n",
       " 'bus_stop1',\n",
       " 'bus_time1',\n",
       " 'walk_distance1',\n",
       " 'rosen_name2',\n",
       " 'eki_name2',\n",
       " 'bus_stop2',\n",
       " 'bus_time2',\n",
       " 'walk_distance2',\n",
       " 'traffic_other',\n",
       " 'snapshot_land_area',\n",
       " 'snapshot_land_shidou',\n",
       " 'land_shidou_a',\n",
       " 'land_shidou_b',\n",
       " 'land_mochibun_a',\n",
       " 'land_mochibun_b',\n",
       " 'house_area',\n",
       " 'flg_new',\n",
       " 'house_kanrinin',\n",
       " 'room_kaisuu',\n",
       " 'snapshot_window_angle',\n",
       " 'madori_number_all',\n",
       " 'madori_kind_all',\n",
       " 'money_kyoueki',\n",
       " 'money_kyoueki_tax',\n",
       " 'money_shuuzen',\n",
       " 'money_shuuzenkikin',\n",
       " 'money_sonota1',\n",
       " 'parking_money',\n",
       " 'parking_money_tax',\n",
       " 'parking_kubun',\n",
       " 'parking_distance',\n",
       " 'parking_number',\n",
       " 'genkyo_code',\n",
       " 'usable_status',\n",
       " 'usable_date',\n",
       " 'school_ele_distance',\n",
       " 'school_jun_distance',\n",
       " 'convenience_distance',\n",
       " 'super_distance',\n",
       " 'drugstore_distance',\n",
       " 'parking_keiyaku',\n",
       " 'money_room',\n",
       " 'building_category',\n",
       " 'is_building_category_unknown',\n",
       " 'property_group',\n",
       " 'Prefecture name',\n",
       " 'City/town/village name',\n",
       " 'unit_area_corrected',\n",
       " 'senyu_area',\n",
       " 'nobeyuka_area',\n",
       " 'kukaku_area',\n",
       " 'tochi_area',\n",
       " 'shikichi_area',\n",
       " 'is_one_room',\n",
       " 'has_k',\n",
       " 'has_dk',\n",
       " 'has_lk',\n",
       " 'has_ldk',\n",
       " 'has_storage_room',\n",
       " 'room_count_clean',\n",
       " 'senyu_area_clean',\n",
       " 'kukaku_area_clean',\n",
       " 'nobeyuka_area_clean',\n",
       " 'tochi_area_clean',\n",
       " 'shikichi_area_clean',\n",
       " 'floor_count_clean',\n",
       " 'room_count_bldg',\n",
       " 'floor_count_bldg',\n",
       " 'senyu_area_bldg',\n",
       " 'kukaku_area_bldg',\n",
       " 'nobeyuka_area_bldg',\n",
       " 'tochi_area_bldg',\n",
       " 'shikichi_area_bldg',\n",
       " 'room_floor_row',\n",
       " 'floor_count_missing',\n",
       " 'room_floor_mismatch',\n",
       " 'has_balcony',\n",
       " 'is_large_room_count',\n",
       " 'senyu_area_log',\n",
       " 'nobeyuka_area_log',\n",
       " 'kukaku_area_log',\n",
       " 'tochi_area_log',\n",
       " 'shikichi_area_log',\n",
       " 'balcony_area_log',\n",
       " 'unit_count_log',\n",
       " 'convenience_distance_log',\n",
       " 'super_distance_log',\n",
       " 'drugstore_distance_log',\n",
       " 'reform_interior 1',\n",
       " 'reform_interior 2',\n",
       " 'reform_interior 3',\n",
       " 'reform_interior 4',\n",
       " 'reform_interior 5',\n",
       " 'reform_interior 6',\n",
       " 'reform_exterior 1',\n",
       " 'reform_exterior 1 ',\n",
       " 'reform_exterior 2',\n",
       " 'reform_wet_area 1',\n",
       " 'reform_wet_area 2',\n",
       " 'reform_wet_area 3',\n",
       " 'reform_wet_area 4',\n",
       " 'reform_wet_area 5',\n",
       " 'reform_wet_area 6',\n",
       " 'built_year',\n",
       " 'target_year',\n",
       " 'built_diff',\n",
       " 'lat_rad',\n",
       " 'lon_rad',\n",
       " 'sin_lat',\n",
       " 'cos_lat',\n",
       " 'sin_lon',\n",
       " 'cos_lon',\n",
       " '土地価格_低層住宅地',\n",
       " '土地価格_南道路',\n",
       " '土地価格_整形地',\n",
       " '土地価格_敷地延長・変形地',\n",
       " '土地価格_角地',\n",
       " '専有部分設備_キッチン_IHコンロ',\n",
       " '専有部分設備_キッチン_カウンターキッチン',\n",
       " '専有部分設備_キッチン_ガスコンロ',\n",
       " '専有部分設備_キッチン_ガスコンロ設置済',\n",
       " '専有部分設備_キッチン_コンロ一口',\n",
       " '専有部分設備_キッチン_コンロ三口',\n",
       " '専有部分設備_キッチン_コンロ二口',\n",
       " '専有部分設備_キッチン_コンロ四口以上',\n",
       " '専有部分設備_キッチン_システムキッチン',\n",
       " '専有部分設備_キッチン_ディスポーザー',\n",
       " '専有部分設備_キッチン_冷蔵庫あり',\n",
       " '専有部分設備_キッチン_浄水器・活水器',\n",
       " '専有部分設備_キッチン_給湯',\n",
       " '専有部分設備_キッチン_電気コンロ',\n",
       " '専有部分設備_キッチン_食器洗い乾燥機',\n",
       " '専有部分設備_トイレ_トイレなし',\n",
       " '専有部分設備_トイレ_共同トイレ',\n",
       " '専有部分設備_トイレ_専用トイレ',\n",
       " '専有部分設備_トイレ_温水洗浄便座',\n",
       " '専有部分設備_収納_ウォークインクローゼット',\n",
       " '専有部分設備_収納_クローゼット',\n",
       " '専有部分設備_収納_シューズインクローゼット',\n",
       " '専有部分設備_収納_シューズクローク',\n",
       " '専有部分設備_収納_シューズボックス',\n",
       " '専有部分設備_収納_トランクルーム',\n",
       " '専有部分設備_収納_パントリー',\n",
       " '専有部分設備_収納_全居室収納',\n",
       " '専有部分設備_収納_床下収納',\n",
       " '専有部分設備_浴室・洗面_オートバス',\n",
       " '専有部分設備_浴室・洗面_シャワー',\n",
       " '専有部分設備_浴室・洗面_シャワー付洗面化粧台',\n",
       " '専有部分設備_浴室・洗面_バスなし',\n",
       " '専有部分設備_浴室・洗面_バス・トイレ別',\n",
       " '専有部分設備_浴室・洗面_共同バス',\n",
       " '専有部分設備_浴室・洗面_専用バス',\n",
       " '専有部分設備_浴室・洗面_洗面所独立',\n",
       " '専有部分設備_浴室・洗面_浴室1.6×1.8M以上',\n",
       " '専有部分設備_浴室・洗面_浴室1.6×2.0M以上',\n",
       " '専有部分設備_浴室・洗面_浴室TV',\n",
       " '専有部分設備_浴室・洗面_浴室乾燥機',\n",
       " '専有部分設備_浴室・洗面_浴室暖房',\n",
       " '専有部分設備_浴室・洗面_追焚機能',\n",
       " '専有部分設備_浴室・洗面_高温差湯式',\n",
       " '専有部分設備_空調・暖房_エアコン',\n",
       " '専有部分設備_空調・暖房_ガス暖房',\n",
       " '専有部分設備_空調・暖房_冷房',\n",
       " '専有部分設備_空調・暖房_床暖房',\n",
       " '専有部分設備_空調・暖房_石油暖房',\n",
       " '専有部分設備_通信_BSアンテナ',\n",
       " '専有部分設備_通信_CATV',\n",
       " '専有部分設備_通信_CATV利用料無料',\n",
       " '専有部分設備_通信_CSアンテナ',\n",
       " '専有部分設備_通信_インターネット使用料無料',\n",
       " '専有部分設備_通信_インターネット対応',\n",
       " '専有部分設備_通信_光ファイバー',\n",
       " '専有部分設備_通信_有線放送',\n",
       " '専有部分設備_通信_高速インターネット',\n",
       " '建物構造・性能_1階の物件',\n",
       " '建物構造・性能_24時間有人管理',\n",
       " '建物構造・性能_2階以上',\n",
       " '建物構造・性能_EV充電設備',\n",
       " '建物構造・性能_TVモニタ付インターホン',\n",
       " '建物構造・性能_ごみ出し24時間OK',\n",
       " '建物構造・性能_エレベーター',\n",
       " '建物構造・性能_オートロック',\n",
       " '建物構造・性能_キッズルーム',\n",
       " '建物構造・性能_ゲストルーム',\n",
       " '建物構造・性能_コンシェルジュサービス',\n",
       " '建物構造・性能_シングル&DINKS向け',\n",
       " '建物構造・性能_セキュリティー充実',\n",
       " '建物構造・性能_セキュリティ会社加入済み',\n",
       " '建物構造・性能_タイル貼り',\n",
       " '建物構造・性能_タワーマンション',\n",
       " '建物構造・性能_テラス',\n",
       " '建物構造・性能_デザイナーズ',\n",
       " '建物構造・性能_ハイグレードマンション',\n",
       " '建物構造・性能_バイク置き場あり',\n",
       " '建物構造・性能_バリアフリー',\n",
       " '建物構造・性能_バルコニー',\n",
       " '建物構造・性能_フリーアクセス',\n",
       " '建物構造・性能_フロントサービス',\n",
       " '建物構造・性能_フローリング',\n",
       " '建物構造・性能_ペット用施設',\n",
       " '建物構造・性能_メゾネット',\n",
       " '建物構造・性能_リゾートマンション',\n",
       " '建物構造・性能_ルーフバルコニー',\n",
       " '建物構造・性能_ロフト付き',\n",
       " '建物構造・性能_二世帯住宅向き',\n",
       " '建物構造・性能_低層マンション',\n",
       " '建物構造・性能_保証付住宅',\n",
       " '建物構造・性能_免震構造',\n",
       " '建物構造・性能_内廊下',\n",
       " '建物構造・性能_出窓',\n",
       " '建物構造・性能_分譲物件',\n",
       " '建物構造・性能_分譲賃貸',\n",
       " '建物構造・性能_制震構造',\n",
       " '建物構造・性能_南向き',\n",
       " '建物構造・性能_吹き抜け',\n",
       " '建物構造・性能_和室',\n",
       " '建物構造・性能_外断熱',\n",
       " '建物構造・性能_大規模マンション',\n",
       " '建物構造・性能_宅配ボックス',\n",
       " '建物構造・性能_室内洗濯機置場',\n",
       " '建物構造・性能_家具・家電付',\n",
       " '建物構造・性能_専用庭',\n",
       " '建物構造・性能_屋上',\n",
       " '建物構造・性能_屋上・ルーフバルコニー',\n",
       " '建物構造・性能_平面駐車場',\n",
       " '建物構造・性能_最上階',\n",
       " '建物構造・性能_洗濯機置場あり',\n",
       " '建物構造・性能_照明器具付',\n",
       " '建物構造・性能_管理人常駐',\n",
       " '建物構造・性能_耐震・制震・免震構造',\n",
       " '建物構造・性能_耐震構造',\n",
       " '建物構造・性能_自走式立体駐車場',\n",
       " '建物構造・性能_複層ガラス採用（二重サッシ・防犯サッシ等）',\n",
       " '建物構造・性能_角部屋',\n",
       " '建物構造・性能_防犯カメラ',\n",
       " '建物構造・性能_隣家との間隔が広い',\n",
       " '建物構造・性能_駐車場あり',\n",
       " '建物構造・性能_駐輪場あり',\n",
       " '建物設備（給排水・インフラ）_オール電化',\n",
       " '建物設備（給排水・インフラ）_ガスその他',\n",
       " '建物設備（給排水・インフラ）_プロパンガス',\n",
       " '建物設備（給排水・インフラ）_下水',\n",
       " '建物設備（給排水・インフラ）_井戸',\n",
       " '建物設備（給排水・インフラ）_公営水道',\n",
       " '建物設備（給排水・インフラ）_太陽光発電システム',\n",
       " '建物設備（給排水・インフラ）_家庭用燃料電池',\n",
       " '建物設備（給排水・インフラ）_排水その他',\n",
       " '建物設備（給排水・インフラ）_水道その他',\n",
       " '建物設備（給排水・インフラ）_汲取',\n",
       " '建物設備（給排水・インフラ）_浄化槽',\n",
       " '建物設備（給排水・インフラ）_環境にやさしい',\n",
       " '建物設備（給排水・インフラ）_都市ガス',\n",
       " '環境プレミアム_コンビニ 400ｍ以内',\n",
       " '環境プレミアム_コンビニ 800ｍ以内',\n",
       " '環境プレミアム_スーパー 800ｍ以内',\n",
       " '環境プレミアム_フィットネス施設（プール含む）800m以内',\n",
       " '環境プレミアム_中学校 800m以内',\n",
       " '環境プレミアム_保育園・幼稚園 400m以内',\n",
       " '環境プレミアム_公園 400ｍ以内',\n",
       " '環境プレミアム_子育てに嬉しい環境',\n",
       " '環境プレミアム_小学校 800ｍ以内',\n",
       " '環境プレミアム_総合病院 800ｍ以内',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_インスペクション（建物検査）報告書',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_住宅性能保証制度証明書',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_修繕・点検の記録',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_地盤調査済',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_建築確認完了検査済証',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_建設住宅性能評価書（新築時）',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_建設住宅性能評価書（既存住宅）',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_新築時・増改築時の設計図書',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_瑕疵保証（不動産会社独自）付',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_瑕疵保険（国交省指定）による保証付',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_瑕疵保険（国交省指定）による保証利用可',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_空き家バンク登録物件',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_耐震基準適合証明書',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_設計住宅性能評価書',\n",
       " '用途・投資セグメント_不動産の証明書・性能評価_長期優良住宅認定通知書',\n",
       " '用途・投資セグメント_売買ステータス_満室賃貸中',\n",
       " '立地プレミアム_最寄り駅が始発駅',\n",
       " '立地プレミアム_複数路線',\n",
       " 'money_kyoueki_tax_filled',\n",
       " 'money_kyoueki_std',\n",
       " 'parking_money_tax_filled',\n",
       " 'parking_money_std',\n",
       " 'window_angle',\n",
       " 'is_south_window',\n",
       " 'is_south_main_light',\n",
       " 'window_angle_mismatch',\n",
       " 'south_room_ratio_proxy',\n",
       " 'is_investment',\n",
       " 'is_business',\n",
       " 'investment_missing',\n",
       " 'investment_proxy',\n",
       " 'land_area_kind_clean',\n",
       " 'is_land_area_koubo',\n",
       " 'is_land_area_jissoku',\n",
       " 'land_area_kind_missing',\n",
       " 'building_area_kind_clean',\n",
       " 'is_area_kabeshin',\n",
       " 'is_area_uchinori',\n",
       " 'building_area_kind_missing',\n",
       " 'has_setback',\n",
       " 'setback_flg_missing',\n",
       " 'land_setback_clean',\n",
       " 'land_setback_log',\n",
       " 'setback_inconsistent',\n",
       " 'has_parking',\n",
       " 'parking_full',\n",
       " 'parking_nearby',\n",
       " 'parking_kubun_missing',\n",
       " 'parking_contract_required',\n",
       " 'parking_contract_missing',\n",
       " 'parking_included_in_rent',\n",
       " 'parking_fee_separate',\n",
       " 'parking_money_included_flag',\n",
       " 'parking_money_log',\n",
       " 'parking_cost_heavy',\n",
       " 'parking_distance_log',\n",
       " 'has_multiple_parking',\n",
       " 'parking_number_missing',\n",
       " 'parking_penalty_score',\n",
       " 'is_residential_land',\n",
       " 'is_non_residential_land',\n",
       " 'is_flat_land',\n",
       " 'is_lowland',\n",
       " 'has_slope_risk',\n",
       " 'y_log',\n",
       " 'nearest_land_price',\n",
       " 'weighted_land_price_3',\n",
       " 'distance_to_landpoint_m',\n",
       " 'log_land_price',\n",
       " 'log_weighted_land_price_3',\n",
       " 'land_price_yoy_nearest',\n",
       " 'land_price_yoy_w3',\n",
       " 'land_price_dlog_nearest',\n",
       " 'land_price_dlog_w3',\n",
       " 'PTN_2020_nn',\n",
       " 'RTA_2025_nn',\n",
       " 'RTB_2025_nn',\n",
       " 'RTC_2025_nn',\n",
       " 'RTD_2025_nn',\n",
       " 'RTE_2025_nn',\n",
       " 'pop_trend_rate_nn',\n",
       " 'road_len_total',\n",
       " 'road_len_wide',\n",
       " 'road_len_narrow',\n",
       " 'road_wide_ratio',\n",
       " 'road_narrow_ratio',\n",
       " 'road_len_total_gap',\n",
       " 'road_narrow_ratio_gap',\n",
       " 'road_len_density',\n",
       " 'road_len_density_gap',\n",
       " 'dist_to_road_any_m',\n",
       " 'dist_to_road_major_m',\n",
       " 'dist_to_road_highway_m',\n",
       " 'road_cnt_any_in_100m',\n",
       " 'road_cnt_major_in_100m',\n",
       " 'road_cnt_any_in_300m',\n",
       " 'road_cnt_major_in_300m',\n",
       " 'road_cnt_any_in_500m',\n",
       " 'road_cnt_major_in_500m',\n",
       " 'zone_group',\n",
       " 'zone_residential_rank',\n",
       " 'is_lowrise_residential',\n",
       " 'kenpei',\n",
       " 'youseki',\n",
       " 'is_urbanized_area',\n",
       " 'is_urban_control_area',\n",
       " 'is_fireproof_area',\n",
       " 'is_quasi_fireproof_area',\n",
       " 'has_height_limit',\n",
       " 'has_district_plan',\n",
       " 'is_land_readjustment_area',\n",
       " 'is_high_utilization_area',\n",
       " 'is_urban_renaissance_area',\n",
       " 'is_special_far_area',\n",
       " 'is_highrise_residential_area',\n",
       " 'is_disaster_prevention_block',\n",
       " 'is_redevelopment_core_area',\n",
       " 'elev_mean',\n",
       " 'elev_range',\n",
       " 'slope_mean',\n",
       " 'slope_max',\n",
       " 'slope_range',\n",
       " 'station_power_sum3',\n",
       " 'station_power_max3',\n",
       " 'disaster_hit',\n",
       " 'disaster_n_types',\n",
       " 'disaster_score_sum',\n",
       " 'disaster_score_max',\n",
       " 'disaster_score',\n",
       " 'elem_school_500m',\n",
       " 'junior_school_1km',\n",
       " 'dist_elem_school_m',\n",
       " 'dist_junior_school_m',\n",
       " 'dist_hospital_m',\n",
       " 'dist_clinic_m',\n",
       " 'hospital_1km',\n",
       " 'dist_hospital_log',\n",
       " 'clinic_500m',\n",
       " 'dist_clinic_log',\n",
       " 'hospital_beds_nearest',\n",
       " 'hospital_is_emergency_nearest',\n",
       " 'hospital_is_disaster_nearest',\n",
       " 'ame_dist_log',\n",
       " 'ame_depth_max_log1p',\n",
       " 'ame_depth_effect',\n",
       " 'kouzui_keikaku_in',\n",
       " 'kouzui_keikaku_rank_max',\n",
       " 'kouzui_keikaku_dist_m_log1p',\n",
       " 'kouzui_saidai_in',\n",
       " 'kouzui_saidai_rank_max',\n",
       " 'kouzui_saidai_dist_m_log1p',\n",
       " 'kouzui_keikaku_rank_ge3',\n",
       " 'kouzui_saidai_rank_ge3',\n",
       " 'kyuusha_in',\n",
       " 'kyuusha_dist_m',\n",
       " 'keikai_genshou1_in',\n",
       " 'keikai_genshou2_in',\n",
       " 'keikai_genshou3_in',\n",
       " 'keikai_kuiki1_in',\n",
       " 'keikai_kuiki2_in',\n",
       " 'keikai_kuiki3_in',\n",
       " 'keikai_kuiki4_in',\n",
       " 'keikai_kouji_date_min',\n",
       " 'keikai_dist_m',\n",
       " 'dosham_in',\n",
       " 'dosham_phen_gake',\n",
       " 'dosham_phen_doseki',\n",
       " 'dosham_phen_jisuberi',\n",
       " 'dosham_phen_nadare',\n",
       " 'dosham_A30a5_005_max',\n",
       " 'dosham_A30a5_006_max',\n",
       " 'dosham_A30a5_007_max',\n",
       " 'dosham_A30a5_008_max',\n",
       " 'dosham_A30a5_009_max',\n",
       " 'dosham_A30a5_010_max',\n",
       " 'tsunami_in',\n",
       " 'tsunami_depth_max_m',\n",
       " 'tsunami_depth_rank_max',\n",
       " 'tsunami_dist_log1p',\n",
       " 'tsunami_depth_max_log1p',\n",
       " 'tsunami_depth_ge1m',\n",
       " 'tsunami_depth_ge3m',\n",
       " 'tsunami_depth_ge5m',\n",
       " 'tsunami_depth_ge10m',\n",
       " 'takashio_in',\n",
       " 'takashio_depth_max_m',\n",
       " 'takashio_depth_rank_max',\n",
       " 'takashio_dist_log1p',\n",
       " 'tsunami_near_500m',\n",
       " 'tsunami_near_1km',\n",
       " 'tsunami_near_3km',\n",
       " 'takashio_depth_max_log1p',\n",
       " 'takashio_depth_ge1m',\n",
       " 'takashio_depth_ge3m',\n",
       " 'takashio_depth_ge5m',\n",
       " 'takashio_depth_ge10m',\n",
       " 'takashio_near_500m',\n",
       " 'takashio_near_1km',\n",
       " 'takashio_near_3km',\n",
       " 'hinanjo_dist_m',\n",
       " 'hinanjo_dist_m_clip',\n",
       " 'hinanjo_dist_log1p',\n",
       " 'hinanjo_cnt_r500',\n",
       " 'hinanjo_cap_sum_r500',\n",
       " 'hinanjo_cap_max_r500',\n",
       " 'hinanjo_area_sum_r500',\n",
       " 'hinanjo_area_max_r500',\n",
       " 'hinanjo_cap_sum_log1p_r500',\n",
       " 'hinanjo_area_sum_log1p_r500',\n",
       " 'hinanjo_cnt_r1000',\n",
       " 'hinanjo_cap_sum_r1000',\n",
       " 'hinanjo_cap_max_r1000',\n",
       " 'hinanjo_area_sum_r1000',\n",
       " 'hinanjo_area_max_r1000',\n",
       " 'hinanjo_cap_sum_log1p_r1000',\n",
       " 'hinanjo_area_sum_log1p_r1000',\n",
       " 'hinanjo_cnt_r2000',\n",
       " 'hinanjo_cap_sum_r2000',\n",
       " 'hinanjo_cap_max_r2000',\n",
       " 'hinanjo_area_sum_r2000',\n",
       " 'hinanjo_area_max_r2000',\n",
       " 'hinanjo_cap_sum_log1p_r2000',\n",
       " 'hinanjo_area_sum_log1p_r2000',\n",
       " 'hinanjo_dist_for_jishin_flg_m',\n",
       " 'hinanjo_dist_for_jishin_flg_clip',\n",
       " 'hinanjo_dist_for_jishin_flg_log1p',\n",
       " 'hinanjo_cnt_for_jishin_flg_r1000',\n",
       " 'hinanjo_cap_sum_for_jishin_flg_r1000',\n",
       " 'hinanjo_cnt_for_jishin_flg_r2000',\n",
       " 'hinanjo_cap_sum_for_jishin_flg_r2000',\n",
       " 'hinanjo_dist_for_tsunami_flg_m',\n",
       " 'hinanjo_dist_for_tsunami_flg_clip',\n",
       " 'hinanjo_dist_for_tsunami_flg_log1p',\n",
       " 'hinanjo_cnt_for_tsunami_flg_r1000',\n",
       " 'hinanjo_cap_sum_for_tsunami_flg_r1000',\n",
       " 'hinanjo_cnt_for_tsunami_flg_r2000',\n",
       " 'hinanjo_cap_sum_for_tsunami_flg_r2000',\n",
       " 'hinanjo_dist_for_suigai_flg_m',\n",
       " 'hinanjo_dist_for_suigai_flg_clip',\n",
       " 'hinanjo_dist_for_suigai_flg_log1p',\n",
       " 'hinanjo_cnt_for_suigai_flg_r1000',\n",
       " 'hinanjo_cap_sum_for_suigai_flg_r1000',\n",
       " 'hinanjo_cnt_for_suigai_flg_r2000',\n",
       " 'hinanjo_cap_sum_for_suigai_flg_r2000',\n",
       " 'hinanjo_dist_for_kazan_flg_m',\n",
       " 'hinanjo_dist_for_kazan_flg_clip',\n",
       " 'hinanjo_dist_for_kazan_flg_log1p',\n",
       " 'hinanjo_cnt_for_kazan_flg_r1000',\n",
       " 'hinanjo_cap_sum_for_kazan_flg_r1000',\n",
       " 'hinanjo_cnt_for_kazan_flg_r2000',\n",
       " 'hinanjo_cap_sum_for_kazan_flg_r2000',\n",
       " 'hinanjo_dist_for_all_flg_m',\n",
       " 'hinanjo_dist_for_all_flg_clip',\n",
       " 'hinanjo_dist_for_all_flg_log1p',\n",
       " 'hinanjo_cnt_for_all_flg_r1000',\n",
       " 'hinanjo_cap_sum_for_all_flg_r1000',\n",
       " 'hinanjo_cnt_for_all_flg_r2000',\n",
       " 'hinanjo_cap_sum_for_all_flg_r2000',\n",
       " 'hinanjo_dist_shubetsu_避難所_m',\n",
       " 'hinanjo_dist_shubetsu_避難所_log1p',\n",
       " 'hinanjo_cnt_shubetsu_避難所_r1000',\n",
       " 'hinanjo_cap_sum_shubetsu_避難所_r1000',\n",
       " 'hinanjo_dist_shubetsu_避難場所_m',\n",
       " 'hinanjo_dist_shubetsu_避難場所_log1p',\n",
       " 'hinanjo_cnt_shubetsu_避難場所_r1000',\n",
       " 'hinanjo_cap_sum_shubetsu_避難場所_r1000',\n",
       " 'Prefecture name_te',\n",
       " 'City/town/village name_te',\n",
       " 'area_ratio',\n",
       " 'is_basement',\n",
       " 'relative_floor',\n",
       " 'unit_land_density_raw',\n",
       " 'unit_land_density',\n",
       " 'unit_land_density_over1',\n",
       " 'area_per_room_raw',\n",
       " 'area_per_room',\n",
       " 'area_per_room_log',\n",
       " 'land_building_ratio_raw',\n",
       " 'land_building_ratio',\n",
       " 'land_building_ratio_hi',\n",
       " 'senyu_area_x_built_diff',\n",
       " 'area_per_room_x_built_diff',\n",
       " 'building_senyu_area_median',\n",
       " 'building_room_floor_max',\n",
       " 'building_unit_count',\n",
       " 'mean_price_300m',\n",
       " 'median_price_300m',\n",
       " 'std_price_300m',\n",
       " 'iqr_price_300m',\n",
       " 'count_neighbors_300m',\n",
       " 'mean_price_300m_house',\n",
       " 'count_neighbors_300m_house',\n",
       " 'mean_price_300m_mansion',\n",
       " 'count_neighbors_300m_mansion',\n",
       " 'mean_price_300m_log',\n",
       " 'median_price_300m_log',\n",
       " 'mean_price_300m_house_log',\n",
       " 'mean_price_300m_mansion_log',\n",
       " 'mean_price_500m',\n",
       " 'median_price_500m',\n",
       " 'std_price_500m',\n",
       " 'iqr_price_500m',\n",
       " 'count_neighbors_500m',\n",
       " 'mean_price_500m_house',\n",
       " 'count_neighbors_500m_house',\n",
       " 'mean_price_500m_mansion',\n",
       " 'count_neighbors_500m_mansion',\n",
       " 'mean_price_500m_log',\n",
       " 'median_price_500m_log',\n",
       " 'mean_price_500m_house_log',\n",
       " 'mean_price_500m_mansion_log',\n",
       " 'mean_price_1000m',\n",
       " 'median_price_1000m',\n",
       " 'std_price_1000m',\n",
       " 'iqr_price_1000m',\n",
       " 'count_neighbors_1000m',\n",
       " 'mean_price_1000m_house',\n",
       " 'count_neighbors_1000m_house',\n",
       " 'mean_price_1000m_mansion',\n",
       " 'count_neighbors_1000m_mansion',\n",
       " 'mean_price_1000m_log',\n",
       " 'median_price_1000m_log',\n",
       " 'mean_price_1000m_house_log',\n",
       " 'mean_price_1000m_mansion_log',\n",
       " 'mean_price_2000m',\n",
       " 'median_price_2000m',\n",
       " 'std_price_2000m',\n",
       " 'iqr_price_2000m',\n",
       " 'count_neighbors_2000m',\n",
       " 'mean_price_2000m_house',\n",
       " 'count_neighbors_2000m_house',\n",
       " 'mean_price_2000m_mansion',\n",
       " 'count_neighbors_2000m_mansion',\n",
       " 'mean_price_2000m_log',\n",
       " 'median_price_2000m_log',\n",
       " 'mean_price_2000m_house_log',\n",
       " 'mean_price_2000m_mansion_log',\n",
       " 'walk_distance1_raw',\n",
       " 'access_zone',\n",
       " 'door_to_station_min',\n",
       " 'door_to_station_min_log',\n",
       " 'walk_distance_bin',\n",
       " 'eki_name1_te',\n",
       " 'eki_name2_te',\n",
       " 'rosen_name1_te',\n",
       " 'rosen_name2_te',\n",
       " 'density_floor_area',\n",
       " 'senyu_area_range',\n",
       " 'has_senyu_area_range',\n",
       " 'senyu_area_range_log',\n",
       " 'empty_ratio',\n",
       " 'last_reform_date',\n",
       " 'last_reform_year',\n",
       " 'has_renovation',\n",
       " 'renovation_recency',\n",
       " 'effective_age',\n",
       " 'target_ym_date',\n",
       " 'listing_months',\n",
       " 'listing_months_log',\n",
       " 'ratio_mean_land',\n",
       " 'ratio_weighted_land',\n",
       " 'logdiff_mean_nearest',\n",
       " 'logdiff_median_weighted',\n",
       " 'ratio_mean_land_clip',\n",
       " 'ratio_weighted_land_clip',\n",
       " 'ratio_mean_land_log',\n",
       " 'ratio_weighted_land_log',\n",
       " 'logdiff_mean_nearest_clip',\n",
       " 'logdiff_median_weighted_clip',\n",
       " 'is_land_price_gap_ratio_mean',\n",
       " 'is_land_price_gap_ratio_weighted',\n",
       " 'kyoueki_per_m2',\n",
       " 'shuuzen_per_m2',\n",
       " 'kyoueki_per_unit',\n",
       " 'shuuzen_per_unit',\n",
       " 'has_kyoueki',\n",
       " 'has_shuuzen',\n",
       " 'land_cheap_flag',\n",
       " 'land_expensive_flag',\n",
       " 'land_theoretical_price',\n",
       " 'land_theoretical_price_x_senyu',\n",
       " 'senyu_to_land_value_ratio',\n",
       " 'land_theoretical_price_weighted',\n",
       " 'land_theoretical_price_weighted_x_senyu',\n",
       " 'land_theoretical_price_within1km_mp',\n",
       " 'amenity_count_within_500m',\n",
       " 'amenity_count_within_1000m',\n",
       " 'genkyo_flex_score',\n",
       " 'usable_immediate_flag',\n",
       " 'usable_fixed_date_flag',\n",
       " 'usable_status_score',\n",
       " 'usable_months_delay',\n",
       " 'has_management_association',\n",
       " 'has_professional_management',\n",
       " 'has_manager',\n",
       " 'management_form_score',\n",
       " 'manager_presence_score',\n",
       " 'management_total_score',\n",
       " 'mochibun_ratio',\n",
       " 'has_mochibun',\n",
       " 'mochibun_area',\n",
       " 'mochibun_area_log',\n",
       " 'shidou_area_eff',\n",
       " 'land_shidou_ratio',\n",
       " 'has_shidou',\n",
       " 'shidou_area_ratio',\n",
       " 'urban_score',\n",
       " 'tag_land_score',\n",
       " 'tag_unit_score',\n",
       " 'tag_building_score',\n",
       " 'tag_infra_score',\n",
       " 'tag_env_score',\n",
       " 'tag_cert_score',\n",
       " 'tag_rule_score_raw',\n",
       " 'tag_rule_score',\n",
       " 'access_station_score',\n",
       " 'neighbor_density_score',\n",
       " 'room_space_score',\n",
       " 'land_road_cond_score',\n",
       " 'ksi_road_access_score',\n",
       " 'ksi_zoning_score',\n",
       " 'ksi_geo_risk_score',\n",
       " 'score_access',\n",
       " 'score_daily',\n",
       " 'score_room',\n",
       " 'score_building',\n",
       " 'livability_score',\n",
       " 'is_no_road',\n",
       " 'road_len_density_x_no_road',\n",
       " 'road_narrow_ratio_gap_x_no_road',\n",
       " 'max_floor_area',\n",
       " 'max_floor_area_log',\n",
       " 'max_floor_area_missing',\n",
       " 'lowrise_x_station_log',\n",
       " 'lowrise_x_station_missing',\n",
       " 'lowrise_x_landprice_log',\n",
       " 'lowrise_x_landprice_missing',\n",
       " 'urban_control_x_land_price_log',\n",
       " 'fireproof_x_max_floor_area_log',\n",
       " 'district_plan_x_station_log',\n",
       " 'high_util_x_youseki',\n",
       " 'height_limit_x_max_floor_area_log',\n",
       " 'urban_renaissance_x_station_log',\n",
       " 'fireproof_x_structure',\n",
       " 'setback_ratio',\n",
       " 'land_constraint_score',\n",
       " 'premium_equipment_count',\n",
       " 'age_decay_30',\n",
       " 'is_wood',\n",
       " 'is_steel',\n",
       " 'is_rcsrc',\n",
       " 'is_precast',\n",
       " 'is_block',\n",
       " 'is_other_structure',\n",
       " 'structure_group',\n",
       " 'log_land_price_x_effective_age',\n",
       " 'log_land_price_x_age_log1p',\n",
       " 'log_land_price_x_age_decay_30',\n",
       " 'log_land_price_x_livability_score',\n",
       " 'log_land_price_x_urban_score',\n",
       " 'log_land_price_x_is_wood',\n",
       " 'log_land_price_x_is_steel',\n",
       " 'log_land_price_x_is_rcsrc',\n",
       " 'log_land_price_x_is_precast',\n",
       " 'log_land_price_x_is_block',\n",
       " 'log_land_price_x_is_other_structure',\n",
       " 'log_weighted_land_price_3_x_effective_age',\n",
       " 'log_weighted_land_price_3_x_age_log1p',\n",
       " 'log_weighted_land_price_3_x_age_decay_30',\n",
       " 'log_weighted_land_price_3_x_livability_score',\n",
       " 'log_weighted_land_price_3_x_urban_score',\n",
       " 'log_weighted_land_price_3_x_is_wood',\n",
       " 'log_weighted_land_price_3_x_is_steel',\n",
       " 'log_weighted_land_price_3_x_is_rcsrc',\n",
       " 'log_weighted_land_price_3_x_is_precast',\n",
       " 'log_weighted_land_price_3_x_is_block',\n",
       " 'log_weighted_land_price_3_x_is_other_structure',\n",
       " 'land_theoretical_price_x_effective_age',\n",
       " 'land_theoretical_price_x_age_log1p',\n",
       " 'land_theoretical_price_x_age_decay_30',\n",
       " 'land_theoretical_price_x_livability_score',\n",
       " 'land_theoretical_price_x_urban_score',\n",
       " 'land_theoretical_price_x_is_wood',\n",
       " 'land_theoretical_price_x_is_steel',\n",
       " 'land_theoretical_price_x_is_rcsrc',\n",
       " 'land_theoretical_price_x_is_precast',\n",
       " 'land_theoretical_price_x_is_block',\n",
       " 'land_theoretical_price_x_is_other_structure',\n",
       " 'land_theoretical_price_weighted_x_effective_age',\n",
       " 'land_theoretical_price_weighted_x_age_log1p',\n",
       " 'land_theoretical_price_weighted_x_age_decay_30',\n",
       " 'land_theoretical_price_weighted_x_livability_score',\n",
       " 'land_theoretical_price_weighted_x_urban_score',\n",
       " 'land_theoretical_price_weighted_x_is_wood',\n",
       " 'land_theoretical_price_weighted_x_is_steel',\n",
       " 'land_theoretical_price_weighted_x_is_rcsrc',\n",
       " 'land_theoretical_price_weighted_x_is_precast',\n",
       " 'land_theoretical_price_weighted_x_is_block',\n",
       " 'land_theoretical_price_weighted_x_is_other_structure',\n",
       " 'land_theoretical_price_within1km_mp_x_effective_age',\n",
       " 'land_theoretical_price_within1km_mp_x_age_log1p',\n",
       " 'land_theoretical_price_within1km_mp_x_age_decay_30',\n",
       " 'land_theoretical_price_within1km_mp_x_livability_score',\n",
       " 'land_theoretical_price_within1km_mp_x_urban_score',\n",
       " 'land_theoretical_price_within1km_mp_x_is_wood',\n",
       " 'land_theoretical_price_within1km_mp_x_is_steel',\n",
       " 'land_theoretical_price_within1km_mp_x_is_rcsrc',\n",
       " 'land_theoretical_price_within1km_mp_x_is_precast',\n",
       " 'land_theoretical_price_within1km_mp_x_is_block',\n",
       " 'land_theoretical_price_within1km_mp_x_is_other_structure',\n",
       " 'hard_penalty_any',\n",
       " 'tag_land_premium_score',\n",
       " 'tag_land_penalty_flag',\n",
       " 'kitchen_upgrade_count',\n",
       " 'kitchen_burner_score',\n",
       " 'kitchen_grade_score',\n",
       " 'kitchen_low_flag',\n",
       " 'kitchen_high_flag',\n",
       " 'wet_area_upgrade_count',\n",
       " 'wet_area_separation_flag',\n",
       " 'wet_area_grade_score',\n",
       " 'toilet_upgrade_count',\n",
       " 'storage_score',\n",
       " 'storage_high_flag',\n",
       " 'hvac_count',\n",
       " 'hvac_grade_score',\n",
       " 'net_ready_score',\n",
       " 'security_score',\n",
       " 'shared_service_score',\n",
       " 'luxury_mansion_flag',\n",
       " 'infra_penalty_score',\n",
       " 'infra_modern_score',\n",
       " 'env_premium_count_400m',\n",
       " 'env_premium_count_800m',\n",
       " 'env_premium_weighted',\n",
       " 'cert_score',\n",
       " 'cert_strong_flag',\n",
       " 'is_rented_full_flag',\n",
       " 'reform_interior_cnt',\n",
       " 'reform_exterior_cnt',\n",
       " 'reform_wet_cnt',\n",
       " 'reform_total_cnt',\n",
       " 'reform_any_flag',\n",
       " 'reform_wet_heavy_flag',\n",
       " 'semi_premium_count',\n",
       " 'discount_pressure_score',\n",
       " 'effective_area_log',\n",
       " 'has_land_theoretical_price',\n",
       " 'has_eki2',\n",
       " 'has_density',\n",
       " 'urban_score_scaled',\n",
       " 'area_for_proxy',\n",
       " 'has_area_for_proxy',\n",
       " 'area_for_proxy_filled',\n",
       " 'proxy_land_price_calibrated',\n",
       " 'effective_land_price',\n",
       " 'keikai_dist_clip',\n",
       " 'keikai_dist_log1p',\n",
       " 'keikai_within_100m',\n",
       " 'keikai_within_300m',\n",
       " 'keikai_within_1000m',\n",
       " 'keikai_within_5000m',\n",
       " 'keikai_no_near',\n",
       " 'kyuusha_dist_clip',\n",
       " 'kyuusha_dist_log1p',\n",
       " 'kyuusha_within_100m',\n",
       " 'kyuusha_within_300m',\n",
       " 'kyuusha_within_1000m',\n",
       " 'kyuusha_within_5000m',\n",
       " 'kyuusha_no_near',\n",
       " 'dosham_dosham_A30a5_005_max_has',\n",
       " 'dosham_dosham_A30a5_005_max_log1p',\n",
       " 'dosham_dosham_A30a5_006_max_has',\n",
       " 'dosham_dosham_A30a5_006_max_log1p',\n",
       " 'dosham_dosham_A30a5_007_max_has',\n",
       " 'dosham_dosham_A30a5_007_max_log1p',\n",
       " 'effective_age_missing',\n",
       " 'age_0_10',\n",
       " 'age_10_20',\n",
       " 'age_20_30',\n",
       " 'age_30_40',\n",
       " 'age_40_60',\n",
       " 'age_60_plus',\n",
       " 'age_40_over',\n",
       " 'age_60_over',\n",
       " 'age_40_over_x_is_wood',\n",
       " 'age_60_over_x_is_wood',\n",
       " 'no_renovation_flag',\n",
       " 'age_40_over_x_no_renov',\n",
       " 'age_60_over_x_no_renov',\n",
       " 'theoretical_building_value',\n",
       " 'land_dominance_score',\n",
       " 'land_dominance_score_log',\n",
       " 'land_dominant_flag',\n",
       " 'nb_build_cnt_300m',\n",
       " 'nb_build_cnt_500m',\n",
       " 'nb_build_cnt_1000m',\n",
       " 'nb_build_cnt_2000m',\n",
       " 'geohash_6',\n",
       " 'geohash6_te_logy',\n",
       " 'dlog_w3_x_log_land_price',\n",
       " 'dlog_w3_x_land_dom',\n",
       " 'dlog_w3_x_age40',\n",
       " 'nobeyuka_area_x_age_40_over',\n",
       " 'nobeyuka_area_x_age_60_over',\n",
       " 'log_land_price_x_nb_build',\n",
       " 'nb_build_cnt_500m_log',\n",
       " 'land_x_road_density',\n",
       " 'over_divided',\n",
       " 'small_building',\n",
       " 'small_x_old',\n",
       " 'floor_area_per_floor',\n",
       " 'floor_area_per_floor_log',\n",
       " 'is_midrise',\n",
       " 'is_highrise',\n",
       " 'is_lowrise',\n",
       " 'land_tp_w_log',\n",
       " 'land_tp_w_log_x_max_floor_area_log',\n",
       " 'land_tp_w_log_x_infra_penalty',\n",
       " 'land_tp_w_log_x_land_penalty_flag',\n",
       " 'land_tp_w_log_x_shidou_area_ratio',\n",
       " 'penalty_any_flag',\n",
       " 'is_midrise_x_penalty',\n",
       " 'rel_floor_sq',\n",
       " 'rel_floor_over_0_8',\n",
       " 'rel_floor_over_0_9',\n",
       " 'is_tower_20',\n",
       " 'floor_premium_interaction',\n",
       " 'is_top_floor',\n",
       " 'is_high_floor_20',\n",
       " 'maint_per_m2_total',\n",
       " 'maint_per_m2_total_log',\n",
       " 'maint_x_station',\n",
       " 'maint_x_age',\n",
       " 'maint_x_kyoueki_std_log',\n",
       " 'tower_x_relative_floor',\n",
       " 'tower_x_high_floor',\n",
       " 'highgrade_x_maint',\n",
       " 'resort_x_elev',\n",
       " 'is_luxury_fee_flag',\n",
       " 'maint_x_city_te',\n",
       " 'maint_x_log_land_price',\n",
       " 'rel_floor_x_maint',\n",
       " 'mochibun_ratio_log',\n",
       " 'mochibun_anomaly_flag',\n",
       " 'infra_penalty_x_log_land_price',\n",
       " 'hard_penalty_x_log_land_price',\n",
       " 'has_shidou_x_log_land_price',\n",
       " 'senyu_area_ratio_to_median',\n",
       " 'area_per_room_x_senyu_diff',\n",
       " 'low_price_proxy',\n",
       " 'log_dist_x_livability',\n",
       " 'UrbanClass',\n",
       " 'urban_class_score',\n",
       " 'risk_disaster_score',\n",
       " 'risk_liquidity_score',\n",
       " 'risk_uncertainty_score',\n",
       " 'discount_risk_score',\n",
       " 'house_discount_score',\n",
       " 'nbhd_price_level',\n",
       " 'nbhd_price_local_premium']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_fe.columns.to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
