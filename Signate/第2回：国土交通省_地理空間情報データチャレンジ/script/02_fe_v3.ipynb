{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ed3091",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7375f2",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b518e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの取り扱いに関するライブラリ\n",
    "import numpy as np # 高速計算\n",
    "import pandas as pd # 表データの扱い\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29fd42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自身がファイルを格納したディレクトリを指定\n",
    "intermediate_path = '../output/intermediate_file/'\n",
    "\n",
    "# スクリプトのバージョン指定\n",
    "preprocessing_ver = 4\n",
    "geo_ver = 1\n",
    "fe_ver = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bd4b4",
   "metadata": {},
   "source": [
    "## File Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae27961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = pd.read_parquet(f'{intermediate_path}train_df_preprocessed_v{preprocessing_ver}.parquet')\n",
    "test_df_fe = pd.read_parquet(f'{intermediate_path}test_df_preprocessed_v{preprocessing_ver}.parquet')\n",
    "\n",
    "fe_cols = test_df_fe.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63cbbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = 'target_ym'\n",
    "target_col = 'money_room'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32856b",
   "metadata": {},
   "source": [
    "## 国土数値情報と結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d78cbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_geo = pd.read_parquet(f'{intermediate_path}train_df_geo_v{geo_ver}.parquet')\n",
    "test_df_geo = pd.read_parquet(f'{intermediate_path}test_df_geo_v{geo_ver}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3ebbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkey_cols = ['target_ym', 'building_id', 'unit_id']\n",
    "\n",
    "train_df_fe = train_df_fe.merge(train_df_geo, on=pkey_cols)\n",
    "test_df_fe = test_df_fe.merge(test_df_geo, on=pkey_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea447671",
   "metadata": {},
   "source": [
    "## 都道府県・市区町村情報のTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004e3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'Prefecture name_te', 'City/town/village name_te'\n",
    "adress_cols = ['Prefecture name', 'City/town/village name']\n",
    "\n",
    "global_mean = train_df_fe[target_col].mean()\n",
    "\n",
    "for col in adress_cols:\n",
    "    # Step1: train でカテゴリごとの平均を計算\n",
    "    mapping = train_df_fe.groupby(col)[target_col].mean()\n",
    "\n",
    "    # Step2: train に map を適用\n",
    "    train_df_fe[col + '_te'] = np.log1p(train_df_fe[col].map(mapping))\n",
    "\n",
    "    # Step3: test にも map を適用（未知カテゴリは global_mean）\n",
    "    test_df_fe[col + '_te'] = np.log1p(test_df_fe[col].map(mapping).fillna(global_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3279abb9",
   "metadata": {},
   "source": [
    "## 面積比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1764bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'area_ratio'\n",
    "train_df_fe['area_ratio'] = train_df_fe['senyu_area'] / train_df_fe['kukaku_area']\n",
    "test_df_fe['area_ratio'] = test_df_fe['senyu_area'] / test_df_fe['kukaku_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235525f",
   "metadata": {},
   "source": [
    "## 相対階数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a608aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'relative_floor'\n",
    "train_df_fe['relative_floor'] = train_df_fe['room_floor'] / train_df_fe['floor_count']\n",
    "test_df_fe['relative_floor']  = test_df_fe['room_floor'] / test_df_fe['floor_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da822b0",
   "metadata": {},
   "source": [
    "## 密度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19fd3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'unit_land_density', 'area_per_room'\n",
    "for df in [train_df_fe, test_df_fe]:\n",
    "    # 2) 敷地あたり専有面積密度: 専有面積 / 区画面積\n",
    "    df['unit_land_density'] = df['senyu_area'] / df['kukaku_area']\n",
    "    df.loc[df['kukaku_area'] <= 0, 'unit_land_density'] = np.nan\n",
    "\n",
    "    # 3) 面積 / 部屋数: 1部屋あたり専有面積\n",
    "    df['area_per_room'] = df['senyu_area'] / df['madori_number_all']\n",
    "    df.loc[df['madori_number_all'] <= 0, 'area_per_room'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a780e",
   "metadata": {},
   "source": [
    "## 豪邸検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c25945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'land_building_ratio'\n",
    "for df in [train_df_fe, test_df_fe]:\n",
    "    df['land_building_ratio'] = df['kukaku_area'] / df['nobeyuka_area']\n",
    "    df.loc[df['nobeyuka_area'] <= 0, 'land_building_ratio'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3867a5",
   "metadata": {},
   "source": [
    "## 面積と築年の交互作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ed9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'senyu_area_x_built_diff', 'area_per_room_x_built_diff'\n",
    "for df in [train_df_fe, test_df_fe]:\n",
    "    # 2) 専有面積 × 築年数\n",
    "    df['senyu_area_x_built_diff'] = df['senyu_area'] * df['built_diff']\n",
    "\n",
    "    # 3) 1部屋あたり面積 × 築年数\n",
    "    #   → 同じ築年数でも「広くてゆとりのある間取り」のプレミアムを表現\n",
    "    df['area_per_room_x_built_diff'] = df['area_per_room'] * df['built_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d3678",
   "metadata": {},
   "source": [
    "## building_idごとの統合特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffa45612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'building_senyu_area_median', 'building_room_floor_max', 'building_unit_count'\n",
    "len_train = len(train_df_fe)\n",
    "\n",
    "# --- train + test を結合 ---\n",
    "combined_df = pd.concat([train_df_fe, test_df_fe], ignore_index=True)\n",
    "\n",
    "# --- 1) building_id ごとの median(senyu_area) ---\n",
    "building_senyu_area_median = (\n",
    "    combined_df.groupby('building_id')['senyu_area']\n",
    "               .median()\n",
    "               .rename('building_senyu_area_median')\n",
    ")\n",
    "\n",
    "# --- 2) building_id ごとの max(room_floor) ---\n",
    "building_room_floor_max = (\n",
    "    combined_df.groupby('building_id')['room_floor']\n",
    "               .max()\n",
    "               .rename('building_room_floor_max')\n",
    ")\n",
    "\n",
    "# --- 3) building_id ごとの unit_count（件数） ---\n",
    "building_unit_count = (\n",
    "    combined_df.groupby('building_id')['unit_id']  # unit_id がなければ建物内 index をカウントでもOK\n",
    "               .count()\n",
    "               .rename('building_unit_count')\n",
    ")\n",
    "\n",
    "# --- まとめて結合 ---\n",
    "combined_df = combined_df.join(building_senyu_area_median, on='building_id')\n",
    "combined_df = combined_df.join(building_room_floor_max,   on='building_id')\n",
    "combined_df = combined_df.join(building_unit_count,       on='building_id')\n",
    "\n",
    "# --- 再び train / test に分割 ---\n",
    "train_df_fe = combined_df.iloc[:len_train].copy()  # 元の train 行数を使う\n",
    "test_df_fe  = combined_df.iloc[len_train:].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96db918",
   "metadata": {},
   "source": [
    "## 近傍価格特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13dbe58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def add_multi_radius_neighbor_features(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    target_col='money_room',\n",
    "    lat_col='lat',\n",
    "    lon_col='lon',\n",
    "    building_id_col='building_id',\n",
    "    building_category_col='building_category',\n",
    "    radius_list_m=[300, 500, 1000, 2000]\n",
    "):\n",
    "    \"\"\"\n",
    "    距離ごと（300m, 500m, 1km, 2km） × building_category別（house, mansion, all）\n",
    "    の近傍集計特徴量を追加する。\n",
    "\n",
    "    作る特徴量例：\n",
    "      - mean_price_300m, median_price_300m（実数）\n",
    "      - mean_price_300m_log, median_price_300m_log（log）\n",
    "      - std_price_300m, iqr_price_300m\n",
    "      - count_neighbors_300m\n",
    "\n",
    "      - mean_price_300m_house, mean_price_300m_house_log\n",
    "      - mean_price_300m_mansion, mean_price_300m_mansion_log\n",
    "      - …\n",
    "\n",
    "    注意：\n",
    "      test 側は train のみを近傍に使う。\n",
    "      train 側は「同じ building_id」は除外する。\n",
    "    \"\"\"\n",
    "\n",
    "    train_df = train_df.copy()\n",
    "    test_df  = test_df.copy()\n",
    "\n",
    "    # ------------------------------\n",
    "    # 基本セット\n",
    "    # ------------------------------\n",
    "    train_coords = np.radians(train_df[[lat_col, lon_col]].to_numpy())\n",
    "    test_coords  = np.radians(test_df[[lat_col, lon_col]].to_numpy())\n",
    "\n",
    "    y_train = train_df[target_col].to_numpy()\n",
    "    cats    = train_df[building_category_col].to_numpy()\n",
    "    bids    = train_df[building_id_col].to_numpy()\n",
    "\n",
    "    n_train = len(train_df)\n",
    "\n",
    "    tree = BallTree(train_coords, metric='haversine')\n",
    "    R = 6371.0\n",
    "\n",
    "    # global values\n",
    "    g_mean    = np.nanmean(y_train)\n",
    "    g_median  = np.nanmedian(y_train)\n",
    "    g_log_mean = np.log1p(g_mean)\n",
    "    g_log_median = np.log1p(g_median)\n",
    "    g_std     = np.nanstd(y_train)\n",
    "    g_iqr     = np.nanpercentile(y_train, 75) - np.nanpercentile(y_train, 25)\n",
    "\n",
    "    # category mask (高速化のため in advance)\n",
    "    mask_house   = (cats == 'house')\n",
    "    mask_mansion = (cats == 'mansion')\n",
    "\n",
    "    # =======================================================\n",
    "    # Train (高速化)\n",
    "    # =======================================================\n",
    "    for r in radius_list_m:\n",
    "\n",
    "        r_rad = (r / 1000) / R\n",
    "\n",
    "        # ★1回で全行の近傍 index を取得\n",
    "        neigh_list = tree.query_radius(train_coords, r=r_rad, return_distance=False)\n",
    "\n",
    "        # 出力用の NumPy 配列（非常に高速）\n",
    "        mean_all      = np.full(n_train, g_mean)\n",
    "        median_all    = np.full(n_train, g_median)\n",
    "        mean_log_all  = np.full(n_train, g_log_mean)\n",
    "        median_log_all= np.full(n_train, g_log_median)\n",
    "        std_all       = np.full(n_train, g_std)\n",
    "        iqr_all       = np.full(n_train, g_iqr)\n",
    "        cnt_all       = np.zeros(n_train, dtype=int)\n",
    "\n",
    "        # category\n",
    "        mean_house = np.full(n_train, g_mean)\n",
    "        mean_mansion = np.full(n_train, g_mean)\n",
    "        mean_house_log = np.full(n_train, g_log_mean)\n",
    "        mean_mansion_log = np.full(n_train, g_log_mean)\n",
    "\n",
    "        cnt_house = np.zeros(n_train, dtype=int)\n",
    "        cnt_mansion = np.zeros(n_train, dtype=int)\n",
    "\n",
    "        # ★ Python ループは「train 行数分」の1回だけ\n",
    "        for i, neigh_idx in enumerate(neigh_list):\n",
    "\n",
    "            neigh_idx = neigh_idx[bids[neigh_idx] != bids[i]]\n",
    "            if len(neigh_idx) == 0:\n",
    "                continue\n",
    "\n",
    "            prices = y_train[neigh_idx]\n",
    "\n",
    "            # all category\n",
    "            m = prices.mean()\n",
    "            md = np.median(prices)\n",
    "            mean_all[i] = m\n",
    "            median_all[i] = md\n",
    "            mean_log_all[i] = np.log1p(m)\n",
    "            median_log_all[i] = np.log1p(md)\n",
    "            cnt_all[i] = len(neigh_idx)\n",
    "\n",
    "            if len(neigh_idx) > 1:\n",
    "                std_all[i] = prices.std()\n",
    "                q75, q25 = np.percentile(prices, [75, 25])\n",
    "                iqr_all[i] = q75 - q25\n",
    "\n",
    "            # category split\n",
    "            neigh_cat = cats[neigh_idx]\n",
    "\n",
    "            # house\n",
    "            idx_h = neigh_idx[neigh_cat == 'house']\n",
    "            if len(idx_h) > 0:\n",
    "                p = y_train[idx_h]\n",
    "                mean_house[i] = p.mean()\n",
    "                mean_house_log[i] = np.log1p(p.mean())\n",
    "                cnt_house[i] = len(idx_h)\n",
    "\n",
    "            # mansion\n",
    "            idx_m = neigh_idx[neigh_cat == 'mansion']\n",
    "            if len(idx_m) > 0:\n",
    "                p = y_train[idx_m]\n",
    "                mean_mansion[i] = p.mean()\n",
    "                mean_mansion_log[i] = np.log1p(p.mean())\n",
    "                cnt_mansion[i] = len(idx_m)\n",
    "\n",
    "        # ★ 一括で DataFrame に代入（高速）\n",
    "        train_df[f'mean_price_{r}m'] = mean_all\n",
    "        train_df[f'median_price_{r}m'] = median_all\n",
    "        train_df[f'mean_price_{r}m_log'] = mean_log_all\n",
    "        train_df[f'median_price_{r}m_log'] = median_log_all\n",
    "        train_df[f'std_price_{r}m'] = std_all\n",
    "        train_df[f'iqr_price_{r}m'] = iqr_all\n",
    "        train_df[f'count_neighbors_{r}m'] = cnt_all\n",
    "\n",
    "        train_df[f'mean_price_{r}m_house'] = mean_house\n",
    "        train_df[f'mean_price_{r}m_house_log'] = mean_house_log\n",
    "        train_df[f'count_neighbors_{r}m_house'] = cnt_house\n",
    "\n",
    "        train_df[f'mean_price_{r}m_mansion'] = mean_mansion\n",
    "        train_df[f'mean_price_{r}m_mansion_log'] = mean_mansion_log\n",
    "        train_df[f'count_neighbors_{r}m_mansion'] = cnt_mansion\n",
    "\n",
    "    # =======================================================\n",
    "    # Test（train のみ近傍）\n",
    "    # =======================================================\n",
    "    for r in radius_list_m:\n",
    "\n",
    "        r_rad = (r / 1000) / R\n",
    "        neigh_list = tree.query_radius(test_coords, r=r_rad, return_distance=False)\n",
    "\n",
    "        n = len(test_df)\n",
    "\n",
    "        mean_all      = np.full(n, g_mean)\n",
    "        median_all    = np.full(n, g_median)\n",
    "        mean_log_all  = np.full(n, g_log_mean)\n",
    "        median_log_all= np.full(n, g_log_median)\n",
    "        std_all       = np.full(n, g_std)\n",
    "        iqr_all       = np.full(n, g_iqr)\n",
    "        cnt_all       = np.zeros(n, dtype=int)\n",
    "\n",
    "        mean_house = np.full(n, g_mean)\n",
    "        mean_mansion = np.full(n, g_mean)\n",
    "        mean_house_log = np.full(n, g_log_mean)\n",
    "        mean_mansion_log = np.full(n, g_log_mean)\n",
    "        cnt_house = np.zeros(n, dtype=int)\n",
    "        cnt_mansion = np.zeros(n, dtype=int)\n",
    "\n",
    "        for i, neigh_idx in enumerate(neigh_list):\n",
    "            if len(neigh_idx) == 0:\n",
    "                continue\n",
    "\n",
    "            prices = y_train[neigh_idx]\n",
    "            cats_sub = cats[neigh_idx]\n",
    "\n",
    "            m = prices.mean()\n",
    "            md = np.median(prices)\n",
    "\n",
    "            mean_all[i] = m\n",
    "            median_all[i] = md\n",
    "            mean_log_all[i] = np.log1p(m)\n",
    "            median_log_all[i] = np.log1p(md)\n",
    "            cnt_all[i] = len(neigh_idx)\n",
    "\n",
    "            if len(neigh_idx) > 1:\n",
    "                std_all[i] = prices.std()\n",
    "                q75, q25 = np.percentile(prices, [75, 25])\n",
    "                iqr_all[i] = q75 - q25\n",
    "\n",
    "            # category\n",
    "            mask_h = cats_sub == 'house'\n",
    "            if mask_h.sum() > 0:\n",
    "                p = prices[mask_h]\n",
    "                mean_house[i] = p.mean()\n",
    "                mean_house_log[i] = np.log1p(p.mean())\n",
    "                cnt_house[i] = mask_h.sum()\n",
    "\n",
    "            mask_m = cats_sub == 'mansion'\n",
    "            if mask_m.sum() > 0:\n",
    "                p = prices[mask_m]\n",
    "                mean_mansion[i] = p.mean()\n",
    "                mean_mansion_log[i] = np.log1p(p.mean())\n",
    "                cnt_mansion[i] = mask_m.sum()\n",
    "\n",
    "        # 一括代入\n",
    "        test_df[f'mean_price_{r}m'] = mean_all\n",
    "        test_df[f'median_price_{r}m'] = median_all\n",
    "        test_df[f'mean_price_{r}m_log'] = mean_log_all\n",
    "        test_df[f'median_price_{r}m_log'] = median_log_all\n",
    "        test_df[f'std_price_{r}m'] = std_all\n",
    "        test_df[f'iqr_price_{r}m'] = iqr_all\n",
    "        test_df[f'count_neighbors_{r}m'] = cnt_all\n",
    "\n",
    "        test_df[f'mean_price_{r}m_house'] = mean_house\n",
    "        test_df[f'mean_price_{r}m_house_log'] = mean_house_log\n",
    "        test_df[f'count_neighbors_{r}m_house'] = cnt_house\n",
    "\n",
    "        test_df[f'mean_price_{r}m_mansion'] = mean_mansion\n",
    "        test_df[f'mean_price_{r}m_mansion_log'] = mean_mansion_log\n",
    "        test_df[f'count_neighbors_{r}m_mansion'] = cnt_mansion\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ce5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_multi_radius_neighbor_features(\n",
    "    train_df_fe,\n",
    "    test_df_fe,\n",
    "    target_col='money_room',\n",
    "    lat_col='lat',\n",
    "    lon_col='lon',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f095335",
   "metadata": {},
   "source": [
    "## 市区町村ごとの緯度・経度の中心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37b719fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成される特徴量：'city_lat', 'city_lon'\n",
    "city_col = 'City/town/village name'\n",
    "\n",
    "# --- ① train + test を結合 ---\n",
    "combined_df = pd.concat([train_df_fe, test_df_fe], axis=0, ignore_index=True)\n",
    "\n",
    "combined_df['lat'] = combined_df['lat'].astype(float)\n",
    "combined_df['lon'] = combined_df['lon'].astype(float)\n",
    "\n",
    "# --- ② 市区町村ごとの lat / lon の中央値 ---\n",
    "city_lat_median = combined_df.groupby(city_col)['lat'].median()\n",
    "city_lon_median = combined_df.groupby(city_col)['lon'].median()\n",
    "\n",
    "# --- ③ 各レコードに city_lat / city_lon を付与 ---\n",
    "combined_df['city_lat'] = combined_df[city_col].map(city_lat_median)\n",
    "combined_df['city_lon'] = combined_df[city_col].map(city_lon_median)\n",
    "\n",
    "# 型を float に統一\n",
    "combined_df['city_lat'] = combined_df['city_lat'].astype('float')\n",
    "combined_df['city_lon'] = combined_df['city_lon'].astype('float')\n",
    "\n",
    "# --- ④ NaN を全体の中央値で埋める ---\n",
    "combined_df['city_lat'] = combined_df['city_lat'].fillna(combined_df['lat'].median())\n",
    "combined_df['city_lon'] = combined_df['city_lon'].fillna(combined_df['lon'].median())\n",
    "\n",
    "# --- ⑤ 再分割 ---\n",
    "train_df_fe = combined_df.iloc[:len(train_df_fe)].copy()\n",
    "test_df_fe  = combined_df.iloc[len(train_df_fe):].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d803f",
   "metadata": {},
   "source": [
    "## タグ情報のPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0b8fd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== land_price PCA Explained Variance (n_components=1) ===\n",
      "PC1: 0.9536,  Cumulative: 0.9536\n",
      "========================================\n",
      "\n",
      "\n",
      "=== building_struct PCA Explained Variance (n_components=3) ===\n",
      "PC1: 0.3215,  Cumulative: 0.3215\n",
      "PC2: 0.1049,  Cumulative: 0.4264\n",
      "PC3: 0.0547,  Cumulative: 0.4811\n",
      "========================================\n",
      "\n",
      "\n",
      "=== infra PCA Explained Variance (n_components=3) ===\n",
      "PC1: 0.4508,  Cumulative: 0.4508\n",
      "PC2: 0.1842,  Cumulative: 0.6350\n",
      "PC3: 0.1323,  Cumulative: 0.7673\n",
      "========================================\n",
      "\n",
      "\n",
      "=== location_premium PCA Explained Variance (n_components=1) ===\n",
      "PC1: 0.9414,  Cumulative: 0.9414\n",
      "========================================\n",
      "\n",
      "\n",
      "=== environment PCA Explained Variance (n_components=2) ===\n",
      "PC1: 0.6547,  Cumulative: 0.6547\n",
      "PC2: 0.0933,  Cumulative: 0.7480\n",
      "========================================\n",
      "\n",
      "\n",
      "=== senyu PCA Explained Variance (n_components=5) ===\n",
      "PC1: 0.3034,  Cumulative: 0.3034\n",
      "PC2: 0.0859,  Cumulative: 0.3893\n",
      "PC3: 0.0522,  Cumulative: 0.4415\n",
      "PC4: 0.0413,  Cumulative: 0.4828\n",
      "PC5: 0.0365,  Cumulative: 0.5193\n",
      "========================================\n",
      "\n",
      "[SKIP] sales_status: n_components <= 0 (not defined)\n",
      "\n",
      "=== certificate PCA Explained Variance (n_components=3) ===\n",
      "PC1: 0.3726,  Cumulative: 0.3726\n",
      "PC2: 0.1411,  Cumulative: 0.5137\n",
      "PC3: 0.0927,  Cumulative: 0.6064\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- 1) combined_df を作成 ---\n",
    "combined_df = pd.concat([train_df_fe, test_df_fe], ignore_index=True)\n",
    "\n",
    "# --- 2) タグ列グループ（新カテゴリごと） ---\n",
    "tag_groups = {\n",
    "    # 土地まわりのタグ\n",
    "    'land_price': [\n",
    "        c for c in combined_df.columns\n",
    "        if c.startswith('土地価格_')\n",
    "    ],\n",
    "\n",
    "    # 建物性能・構造\n",
    "    'building_struct': [\n",
    "        c for c in combined_df.columns\n",
    "        if c.startswith('建物構造・性能_')\n",
    "    ],\n",
    "\n",
    "    # 建物の給排水・インフラ設備\n",
    "    'infra': [\n",
    "        c for c in combined_df.columns\n",
    "        if c.startswith('建物設備（給排水・インフラ）_')\n",
    "    ],\n",
    "\n",
    "    # 立地プレミアム（タグ由来のもの）\n",
    "    'location_premium': [\n",
    "        c for c in combined_df.columns\n",
    "        if c.startswith('立地プレミアム_')\n",
    "    ],\n",
    "\n",
    "    # 環境プレミアム（タグ由来のもの）\n",
    "    'environment': [\n",
    "        c for c in combined_df.columns\n",
    "        if c.startswith('環境プレミアム_')\n",
    "    ],\n",
    "\n",
    "    # 専有部分設備\n",
    "    'senyu': [\n",
    "        c for c in combined_df.columns\n",
    "        if c.startswith('専有部分設備')\n",
    "    ],\n",
    "\n",
    "    # 用途・投資セグメント\n",
    "    'sales_status': [\n",
    "        c for c in combined_df.columns\n",
    "        if c.startswith('用途・投資セグメント_売買ステータス_')\n",
    "    ],\n",
    "    'certificate': [\n",
    "        c for c in combined_df.columns\n",
    "        if c.startswith('用途・投資セグメント_不動産の証明書・性能評価_')\n",
    "    ],\n",
    "}\n",
    "\n",
    "# --- 2.5) グループごとの PCA 次元数（推奨値） ---\n",
    "pca_dims = {\n",
    "    'land_price': 1,          # 土地価格系タグは少数なので 1〜2\n",
    "    'building_struct': 3,     # 構造・性能\n",
    "    'infra': 3,               # 給排水・インフラ\n",
    "    'location_premium': 1,    # 立地プレミアムタグは情報量少なめ\n",
    "    'environment': 2,         # 環境系タグ\n",
    "    'senyu': 5,                # 浴室・洗面\n",
    "    'certificate': 3,         # 証明書・評価系\n",
    "}\n",
    "\n",
    "# --- 3) PCA + 累積寄与率を計算する関数 ---\n",
    "def add_pca_features_and_report(df, cols, prefix, n_components):\n",
    "    if len(cols) == 0:\n",
    "        print(f'[SKIP] {prefix}: No columns')\n",
    "        return df\n",
    "\n",
    "    # 列数より多い成分数は指定できないので調整しておく\n",
    "    n_components = min(n_components, len(cols))\n",
    "    if n_components <= 0:\n",
    "        print(f'[SKIP] {prefix}: n_components <= 0 after adjustment')\n",
    "        return df\n",
    "\n",
    "    X = df[cols].fillna(0).astype(float)\n",
    "\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    pca_features = pca.fit_transform(X)\n",
    "\n",
    "    # 新しい PCA 列を追加\n",
    "    for i in range(n_components):\n",
    "        df[f'{prefix}_pca_{i+1}'] = pca_features[:, i]\n",
    "\n",
    "    # 累積寄与率を計算\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    cum_explained = explained.cumsum()\n",
    "\n",
    "    # 表示\n",
    "    print(f'\\n=== {prefix} PCA Explained Variance (n_components={n_components}) ===')\n",
    "    for i, (e, c) in enumerate(zip(explained, cum_explained), start=1):\n",
    "        print(f'PC{i}: {e:.4f},  Cumulative: {c:.4f}')\n",
    "    print('========================================\\n')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 4) 各グループに対して PCA + 累積寄与率を表示 ---\n",
    "for prefix, cols in tag_groups.items():\n",
    "    n_comp = pca_dims.get(prefix, 0)\n",
    "    if n_comp <= 0:\n",
    "        print(f'[SKIP] {prefix}: n_components <= 0 (not defined)')\n",
    "        continue\n",
    "\n",
    "    combined_df = add_pca_features_and_report(\n",
    "        combined_df,\n",
    "        cols,\n",
    "        prefix,\n",
    "        n_components=n_comp\n",
    "    )\n",
    "\n",
    "# --- 5) train/test に戻す ---\n",
    "train_len = len(train_df_fe)\n",
    "train_df_fe = combined_df.iloc[:train_len].copy()\n",
    "test_df_fe  = combined_df.iloc[train_len:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f2357",
   "metadata": {},
   "source": [
    "## 交通情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaae259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_access_zone_features(df, far_thresh=5000, error_thresh=20000, walk_speed=80):\n",
    "    \"\"\"\n",
    "    交通系FEをまとめて付与する関数\n",
    "\n",
    "    作成する特徴量:\n",
    "      - access_zone           : 'walk', 'bus', 'car', 'error', 'unknown'\n",
    "      - door_to_station_min   : 駅までの実質アクセス時間（徒歩 + バス）\n",
    "      - door_to_station_min_log\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 元の距離を退避\n",
    "    df['walk_distance1_raw'] = df['walk_distance1']\n",
    "\n",
    "    # 基本フラグ\n",
    "    has_eki           = df['eki_name1'].notnull()\n",
    "    has_bus_stop      = df['bus_stop1'].notnull()\n",
    "    has_bus_time      = df['bus_time1'].notnull()\n",
    "    has_traffic_other = df['traffic_other'].notnull()\n",
    "\n",
    "    # =========================\n",
    "    # 1) access_zone の分類\n",
    "    # =========================\n",
    "    df['access_zone'] = 'unknown'\n",
    "\n",
    "    # 徒歩圏：駅あり & バス停なし\n",
    "    mask_walk = has_eki & ~has_bus_stop\n",
    "    df.loc[mask_walk, 'access_zone'] = 'walk'\n",
    "\n",
    "    # バス圏：バス停あり（駅あり/なしどちらも）\n",
    "    mask_bus = has_bus_stop\n",
    "    df.loc[mask_bus, 'access_zone'] = 'bus'\n",
    "\n",
    "    # 自動車圏候補：「駅までめっちゃ遠い」ケース\n",
    "    very_far = df['walk_distance1_raw'] >= far_thresh\n",
    "\n",
    "    # 1) traffic_other にコメントあり → 自動車圏\n",
    "    mask_car1 = very_far & has_traffic_other\n",
    "\n",
    "    # 2) 駅までの徒歩距離が far_thresh〜error_thresh 未満 → 自動車圏\n",
    "    mask_car2 = very_far & (df['walk_distance1_raw'] < error_thresh)\n",
    "\n",
    "    mask_car = mask_car1 | mask_car2\n",
    "\n",
    "    # walk / bus / unknown のうち、car 条件を満たすものを上書き\n",
    "    df.loc[mask_car, 'access_zone'] = 'car'\n",
    "\n",
    "    # 20,000m 以上は入力ミス疑い(駅の位置情報取れれば直接計算もできるが、、)\n",
    "    mask_error = df['walk_distance1_raw'] >= error_thresh\n",
    "    df.loc[mask_error, 'access_zone'] = 'error'\n",
    "\n",
    "    # カテゴリ化\n",
    "    df['access_zone'] = df['access_zone'].astype('category')\n",
    "\n",
    "    # =========================\n",
    "    # 2) 駅までの実質アクセス時間\n",
    "    #    (door_to_station_min)\n",
    "    # =========================\n",
    "    # 自宅→徒歩時間（分）\n",
    "    walk_min1 = df['walk_distance1_raw'] / walk_speed\n",
    "\n",
    "    # 初期化\n",
    "    df['door_to_station_min'] = np.nan\n",
    "\n",
    "    # パターンA：駅あり + バス停あり + バス時間あり（徒歩＋バス）\n",
    "    mask_A = has_eki & has_bus_stop & has_bus_time\n",
    "    df.loc[mask_A, 'door_to_station_min'] = (\n",
    "        walk_min1[mask_A] + df.loc[mask_A, 'bus_time1']\n",
    "    )\n",
    "\n",
    "    # パターンB：駅のみ → 徒歩のみ\n",
    "    mask_B = has_eki & ~has_bus_stop\n",
    "    df.loc[mask_B, 'door_to_station_min'] = walk_min1[mask_B]\n",
    "\n",
    "    # パターンC（駅なし＋バスのみ）は NaN のまま\n",
    "    # → bus_only_flag などで別途対処可能\n",
    "\n",
    "    # 非線形吸収用ログ特徴量\n",
    "    df['door_to_station_min_log'] = np.log1p(df['door_to_station_min'])\n",
    "\n",
    "    bins = [-1, 300, 700, 1500, 5000]\n",
    "    labels = ['0-300', '300-700', '700-1500', '1500-5000']\n",
    "  \n",
    "    df['walk_distance_bin'] = pd.cut(\n",
    "        df['walk_distance1_raw'],\n",
    "        bins=bins,\n",
    "        labels=labels\n",
    "    ).astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df_fe = add_access_zone_features(train_df_fe)\n",
    "test_df_fe  = add_access_zone_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958f6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_te_cols = ['eki_name1', 'eki_name2', 'rosen_name1', 'rosen_name2']\n",
    "\n",
    "global_mean = train_df_fe[target_col].mean()\n",
    "\n",
    "for col in traffic_te_cols:\n",
    "    mapping = train_df_fe.groupby(col)[target_col].mean()\n",
    "\n",
    "    train_df_fe[col + '_te'] = np.log1p(train_df_fe[col].map(mapping))\n",
    "    test_df_fe[col + '_te']  = np.log1p(test_df_fe[col].map(mapping).fillna(global_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a2978",
   "metadata": {},
   "source": [
    "## 建物情報の拡充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "315a9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_building_area_features(df):\n",
    "    \"\"\"\n",
    "    建物規模系の追加特徴量を作成する\n",
    "    - density_floor_area\n",
    "    - unit_count_density\n",
    "    - unit_area_range\n",
    "    - empty_ratio\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ================\n",
    "    # 1) 延床面積密度\n",
    "    # ================\n",
    "    df['density_floor_area'] = df['nobeyuka_area'] / df['tochi_area']\n",
    "    \n",
    "    # ================\n",
    "    # 2) 総戸数密度\n",
    "    # ================\n",
    "    df['unit_count_density'] = df['unit_count'] / df['tochi_area']\n",
    "\n",
    "    # ================\n",
    "    # 3) 専有面積の範囲（max-min）\n",
    "    # ================\n",
    "    df['unit_area_range'] = df['unit_area_max'] - df['unit_area_min']\n",
    "\n",
    "    # ================\n",
    "    # 4) 空室率\n",
    "    #    unit_count = 0 のケースは NaN にする\n",
    "    # ================\n",
    "    df['empty_ratio'] = df['empty_number'] / df['unit_count']\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df_fe = add_building_area_features(train_df_fe)\n",
    "test_df_fe  = add_building_area_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1719bd0",
   "metadata": {},
   "source": [
    "## リフォーム・リノベ情報の拡充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b83100ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_effective_age(df, train_year, train_month):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) 日付を datetime に\n",
    "    date_cols = ['reform_interior_date', 'reform_wet_area_date',\n",
    "                 'reform_exterior_date', 'renovation_date']\n",
    "\n",
    "    df[date_cols] = df[date_cols].apply(lambda col: pd.to_datetime(col, errors='coerce'))\n",
    "\n",
    "    # 2) YYYYMM 整数化（datetime → int）\n",
    "    for c in date_cols:\n",
    "        df[c + '_ym'] = df[c].dt.year * 100 + df[c].dt.month\n",
    "\n",
    "    # 部分リフォームのみ\n",
    "    reform_cols_ym = ['reform_interior_date_ym', 'reform_wet_area_date_ym', 'reform_exterior_date_ym']\n",
    "\n",
    "    df['first_reform_yearmonth'] = df[reform_cols_ym].min(axis=1)\n",
    "\n",
    "    # フルリノベ判定\n",
    "    reform_flag_cols = df.filter(regex=r'^reform_(exterior|wet_area|interior)').columns\n",
    "    reform_count = df[reform_flag_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).sum(axis=1)\n",
    "\n",
    "    is_full_reno = df['renovation_date'].notnull() | (reform_count >= 5)\n",
    "\n",
    "    # effective_build_year\n",
    "    df['reno_year'] = df['renovation_date'].dt.year\n",
    "    df['effective_build_year'] = np.where(\n",
    "        is_full_reno & df['renovation_date'].notnull(),\n",
    "        df['reno_year'],\n",
    "        df['year_built']\n",
    "    )\n",
    "\n",
    "    # effective_age\n",
    "    df['effective_age'] = train_year - df['effective_build_year']\n",
    "\n",
    "    # ================\n",
    "    # リノベ後のリフォームだけ discount する\n",
    "    # ================\n",
    "    def calc_discount(row):\n",
    "        reno_ym = row['renovation_date_ym'] if pd.notnull(row['renovation_date_ym']) else None\n",
    "        discount = 0\n",
    "\n",
    "        # interior\n",
    "        if pd.notnull(row['reform_interior_date_ym']):\n",
    "            if (reno_ym is None) or (row['reform_interior_date_ym'] > reno_ym):\n",
    "                discount += 2\n",
    "\n",
    "        # wet area\n",
    "        if pd.notnull(row['reform_wet_area_date_ym']):\n",
    "            if (reno_ym is None) or (row['reform_wet_area_date_ym'] > reno_ym):\n",
    "                discount += 3\n",
    "\n",
    "        # exterior\n",
    "        if pd.notnull(row['reform_exterior_date_ym']):\n",
    "            if (reno_ym is None) or (row['reform_exterior_date_ym'] > reno_ym):\n",
    "                discount += 1\n",
    "\n",
    "        return discount\n",
    "\n",
    "    df['discount'] = df.apply(calc_discount, axis=1)\n",
    "    df['effective_age'] = np.maximum(0, df['effective_age'] - df['discount'])\n",
    "\n",
    "    # ================\n",
    "    # reform_newness（経過月数）\n",
    "    # ================\n",
    "    ref_total_months = train_year * 12 + train_month\n",
    "\n",
    "    df['reform_newness'] = np.where(\n",
    "        df['first_reform_yearmonth'].notnull(),\n",
    "        ref_total_months - df['first_reform_yearmonth'] // 1,   # YYYYMM整数に対して計算\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df['reform_newness_log'] = np.log1p(df['reform_newness'])\n",
    "    df['reform_total_count'] = reform_count\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fa12d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例：target_ym の最大値から基準年・月を決める\n",
    "train_max_ym = train_df_fe['target_ym'].max()  # 例: 202210\n",
    "train_year = train_max_ym // 100            # → 2022\n",
    "train_month = train_max_ym % 100            # → 10\n",
    "\n",
    "train_df_fe = add_effective_age(train_df_fe, train_year, train_month)\n",
    "test_df_fe  = add_effective_age(test_df_fe, train_year, train_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748bbbf7",
   "metadata": {},
   "source": [
    "## 掲載期間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e005cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する特徴量：'listing_months'\n",
    "def calculate_listing_months(df):\n",
    "\n",
    "    # 1) building_create_date を datetime へ（すでに datetime の場合はスキップ）\n",
    "    df['building_create_date'] = pd.to_datetime(df['building_create_date'], errors='coerce')\n",
    "\n",
    "    # 2) target_ym (例: 201901 → 2019-01-01) を datetime に変換\n",
    "    df['target_ym_date'] = pd.to_datetime(df['target_ym'].astype(str), format='%Y%m', errors='coerce')\n",
    "\n",
    "    # 3) 年月のみを使った '月数' 変換\n",
    "    b_y = df['building_create_date'].dt.year\n",
    "    b_m = df['building_create_date'].dt.month\n",
    "    t_y = df['target_ym_date'].dt.year\n",
    "    t_m = df['target_ym_date'].dt.month\n",
    "\n",
    "    # 4) 掲載期間（何ヶ月経っているか）を計算\n",
    "    df['listing_months'] = (t_y - b_y) * 12 + (t_m - b_m)\n",
    "\n",
    "    # 5) マイナス値はおかしいので NaN にする\n",
    "    df.loc[df['listing_months'] < 0, 'listing_months'] = pd.NA\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df_fe = calculate_listing_months(train_df_fe)\n",
    "test_df_fe  = calculate_listing_months(test_df_fe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf84bf1",
   "metadata": {},
   "source": [
    "## 地価の比率・平均値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd7d6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する特徴量：'ratio_mean_land', 'ratio_weighted_land'\n",
    "def add_land_price_ratios(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # 分母が 0 or NaN のときは NaN にするマスク\n",
    "    mask_mean = (df['nearest_land_price'] > 0) & df['mean_price_1000m'].notna()\n",
    "    mask_weighted = (df['weighted_land_price_3'] > 0) & df['median_price_1000m'].notna()\n",
    "\n",
    "    df['ratio_mean_land'] = np.nan\n",
    "    df.loc[mask_mean, 'ratio_mean_land'] = (\n",
    "        df.loc[mask_mean, 'mean_price_1000m'] / df.loc[mask_mean, 'nearest_land_price']\n",
    "    )\n",
    "\n",
    "    df['ratio_weighted_land'] = np.nan\n",
    "    df.loc[mask_weighted, 'ratio_weighted_land'] = (\n",
    "        df.loc[mask_weighted, 'median_price_1000m'] / df.loc[mask_weighted, 'weighted_land_price_3']\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df_fe = add_land_price_ratios(train_df_fe)\n",
    "test_df_fe  = add_land_price_ratios(test_df_fe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6fbae",
   "metadata": {},
   "source": [
    "## 未整理FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41514dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する特徴量：'kyoueki_per_m2', 'shuuzen_per_m2', 'kyoueki_per_unit', 'shuuzen_per_unit', 'has_kyoueki', 'has_shuuzen', 'land_cheap_flag', 'land_expensive_flag', 'land_theoretical_price', 'land_theoretical_price_weighted', 'land_theoretical_price_within1km_mp',\n",
    "def add_block1_2_features(train_df_fe: pd.DataFrame,\n",
    "                          test_df_fe: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ① 共益費・修繕費まわりのFE\n",
    "    ② 地価ギャップまわりのFE\n",
    "    を train/test 両方に追加する。\n",
    "    \"\"\"\n",
    "    train = train_df_fe.copy()\n",
    "    test  = test_df_fe.copy()\n",
    "    \n",
    "    for df in (train, test):\n",
    "        # ======================\n",
    "        # ① 共益費・修繕費ブロック\n",
    "        # ======================\n",
    "        # 面積・戸数が無い行は NaN にしておく（LightGBM は NaN を自然に扱える）\n",
    "        house = df.get('senyu_area')\n",
    "        unit_cnt = df.get('unit_count')\n",
    "        \n",
    "        # 共益費・修繕積立の生値\n",
    "        kyoueki = df.get('money_kyoueki_std')\n",
    "        shuuzen = df.get('money_shuuzen')\n",
    "        \n",
    "        # 1) 面積あたり\n",
    "        if (house is not None) and (kyoueki is not None):\n",
    "            df['kyoueki_per_m2'] = np.where(\n",
    "                (house > 0) & np.isfinite(house),\n",
    "                kyoueki / house,\n",
    "                np.nan\n",
    "            )\n",
    "        if (house is not None) and (shuuzen is not None):\n",
    "            df['shuuzen_per_m2'] = np.where(\n",
    "                (house > 0) & np.isfinite(house),\n",
    "                shuuzen / house,\n",
    "                np.nan\n",
    "            )\n",
    "        \n",
    "        # 2) 戸数あたり\n",
    "        if (unit_cnt is not None) and (kyoueki is not None):\n",
    "            df['kyoueki_per_unit'] = np.where(\n",
    "                (unit_cnt > 0) & np.isfinite(unit_cnt),\n",
    "                kyoueki / unit_cnt,\n",
    "                np.nan\n",
    "            )\n",
    "        if (unit_cnt is not None) and (shuuzen is not None):\n",
    "            df['shuuzen_per_unit'] = np.where(\n",
    "                (unit_cnt > 0) & np.isfinite(unit_cnt),\n",
    "                shuuzen / unit_cnt,\n",
    "                np.nan\n",
    "            )\n",
    "        \n",
    "        # 3) 有無フラグ\n",
    "        if kyoueki is not None:\n",
    "            df['has_kyoueki'] = (kyoueki > 0).astype('Int8')\n",
    "        if shuuzen is not None:\n",
    "            df['has_shuuzen'] = (shuuzen > 0).astype('Int8')\n",
    "        \n",
    "        # ======================\n",
    "        # ② 地価ギャップブロック\n",
    "        # ======================\n",
    "        nearest_lp   = df.get('nearest_land_price')\n",
    "        weighted_lp  = df.get('weighted_land_price_3')\n",
    "        within1km_mp = df.get('mean_price_1000m')\n",
    "        \n",
    "        # 割安/割高フラグ（threshold は仮に 0.8 / 1.2）\n",
    "        if 'ratio_mean_land' in df.columns:\n",
    "            df['land_cheap_flag'] = (df['ratio_mean_land'] < 0.8).astype('Int8')\n",
    "            df['land_expensive_flag'] = (df['ratio_mean_land'] > 1.2).astype('Int8')\n",
    "        \n",
    "        # 理論土地価格（= 地価 × 土地面積）\n",
    "        land_area = df.get('kukaku_area')\n",
    "        if (land_area is not None) and (nearest_lp is not None):\n",
    "            df['land_theoretical_price'] = np.where(\n",
    "                (land_area > 0) & np.isfinite(land_area),\n",
    "                np.log1p(nearest_lp * land_area),\n",
    "                np.nan\n",
    "            )\n",
    "        if (land_area is not None) and (weighted_lp is not None):\n",
    "            df['land_theoretical_price_weighted'] = np.where(\n",
    "                (land_area > 0) & np.isfinite(land_area),\n",
    "                np.log1p(weighted_lp * land_area),\n",
    "                np.nan\n",
    "            )\n",
    "        if (land_area is not None) and (weighted_lp is not None):\n",
    "            df['land_theoretical_price_within1km_mp'] = np.where(\n",
    "                (land_area > 0) & np.isfinite(land_area),\n",
    "                np.log1p(within1km_mp * land_area),\n",
    "                np.nan\n",
    "            )\n",
    "    \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60cfe05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_block1_2_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11ac24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する特徴量：'parking_available', 'parking_on_site', 'parking_nearby_only', 'parking_distance_log', 'parking_money', 'parking_cost_ratio_clip_log',  'parking_cost_per_sqm_clip',\n",
    "def add_parking_features(train_df_fe: pd.DataFrame,\n",
    "                                  test_df_fe: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    駐車場まわり（有無・近さ・コスト比）\n",
    "      - parking_available, parking_on_site, parking_nearby_only\n",
    "      - parking_distance_log\n",
    "      - parking_cost_ratio, parking_cost_ratio_log\n",
    "      - parking_cost_per_sqm\n",
    "\n",
    "    を train/test 両方に付与する。\n",
    "    \"\"\"\n",
    "    combined = pd.concat([train_df_fe, test_df_fe], ignore_index=True)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4) 駐車場まわりの特徴量\n",
    "    # ---------------------------\n",
    "    pk = combined.get('parking_kubun', pd.Series(np.nan, index=combined.index))\n",
    "\n",
    "    # 1:空有, 3:近隣, 5:有 → 駐車場あり\n",
    "    combined['parking_available'] = pk.isin([1, 3, 5]).astype(int)\n",
    "\n",
    "    # 敷地内あり（1:空有, 5:有）\n",
    "    combined['parking_on_site'] = pk.isin([1, 5]).astype(int)\n",
    "\n",
    "    # 近隣のみ（3）\n",
    "    combined['parking_nearby_only'] = (pk == 3).astype(int)\n",
    "\n",
    "    # 距離（log）\n",
    "    if 'parking_distance' in combined.columns:\n",
    "        dist = combined['parking_distance'].astype(float)\n",
    "        dist = dist.clip(lower=0)\n",
    "        combined['parking_distance_log'] = np.log1p(dist)\n",
    "    else:\n",
    "        combined['parking_distance_log'] = np.nan\n",
    "\n",
    "    # コスト比：駐車場料金 / 物件価格\n",
    "    parking_money = combined.get('parking_money_std', pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    money_room    = combined.get('money_room',    pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "\n",
    "    valid_cost = (parking_money > 0) & (money_room > 0)\n",
    "    parking_cost_ratio = np.where(valid_cost, parking_money / money_room, np.nan)\n",
    "    parking_cost_ratio = np.clip(parking_cost_ratio, 0, 0.1)  # 10% 以上はアウトライヤーとしてクリップ（お好み）\n",
    "\n",
    "    combined['parking_cost_ratio']      = parking_cost_ratio\n",
    "\n",
    "    # コスト / 専有面積（senyu_area 優先, なければ unit_area）\n",
    "    if 'senyu_area' in combined.columns:\n",
    "        area = combined['senyu_area'].astype(float)\n",
    "    else:\n",
    "        area = pd.Series(np.nan, index=combined.index)\n",
    "\n",
    "    valid_area = (parking_money > 0) & (area > 0)\n",
    "    parking_cost_per_sqm = np.where(valid_area, parking_money / area, np.nan)\n",
    "    parking_cost_per_sqm = np.clip(parking_cost_per_sqm, 0, np.nanpercentile(parking_cost_per_sqm[~np.isnan(parking_cost_per_sqm)], 99)\n",
    "                                  ) if np.any(valid_area) else parking_cost_per_sqm\n",
    "\n",
    "    combined['parking_cost_per_sqm'] = parking_cost_per_sqm\n",
    "\n",
    "    # ---------------------------\n",
    "    # 5) train/test に戻す\n",
    "    # ---------------------------\n",
    "    n_train = len(train_df_fe)\n",
    "    train_out = combined.iloc[:n_train].reset_index(drop=True)\n",
    "    test_out  = combined.iloc[n_train:].reset_index(drop=True)\n",
    "\n",
    "    return train_out, test_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0028ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_parking_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94010387",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['parking_cost_ratio', 'parking_cost_per_sqm', 'parking_money_std']:\n",
    "    x = train_df_fe[col]\n",
    "    # 上位1%でクリップ\n",
    "    hi = x.quantile(0.99)\n",
    "    train_df_fe[col + '_clip'] = x.clip(upper=hi)\n",
    "    test_df_fe[col + '_clip']  = test_df_fe[col].clip(upper=hi)\n",
    "\n",
    "# ratio 系は明示的に log バージョンだけ使うのもアリ\n",
    "train_df_fe['parking_cost_ratio_clip_log'] = np.log1p(train_df_fe['parking_cost_ratio_clip'])\n",
    "test_df_fe['parking_cost_ratio_clip_log']  = np.log1p(test_df_fe['parking_cost_ratio_clip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e3e33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する特徴量：'log_min_amenity_distance', 'convenience_distance_log', 'super_distance_log', 'drugstore_distance_log', 'amenity_within_500m', 'amenity_within_1000m',\n",
    "def add_life_convenience_features(\n",
    "    train_df_fe: pd.DataFrame,\n",
    "    test_df_fe: pd.DataFrame,\n",
    "    amenity_cols: list[str] | None = None,\n",
    "    thresholds: tuple[int, int] = (500, 1000),\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    生活利便距離の log & 最小距離 & 閾値フラグ を追加する。\n",
    "\n",
    "    - 各 amenity 距離について log 変換列 xxx_log を追加\n",
    "    - min_amenity_distance: 複数の生活利便距離の最小値\n",
    "    - log_min_amenity_distance: 上記の log1p\n",
    "    - amenity_within_500m, amenity_within_1000m: 閾値以下の便益フラグ\n",
    "    \"\"\"\n",
    "    combined = pd.concat([train_df_fe, test_df_fe], ignore_index=True)\n",
    "\n",
    "    # デフォルトの生活利便距離カラム\n",
    "    if amenity_cols is None:\n",
    "        amenity_cols = [\n",
    "            c for c in [\n",
    "                'convenience_distance',\n",
    "                'super_distance',\n",
    "                'hospital_distance',\n",
    "                'park_distance',\n",
    "                'drugstore_distance',\n",
    "                'bank_distance',\n",
    "                'shopping_street_distance',\n",
    "                'est_other_distance',\n",
    "            ]\n",
    "            if c in combined.columns\n",
    "        ]\n",
    "\n",
    "    # 何もなければそのまま返す\n",
    "    if len(amenity_cols) == 0:\n",
    "        print('[add_life_convenience_features] amenity_cols is empty. Skip.')\n",
    "        return train_df_fe, test_df_fe\n",
    "\n",
    "    # 各 amenity 距離の log 変換\n",
    "    for col in amenity_cols:\n",
    "        vals = combined[col].astype(float)\n",
    "        vals = vals.clip(lower=0)  # マイナスは 0 に丸める\n",
    "        combined[f'{col}_log'] = np.log1p(vals)\n",
    "\n",
    "    # 最小距離\n",
    "    amenity_dist = combined[amenity_cols].astype(float)\n",
    "    min_dist = amenity_dist.min(axis=1)\n",
    "\n",
    "    combined['min_amenity_distance'] = min_dist\n",
    "    combined['log_min_amenity_distance'] = np.log1p(min_dist.clip(lower=0))\n",
    "\n",
    "    # 閾値フラグ（例: 500m, 1000m）\n",
    "    th1, th2 = thresholds\n",
    "    combined[f'amenity_within_{th1}m'] = (min_dist <= th1).astype(int)\n",
    "    combined[f'amenity_within_{th2}m'] = (min_dist <= th2).astype(int)\n",
    "\n",
    "    # 分割して返す\n",
    "    n_train = len(train_df_fe)\n",
    "    train_out = combined.iloc[:n_train].reset_index(drop=True)\n",
    "    test_out  = combined.iloc[n_train:].reset_index(drop=True)\n",
    "\n",
    "    return train_out, test_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c27bafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_life_convenience_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a9ba997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する特徴量：'genkyo_flex_score', 'usable_status_score', 'usable_months_delay', 'has_management_association', 'management_form_score', 'manager_presence_score', 'management_total_score',\n",
    "def add_status_and_management_features(\n",
    "    train_df_fe: pd.DataFrame,\n",
    "    test_df_fe: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    現況(genkyo_code)、引渡し(usable_status, usable_date)、\n",
    "    管理状態(management_form, management_association_flg, house_kanrinin)\n",
    "    を再整理 & スコア化して特徴量追加。\n",
    "    \"\"\"\n",
    "\n",
    "    combined = pd.concat([train_df_fe, test_df_fe], ignore_index=True)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 1) 現況 (genkyo_code)\n",
    "    # ---------------------------\n",
    "    genkyo = combined.get('genkyo_code', pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "\n",
    "    # 自由度スコア\n",
    "    flex_map = {\n",
    "        1: 0.5,   # 居住中 or 更地（兼ねるので控えめ）\n",
    "        2: 1.5,   # 空家\n",
    "        3: 0.0,   # 賃貸中 → 自由度低い\n",
    "        4: 1.0,   # 未完成\n",
    "        10: 1.5,  # 古屋あり更地引渡可\n",
    "    }\n",
    "    combined['genkyo_flex_score'] = genkyo.map(flex_map).fillna(0.0)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 2) 引渡し (usable_status, usable_date)\n",
    "    # ---------------------------\n",
    "    usable_status = combined.get('usable_status', pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    usable_date   = combined.get('usable_date',   pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    target_ym     = combined.get('target_ym',     pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "\n",
    "    # フラグ\n",
    "    combined['usable_immediate_flag']   = (usable_status == 1).astype(int)\n",
    "    combined['usable_fixed_date_flag']  = (usable_status == 3).astype(int)\n",
    "\n",
    "    # スコア: 即時 > 期日指定 > 相談・未定\n",
    "    usable_score_map = {\n",
    "        1: 2.0,   # 即時\n",
    "        3: 1.0,   # 期日指定\n",
    "        2: 0.5,   # 相談\n",
    "        4: 0.0,   # 未定\n",
    "    }\n",
    "    combined['usable_status_score'] = usable_status.map(usable_score_map).fillna(0.0)\n",
    "\n",
    "    # yyyymm 同士の差分 → おおざっぱに「ヶ月差」とみなす\n",
    "    # 例: target_ym=202201, usable_date=202204 → 3 ヶ月\n",
    "    usable_months_delay = np.nan\n",
    "\n",
    "    if 'usable_date' in combined.columns and 'target_ym' in combined.columns:\n",
    "        # 年月を整数に分解\n",
    "        u = usable_date.copy()\n",
    "        t = target_ym.copy()\n",
    "\n",
    "        u_year  = (u // 100).astype('Int64')\n",
    "        u_month = (u % 100).astype('Int64')\n",
    "\n",
    "        t_year  = (t // 100).astype('Int64')\n",
    "        t_month = (t % 100).astype('Int64')\n",
    "\n",
    "        usable_months_delay = (u_year - t_year) * 12 + (u_month - t_month)\n",
    "\n",
    "    combined['usable_months_delay'] = usable_months_delay\n",
    "\n",
    "    # ---------------------------\n",
    "    # 3) 管理状態\n",
    "    # ---------------------------\n",
    "    management_form          = combined.get('management_form',          pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    management_association   = combined.get('management_association_flg', pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "    house_kanrinin           = combined.get('house_kanrinin',          pd.Series(np.nan, index=combined.index)).astype(float)\n",
    "\n",
    "    # 管理組合あり\n",
    "    combined['has_management_association'] = (management_association == 2).astype(int)\n",
    "\n",
    "    # プロ管理（委託あり）\n",
    "    combined['has_professional_management'] = management_form.isin([2, 3]).astype(int)\n",
    "\n",
    "    # 管理人あり\n",
    "    combined['has_manager'] = house_kanrinin.isin([1, 2, 3, 5]).astype(int)\n",
    "\n",
    "    # 管理形態スコア\n",
    "    management_form_score_map = {\n",
    "        1: 1.0,   # 自主管理\n",
    "        2: 2.0,   # 一部委託\n",
    "        3: 3.0,   # 全部委託\n",
    "    }\n",
    "    combined['management_form_score'] = management_form.map(management_form_score_map).fillna(0.0)\n",
    "\n",
    "    # 管理人スコア\n",
    "    manager_score_map = {\n",
    "        4: 0.0,   # 無\n",
    "        5: 0.5,   # 非常駐\n",
    "        3: 1.0,   # 巡回\n",
    "        2: 1.5,   # 日勤\n",
    "        1: 2.0,   # 常駐\n",
    "    }\n",
    "    combined['manager_presence_score'] = house_kanrinin.map(manager_score_map).fillna(0.0)\n",
    "\n",
    "    # 合計管理スコア\n",
    "    combined['management_total_score'] = (\n",
    "        combined['management_form_score']\n",
    "        + combined['manager_presence_score']\n",
    "        + combined['has_management_association'] * 0.5  # 管理組合ありに少し加点\n",
    "    )\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4) train/test に戻す\n",
    "    # ---------------------------\n",
    "    n_train = len(train_df_fe)\n",
    "    train_out = combined.iloc[:n_train].reset_index(drop=True)\n",
    "    test_out  = combined.iloc[n_train:].reset_index(drop=True)\n",
    "\n",
    "    return train_out, test_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5452a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe = add_status_and_management_features(train_df_fe, test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1470f",
   "metadata": {},
   "source": [
    "## 持分比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a8a8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mochibun_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 持分割合（欠損は 100% 所有とみなす）\n",
    "    df['mochibun_ratio'] = df['land_mochibun_b'] / df['land_mochibun_a']\n",
    "    df['mochibun_ratio'] = df['mochibun_ratio'].replace([np.inf, -np.inf], np.nan)\n",
    "    df['mochibun_ratio'] = df['mochibun_ratio'].fillna(1.0)\n",
    "\n",
    "    # フラグ\n",
    "    df['has_mochibun'] = (df['mochibun_ratio'] < 1.0).astype(int)\n",
    "\n",
    "    # 実効面積（土地面積が存在する場合のみ）\n",
    "    if 'land_area' in df.columns:\n",
    "        df['mochibun_area'] = df['land_area'] * df['mochibun_ratio']\n",
    "    else:\n",
    "        df['mochibun_area'] = np.nan\n",
    "\n",
    "    df['mochibun_area_log'] = np.log1p(df['mochibun_area'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7df17fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = make_mochibun_features(train_df_fe)\n",
    "test_df_fe = make_mochibun_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846b21",
   "metadata": {},
   "source": [
    "## 私道比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4549cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shidou_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 私道負担面積（欠損＝0）\n",
    "    df['shidou_area_eff'] = df['snapshot_land_shidou'].fillna(0)\n",
    "\n",
    "    # 私道負担割合（分子 / 分母）\n",
    "    df['land_shidou_ratio'] = (\n",
    "        df['land_shidou_b'] / df['land_shidou_a']\n",
    "    )\n",
    "    df['land_shidou_ratio'] = df['land_shidou_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    # フラグ\n",
    "    df['has_shidou'] = (df['shidou_area_eff'] > 0).astype(int)\n",
    "\n",
    "    # optional: 土地面積比率\n",
    "    if 'tochi_area' in df.columns:\n",
    "        df['shidou_area_ratio'] = df['shidou_area_eff'] / df['tochi_area']\n",
    "        df['shidou_area_ratio'] = df['shidou_area_ratio'].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "284fab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe = make_shidou_features(train_df_fe)\n",
    "test_df_fe = make_shidou_features(test_df_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630becf8",
   "metadata": {},
   "source": [
    "## 住みやすさスコア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9c39630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ルールベースタグ重み（20選 + 必須欠落ペナルティ）\n",
    "# =========================================================\n",
    "\n",
    "TAG_RULES = {\n",
    "    \"bonus\": {\n",
    "        # --- 環境・立地系 ---\n",
    "        \"環境プレミアム_コンビニ 400ｍ以内\": 2.0,\n",
    "        \"環境プレミアム_スーパー 800ｍ以内\": 3.0,\n",
    "        \"環境プレミアム_総合病院 800ｍ以内\": 2.0,\n",
    "        \"環境プレミアム_公園 400ｍ以内\": 1.5,\n",
    "        \"環境プレミアム_子育てに嬉しい環境\": 2.0,\n",
    "\n",
    "        # --- 建物構造・共用部 ---\n",
    "        \"建物構造・性能_オートロック\": 2.0,\n",
    "        \"建物構造・性能_宅配ボックス\": 2.5,\n",
    "        \"建物構造・性能_防犯カメラ\": 1.5,\n",
    "        \"建物構造・性能_エレベーター\": 1.0,\n",
    "        \"建物構造・性能_管理人常駐\": 1.5,\n",
    "        \"建物構造・性能_免震構造\": 2.0,\n",
    "        \"建物構造・性能_耐震・制震・免震構造\": 2.0,\n",
    "\n",
    "        # --- 専有部設備 ---\n",
    "        \"専有部分設備_浴室・洗面_浴室乾燥機\": 1.5,\n",
    "        \"専有部分設備_浴室・洗面_追焚機能\": 1.5,\n",
    "        \"専有部分設備_浴室・洗面_洗面所独立\": 1.0,\n",
    "        \"専有部分設備_キッチン_システムキッチン\": 1.5,\n",
    "        \"専有部分設備_キッチン_食器洗い乾燥機\": 1.5,\n",
    "        \"専有部分設備_収納_ウォークインクローゼット\": 1.5,\n",
    "        \"専有部分設備_収納_全居室収納\": 1.0,\n",
    "        \"専有部分設備_空調・暖房_床暖房\": 2.0,\n",
    "    },\n",
    "    \"penalty\": {\n",
    "        # --- 必須欠落（強い減点） ---\n",
    "        \"専有部分設備_トイレ_トイレなし\": -10.0,\n",
    "        \"専有部分設備_浴室・洗面_バスなし\": -10.0,\n",
    "        \"専有部分設備_トイレ_共同トイレ\": -5.0,\n",
    "        \"専有部分設備_浴室・洗面_共同バス\": -5.0,\n",
    "        \"建物設備（給排水・インフラ）_汲取\": -3.0,\n",
    "        \"建物設備（給排水・インフラ）_浄化槽\": -2.0,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def compute_tag_rule_score(df: pd.DataFrame, rules: dict = TAG_RULES) -> pd.Series:\n",
    "    \"\"\"\n",
    "    ルールベースタグスコア（加点 + 減点）を算出。\n",
    "    存在しない列は無視するので、そのまま使える。\n",
    "    \"\"\"\n",
    "    score = pd.Series(0.0, index=df.index)\n",
    "\n",
    "    for col, w in rules.get(\"bonus\", {}).items():\n",
    "        if col in df.columns:\n",
    "            score += df[col].fillna(0).astype(float) * float(w)\n",
    "\n",
    "    for col, w in rules.get(\"penalty\", {}).items():\n",
    "        if col in df.columns:\n",
    "            score += df[col].fillna(0).astype(float) * float(w)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ユーティリティ関数\n",
    "# =========================================================\n",
    "\n",
    "def _zscore(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"平均0・分散1に正規化（std=0 のときは 0 を返す）\"\"\"\n",
    "    s = series.astype(float)\n",
    "    std = s.std()\n",
    "    if std == 0 or np.isnan(std):\n",
    "        return pd.Series(0.0, index=s.index)\n",
    "    return (s - s.mean()) / std\n",
    "\n",
    "\n",
    "def _safe_mean(df: pd.DataFrame, cols: list[str]) -> pd.Series:\n",
    "    \"\"\"存在する列だけで行方向平均を取る（全て無ければ0）\"\"\"\n",
    "    cols_exist = [c for c in cols if c in df.columns]\n",
    "    if not cols_exist:\n",
    "        return pd.Series(0.0, index=df.index)\n",
    "    return df[cols_exist].mean(axis=1).fillna(0.0)\n",
    "\n",
    "\n",
    "def _add_tag_score(df: pd.DataFrame,\n",
    "                   prefixes: list[str],\n",
    "                   new_col: str) -> pd.DataFrame:\n",
    "    \"\"\"指定プレフィクスの One-hot 列の平均をスコア化して new_col に追加\"\"\"\n",
    "    cols = [c for c in df.columns\n",
    "            if any(c.startswith(p) for p in prefixes)]\n",
    "    if not cols:\n",
    "        df[new_col] = 0.0\n",
    "    else:\n",
    "        df[new_col] = df[cols].mean(axis=1).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ① 都市度スコアの作成\n",
    "# =========================================================\n",
    "\n",
    "def make_urban_score(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    urban_features: list[str] | None = None,\n",
    "    impute_strategy: str = \"median\",\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "\n",
    "    if urban_features is None:\n",
    "        candidate_cols = [\n",
    "            \"count_neighbors_1000m\",\n",
    "            \"door_to_station_min_log\",\n",
    "            \"tochi_area_log\",\n",
    "            \"shikichi_area_log\",\n",
    "        ]\n",
    "        urban_features = [c for c in candidate_cols if c in train_df.columns]\n",
    "\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    if not urban_features:\n",
    "        train_df[\"urban_score\"] = 0.0\n",
    "        test_df[\"urban_score\"] = 0.0\n",
    "        return train_df, test_df, {\"scaler\": None, \"pca\": None, \"urban_features\": []}\n",
    "\n",
    "    combined = pd.concat(\n",
    "        [train_df[urban_features], test_df[urban_features]],\n",
    "        axis=0, ignore_index=True\n",
    "    ).astype(float)\n",
    "\n",
    "    combined = combined.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    used_features = [c for c in combined.columns if combined[c].notna().any()]\n",
    "    combined = combined[used_features]\n",
    "\n",
    "    if not used_features:\n",
    "        train_df[\"urban_score\"] = 0.0\n",
    "        test_df[\"urban_score\"] = 0.0\n",
    "        return train_df, test_df, {\"scaler\": None, \"pca\": None, \"urban_features\": []}\n",
    "\n",
    "    if impute_strategy == \"median\":\n",
    "        fill_values = combined.median(numeric_only=True)\n",
    "    elif impute_strategy == \"mean\":\n",
    "        fill_values = combined.mean(numeric_only=True)\n",
    "    else:\n",
    "        raise ValueError(\"impute_strategy must be 'median' or 'mean'\")\n",
    "\n",
    "    combined_imputed = combined.fillna(fill_values)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    combined_scaled = scaler.fit_transform(combined_imputed)\n",
    "\n",
    "    pca = PCA(n_components=1, random_state=42)\n",
    "    urban_component = pca.fit_transform(combined_scaled).ravel()\n",
    "\n",
    "    n_train = len(train_df)\n",
    "    train_df[\"urban_score\"] = urban_component[:n_train]\n",
    "    test_df[\"urban_score\"] = urban_component[n_train:]\n",
    "\n",
    "    meta = {\n",
    "        \"scaler\": scaler,\n",
    "        \"pca\": pca,\n",
    "        \"urban_features\": used_features,\n",
    "        \"impute_values\": fill_values.to_dict(),\n",
    "    }\n",
    "    return train_df, test_df, meta\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ② タグ＋数値から住みやすさサブスコアを作成（ルールタグを追加）\n",
    "# =========================================================\n",
    "\n",
    "def make_livability_subscores(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    use_rule_tags: bool = True,\n",
    "    rule_weight_in_daily: float = 0.6,\n",
    "    rule_weight_in_building: float = 0.8,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    # ---------- タグ系スコア（平均） ----------\n",
    "    tag_groups = {\n",
    "        \"tag_land\": [\"土地価格_\"],\n",
    "        \"tag_unit\": [\"専有部分設備_\"],\n",
    "        \"tag_building\": [\"建物構造・性能_\"],\n",
    "        \"tag_infra\": [\"建物設備（給排水・インフラ）_\"],\n",
    "        \"tag_env\": [\"環境プレミアム_\"],\n",
    "        \"tag_cert\": [\"用途・投資セグメント_不動産の証明書・性能評価_\"],\n",
    "    }\n",
    "\n",
    "    for name, prefixes in tag_groups.items():\n",
    "        train_df = _add_tag_score(train_df, prefixes, f\"{name}_score\")\n",
    "        test_df = _add_tag_score(test_df, prefixes, f\"{name}_score\")\n",
    "\n",
    "    # ---------- ルールベースタグ（重み付き） ----------\n",
    "    if use_rule_tags:\n",
    "        train_df[\"tag_rule_score_raw\"] = compute_tag_rule_score(train_df)\n",
    "        test_df[\"tag_rule_score_raw\"] = compute_tag_rule_score(test_df)\n",
    "\n",
    "        # train 기준で z-score し、testにも同じスケールで適用（安定）\n",
    "        mu = train_df[\"tag_rule_score_raw\"].mean()\n",
    "        sd = train_df[\"tag_rule_score_raw\"].std()\n",
    "        if sd == 0 or np.isnan(sd):\n",
    "            train_df[\"tag_rule_score\"] = 0.0\n",
    "            test_df[\"tag_rule_score\"] = 0.0\n",
    "        else:\n",
    "            train_df[\"tag_rule_score\"] = (train_df[\"tag_rule_score_raw\"] - mu) / sd\n",
    "            test_df[\"tag_rule_score\"] = (test_df[\"tag_rule_score_raw\"] - mu) / sd\n",
    "    else:\n",
    "        train_df[\"tag_rule_score\"] = 0.0\n",
    "        test_df[\"tag_rule_score\"] = 0.0\n",
    "\n",
    "    # ---------- 数値系（駅近 / 密度 / 面積） ----------\n",
    "    for df in (train_df, test_df):\n",
    "        if \"door_to_station_min_log\" in df.columns:\n",
    "            df[\"access_station_score\"] = _zscore(-df[\"door_to_station_min_log\"].astype(float))\n",
    "        else:\n",
    "            df[\"access_station_score\"] = 0.0\n",
    "\n",
    "        if \"count_neighbors_1000m\" in df.columns:\n",
    "            df[\"neighbor_density_score\"] = _zscore(df[\"count_neighbors_1000m\"].astype(float))\n",
    "        else:\n",
    "            df[\"neighbor_density_score\"] = 0.0\n",
    "\n",
    "        numeric_area_cols = [\n",
    "            c for c in df.columns\n",
    "            if any(k in c for k in [\"senyu_area_log\", \"area_per_room\", \"nobeyuka_area_log\"])\n",
    "        ]\n",
    "        df[\"room_space_score\"] = _safe_mean(df, numeric_area_cols)\n",
    "        if df[\"room_space_score\"].std() > 0:\n",
    "            df[\"room_space_score\"] = _zscore(df[\"room_space_score\"])\n",
    "        else:\n",
    "            df[\"room_space_score\"] = 0.0\n",
    "\n",
    "    # ---------- 4つのサブスコア ----------\n",
    "    for df in (train_df, test_df):\n",
    "        df[\"score_access\"] = _safe_mean(df, [\n",
    "            \"access_station_score\",\n",
    "            \"neighbor_density_score\",\n",
    "            \"tag_env_score\",\n",
    "        ])\n",
    "\n",
    "        # 生活利便性（+ ルールタグの一部を足す）\n",
    "        df[\"score_daily\"] = _safe_mean(df, [\n",
    "            \"tag_env_score\",\n",
    "            \"tag_land_score\",\n",
    "        ]) + rule_weight_in_daily * df[\"tag_rule_score\"]\n",
    "\n",
    "        # 専有部快適性\n",
    "        df[\"score_room\"] = _safe_mean(df, [\n",
    "            \"tag_unit_score\",\n",
    "            \"room_space_score\",\n",
    "        ])\n",
    "\n",
    "        # 建物性能（+ ルールタグを強めに足す）\n",
    "        df[\"score_building\"] = _safe_mean(df, [\n",
    "            \"tag_building_score\",\n",
    "            \"tag_infra_score\",\n",
    "            \"tag_cert_score\",\n",
    "        ]) + rule_weight_in_building * df[\"tag_rule_score\"]\n",
    "\n",
    "    meta = {\n",
    "        \"tag_groups\": tag_groups,\n",
    "        \"subscores\": [\"score_access\", \"score_daily\", \"score_room\", \"score_building\"],\n",
    "        \"use_rule_tags\": use_rule_tags,\n",
    "        \"rule_weights\": {\n",
    "            \"daily\": rule_weight_in_daily,\n",
    "            \"building\": rule_weight_in_building\n",
    "        },\n",
    "        \"rule_tags_used\": {\n",
    "            \"bonus\": [k for k in TAG_RULES[\"bonus\"].keys() if k in train_df.columns],\n",
    "            \"penalty\": [k for k in TAG_RULES[\"penalty\"].keys() if k in train_df.columns],\n",
    "        }\n",
    "    }\n",
    "    return train_df, test_df, meta\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ③ 都市度 × サブスコアの重みを回帰で自動学習\n",
    "# =========================================================\n",
    "\n",
    "def fit_livability_weight_model(\n",
    "    train_df: pd.DataFrame,\n",
    "    target_col: str = \"money_room\",\n",
    "    alpha: float = 1.0,\n",
    ") -> tuple[Ridge, list[str]]:\n",
    "\n",
    "    required_cols = [\"urban_score\", \"score_access\", \"score_daily\", \"score_room\", \"score_building\"]\n",
    "    for c in required_cols + [target_col]:\n",
    "        if c not in train_df.columns:\n",
    "            raise KeyError(f\"必要な列が存在しません: {c}\")\n",
    "\n",
    "    df = train_df.dropna(subset=[target_col]).copy()\n",
    "    y = df[target_col].astype(float)\n",
    "\n",
    "    # 標準化ターゲット\n",
    "    y_std = (y - y.mean()) / y.std()\n",
    "\n",
    "    X_parts = []\n",
    "    feature_names = []\n",
    "\n",
    "    X_parts.append(df[required_cols].astype(float).values)\n",
    "    feature_names.extend(required_cols)\n",
    "\n",
    "    for col in [\"score_access\", \"score_daily\", \"score_room\", \"score_building\"]:\n",
    "        inter_name = f\"{col}_x_urban\"\n",
    "        X_parts.append((df[col] * df[\"urban_score\"]).values.reshape(-1, 1))\n",
    "        feature_names.append(inter_name)\n",
    "\n",
    "    X = np.hstack(X_parts)\n",
    "\n",
    "    model = Ridge(alpha=alpha, random_state=42)\n",
    "    model.fit(X, y_std)\n",
    "\n",
    "    return model, feature_names\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ④ 最終住みやすさスコアの算出（0〜100）\n",
    "# =========================================================\n",
    "\n",
    "def apply_livability_score(\n",
    "    df: pd.DataFrame,\n",
    "    model: Ridge,\n",
    "    feature_names: list[str],\n",
    "    train_min: float,\n",
    "    train_max: float,\n",
    ") -> pd.Series:\n",
    "\n",
    "    base_cols = [\"urban_score\", \"score_access\", \"score_daily\", \"score_room\", \"score_building\"]\n",
    "\n",
    "    X_parts = [df[base_cols].astype(float).values]\n",
    "    for col in [\"score_access\", \"score_daily\", \"score_room\", \"score_building\"]:\n",
    "        X_parts.append((df[col] * df[\"urban_score\"]).values.reshape(-1, 1))\n",
    "    X = np.hstack(X_parts)\n",
    "\n",
    "    liv_raw = model.predict(X)\n",
    "\n",
    "    if train_max == train_min:\n",
    "        return pd.Series(50.0, index=df.index)\n",
    "\n",
    "    liv_scaled = (liv_raw - train_min) / (train_max - train_min)\n",
    "    liv_scaled = liv_scaled.clip(0, 1) * 100.0\n",
    "    return pd.Series(liv_scaled, index=df.index)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# パイプライン一括実行\n",
    "# =========================================================\n",
    "\n",
    "def add_livability_features(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    target_col: str = \"money_room\",\n",
    "    alpha: float = 1.0,\n",
    "    use_rule_tags: bool = True,\n",
    "    rule_weight_in_daily: float = 0.6,\n",
    "    rule_weight_in_building: float = 0.8,\n",
    "):\n",
    "    \"\"\"\n",
    "    ① urban_score\n",
    "    ② subscores（ルールタグを加算）\n",
    "    ③ Ridgeで重み学習\n",
    "    ④ livability_score（0〜100）\n",
    "    \"\"\"\n",
    "\n",
    "    train_u, test_u, urban_meta = make_urban_score(train_df, test_df)\n",
    "\n",
    "    train_s, test_s, subs_meta = make_livability_subscores(\n",
    "        train_u, test_u,\n",
    "        use_rule_tags=use_rule_tags,\n",
    "        rule_weight_in_daily=rule_weight_in_daily,\n",
    "        rule_weight_in_building=rule_weight_in_building,\n",
    "    )\n",
    "\n",
    "    model, feature_names = fit_livability_weight_model(\n",
    "        train_s, target_col=target_col, alpha=alpha\n",
    "    )\n",
    "\n",
    "    # raw を一旦計算して min/max を取る（※スケールはこの raw で決める）\n",
    "    raw_tmp = model.predict(np.hstack([\n",
    "        train_s[[\"urban_score\",\"score_access\",\"score_daily\",\"score_room\",\"score_building\"]].astype(float).values,\n",
    "        (train_s[\"score_access\"] * train_s[\"urban_score\"]).values.reshape(-1,1),\n",
    "        (train_s[\"score_daily\"]  * train_s[\"urban_score\"]).values.reshape(-1,1),\n",
    "        (train_s[\"score_room\"]   * train_s[\"urban_score\"]).values.reshape(-1,1),\n",
    "        (train_s[\"score_building\"] * train_s[\"urban_score\"]).values.reshape(-1,1),\n",
    "    ]))\n",
    "    train_min = float(np.nanmin(raw_tmp))\n",
    "    train_max = float(np.nanmax(raw_tmp))\n",
    "\n",
    "    train_s[\"livability_score\"] = apply_livability_score(train_s, model, feature_names, train_min, train_max)\n",
    "    test_s[\"livability_score\"]  = apply_livability_score(test_s,  model, feature_names, train_min, train_max)\n",
    "\n",
    "    meta = {\n",
    "        \"urban_meta\": urban_meta,\n",
    "        \"subscores_meta\": subs_meta,\n",
    "        \"model\": model,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"train_min\": train_min,\n",
    "        \"train_max\": train_max,\n",
    "    }\n",
    "    return train_s, test_s, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "682696fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe, test_df_fe, liv_meta = add_livability_features(\n",
    "    train_df_fe,\n",
    "    test_df_fe,\n",
    "    target_col=target_col,\n",
    "    alpha=1.0,\n",
    "    use_rule_tags=True,\n",
    "    rule_weight_in_daily=0.6,\n",
    "    rule_weight_in_building=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d814fa",
   "metadata": {},
   "source": [
    "## 道路関連"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7950c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df_fe, test_df_fe]:\n",
    "    df['is_no_road'] = (df['land_road_cond'] == 10).astype('int8')\n",
    "    df['road_len_density_x_no_road'] = (df['road_len_density'] * df['is_no_road']).astype('float32')\n",
    "    df['road_narrow_ratio_gap_x_no_road'] = (df['road_narrow_ratio_gap'] * df['is_no_road']).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c861e",
   "metadata": {},
   "source": [
    "## 特徴量の追加・削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abae7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = [\n",
    "    'distance_to_landpoint_m', 'log_land_price', 'log_weighted_land_price_3',\n",
    "    'land_price_yoy_nearest', 'land_price_yoy_w3', 'land_price_dlog_nearest', 'land_price_dlog_w3',\n",
    "    'PTN_2020_nn', 'PTN_2020_idw3', 'RTA_2025_nn', 'RTA_2025_idw3',\n",
    "    'RTB_2025_nn', 'RTB_2025_idw3', 'RTC_2025_nn', 'RTC_2025_idw3',\n",
    "    'RTD_2025_nn', 'RTD_2025_idw3', 'RTE_2025_nn', 'RTE_2025_idw3',\n",
    "    'pop_trend_rate_nn', 'pop_trend_rate_idw3',\n",
    "    # 'road_road_len_total', 'road_road_len_wide', 'road_road_len_narrow',\n",
    "    # 'road_road_wide_ratio', 'road_road_narrow_ratio',\n",
    "    # 'road_road_len_total_gap', 'road_road_narrow_ratio_gap'\n",
    "    'road_len_density', 'road_len_density_gap'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19d4ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_cols += [\n",
    "    'Prefecture name_te', 'City/town/village name_te',\n",
    "    'area_ratio', 'relative_floor',\n",
    "    'unit_land_density', 'area_per_room',\n",
    "    'land_building_ratio',\n",
    "    'senyu_area_x_built_diff', 'area_per_room_x_built_diff',\n",
    "    'building_senyu_area_median', 'building_room_floor_max', 'building_unit_count',\n",
    "    'mean_price_300m_log', 'median_price_300m_log', 'std_price_300m', 'iqr_price_300m', 'count_neighbors_300m', 'mean_price_300m_house_log', 'mean_price_300m_mansion_log',\n",
    "    'mean_price_500m_log', 'median_price_500m_log', 'std_price_500m', 'iqr_price_500m', 'count_neighbors_500m', 'mean_price_500m_house_log', 'mean_price_500m_mansion_log',\n",
    "    'mean_price_1000m_log', 'median_price_1000m_log', 'std_price_1000m', 'iqr_price_1000m', 'count_neighbors_1000m', 'mean_price_1000m_house_log', 'mean_price_1000m_mansion_log',\n",
    "    'mean_price_2000m_log', 'median_price_2000m_log', 'std_price_2000m', 'iqr_price_2000m', 'count_neighbors_2000m', 'mean_price_2000m_house_log', 'mean_price_2000m_mansion_log',\n",
    "    'city_lat', 'city_lon',\n",
    "    'access_zone', 'walk_distance_bin', 'door_to_station_min_log',\n",
    "    'density_floor_area', 'unit_count_density', 'unit_area_range', 'empty_ratio',\n",
    "    'effective_age', 'reform_total_count', 'reform_newness_log',\n",
    "    'listing_months',\n",
    "    'ratio_mean_land', 'ratio_weighted_land',\n",
    "    'kyoueki_per_m2', 'shuuzen_per_m2', 'kyoueki_per_unit', 'shuuzen_per_unit', 'has_kyoueki', 'has_shuuzen',\n",
    "    'land_cheap_flag', 'land_expensive_flag', 'land_theoretical_price', 'land_theoretical_price_weighted', 'land_theoretical_price_within1km_mp',\n",
    "    'parking_available', 'parking_on_site', 'parking_nearby_only', 'parking_distance_log', 'parking_money_std_clip', 'parking_cost_ratio_clip_log',  'parking_cost_per_sqm_clip',\n",
    "    'log_min_amenity_distance', 'convenience_distance_log', 'super_distance_log', 'drugstore_distance_log', 'amenity_within_500m', 'amenity_within_1000m',\n",
    "    'genkyo_flex_score', 'usable_status_score', 'usable_months_delay',\n",
    "    'has_management_association', 'management_form_score', 'manager_presence_score', 'management_total_score',\n",
    "    'mochibun_ratio', 'mochibun_area_log', \n",
    "    'land_shidou_ratio', 'has_shidou', 'shidou_area_ratio',\n",
    "    'livability_score', 'urban_score', 'score_access', 'score_room', 'score_building',\n",
    "    'is_no_road', 'road_len_density_x_no_road', 'road_narrow_ratio_gap_x_no_road' \n",
    "] + geo_cols + [c for c in train_df_fe.columns if 'pca' in c.lower()] + [c + '_te' for c in traffic_te_cols]\n",
    "\n",
    "# 削除する特徴量\n",
    "remove_cols = [\n",
    "    'building_name', 'homes_building_name', \n",
    "    'lon', 'lat',\n",
    "    'reform_date', 'reform_interior_date', 'reform_exterior_date', 'reform_wet_area_date', 'renovation_date',\n",
    "    # 'rosen_name1', 'rosen_name2', 'eki_name1', 'eki_name2', \n",
    "    'walk_distance1', 'walk_distance2',\n",
    "    'bus_stop1', 'bus_stop2', 'bus_time1', 'bus_time2', 'traffic_other',\n",
    "    'building_tag_id', 'unit_tag_id', 'statuses',\n",
    "    'building_create_date', \n",
    "    'unit_area_max', 'unit_area_min',\n",
    "    'parking_money', 'parking_distance',\n",
    "    'management_form', 'management_association_flg',\n",
    "    'genkyo_code', 'usable_status', 'usable_date', \n",
    "    'convenience_distance', 'super_distance', 'drugstore_distance', 'school_ele_distance', 'school_jun_distance',\n",
    "    # 'Prefecture name', 'City/town/village name',\n",
    "    'senyu_area', 'nobeyuka_area', 'kukaku_area', 'tochi_area', 'shikichi_area', 'unit_count',\n",
    "]\n",
    "fe_cols = [c for c in fe_cols if c not in remove_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446b947",
   "metadata": {},
   "source": [
    "## 出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97e13a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_fe[fe_cols + [target_col]].to_parquet(f'{intermediate_path}train_df_fe_v{fe_ver}.parquet')\n",
    "test_df_fe[fe_cols].to_parquet(f'{intermediate_path}test_df_fe_v{fe_ver}.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
