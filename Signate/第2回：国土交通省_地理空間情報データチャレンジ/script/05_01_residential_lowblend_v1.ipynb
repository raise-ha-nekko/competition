{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc1c087",
   "metadata": {},
   "source": [
    "# residential: low-classifier + low-regressor ブレンド（v1）\n",
    "\n",
    "このノートブックは、既存の `03_02_training_v8.ipynb` / `04_01_inference_v8.ipynb` / `04_02_post_revision_v1.ipynb` の出力を流用し、\n",
    "\n",
    "- 低価格帯 classifier（確率）\n",
    "- 低価格帯 regressor\n",
    "- 確率ブレンドによる後補正\n",
    "- 提出ファイル作成\n",
    "\n",
    "までを一気通貫で実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0065b2",
   "metadata": {},
   "source": [
    "## 0. 設定・読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44c146e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today: 20260109\n",
      "LOW_THRESHOLD: 10000000 N_SPLITS: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =========================\n",
    "# Path / Version\n",
    "# =========================\n",
    "ROOT_DIR = '../input/'\n",
    "intermediate_path = '../output/intermediate_file/'\n",
    "model_path = '../output/model/'\n",
    "oof_path = '../output/oof/'\n",
    "pred_path = '../output/pred/'\n",
    "\n",
    "submit_file_path = ROOT_DIR + 'sample_submit.csv'\n",
    "\n",
    "# 既存ノートブックに合わせる\n",
    "create_tbl_ver = 2\n",
    "training_ver = 8\n",
    "inference_ver = 8\n",
    "submit_ver = 1\n",
    "\n",
    "# 本ノートブックのバージョン\n",
    "low_blend_ver = 1\n",
    "today = dt.datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "# 対象\n",
    "target_model = 'residential'\n",
    "alg = 'lgb'\n",
    "\n",
    "# low の閾値（residential）\n",
    "LOW_THRESHOLD = 10_000_000\n",
    "\n",
    "# CV（既存 training_v8 の main CV に合わせる）\n",
    "N_SPLITS = 3\n",
    "\n",
    "print('today:', today)\n",
    "print('LOW_THRESHOLD:', LOW_THRESHOLD, 'N_SPLITS:', N_SPLITS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "707fcc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features(fe_cols): 308\n",
      "n_cat_cols: 6\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 既存モデル辞書（fe_cols/cat_cols を取得）\n",
    "# =========================\n",
    "with open(f'{model_path}/model_{target_model}_{alg}_v{training_ver}.pkl', \"rb\") as f:\n",
    "    models_dict = pickle.load(f)\n",
    "\n",
    "fe_cols = models_dict['fe_cols']\n",
    "cat_cols = models_dict['cat_cols']\n",
    "\n",
    "def _union_if_dict(x):\n",
    "    if isinstance(x, dict):\n",
    "        out = set()\n",
    "        for v in x.values():\n",
    "            out |= set(v)\n",
    "        return sorted(out)\n",
    "    return list(x)\n",
    "\n",
    "fe_cols_union = _union_if_dict(fe_cols)\n",
    "cat_cols_union = _union_if_dict(cat_cols)\n",
    "\n",
    "print('n_features(fe_cols):', len(fe_cols_union))\n",
    "print('n_cat_cols:', len(cat_cols_union))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0addb57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN_OOF_COL: residential_lgb_oof_pred_log\n",
      "train_with_pred: (195154, 392)\n"
     ]
    }
   ],
   "source": [
    "# OOF 学習用\n",
    "oof_csv_path = f'{oof_path}train_with_pred_residential_lgb_v{training_ver}.csv'\n",
    "train_with_pred = pd.read_csv(oof_csv_path)\n",
    "\n",
    "TARGET_COL = 'money_room'\n",
    "GROUP_COL = 'building_id'\n",
    "\n",
    "cand = [c for c in train_with_pred.columns if ('oof' in c) and ('pred' in c) and ('residential' in c)]\n",
    "MAIN_OOF_COL = cand[0] if len(cand) > 0 else 'residential_lgb_oof_pred'\n",
    "\n",
    "assert TARGET_COL in train_with_pred.columns\n",
    "assert GROUP_COL in train_with_pred.columns\n",
    "assert MAIN_OOF_COL in train_with_pred.columns\n",
    "\n",
    "print('MAIN_OOF_COL:', MAIN_OOF_COL)\n",
    "print('train_with_pred:', train_with_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5afaa45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df: (58834, 374) pred_df_main: (58834, 382)\n"
     ]
    }
   ],
   "source": [
    "# test 特徴量 & main test 予測\n",
    "test_df = pd.read_parquet(f'{intermediate_path}test_df_{target_model}_v{create_tbl_ver}.parquet')\n",
    "pred_df_main = pd.read_parquet(f'{intermediate_path}pred_df_{target_model}_v{inference_ver}.parquet').reindex(test_df.index)\n",
    "\n",
    "assert 'pred' in pred_df_main.columns\n",
    "pred_main_test = pred_df_main['pred'].astype(float).values\n",
    "\n",
    "print('test_df:', test_df.shape, 'pred_df_main:', pred_df_main.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00101ed3",
   "metadata": {},
   "source": [
    "## 1. 学習データの feature セットを確定（train/test の共通部分のみ使用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ce5564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_cols: 282\n",
      "common_cols head: ['City/town/village_name_te', 'PTN_2020_nn', 'Prefecture_name_te', 'RTA_2025_nn', 'RTB_2025_nn', 'RTC_2025_nn', 'RTD_2025_nn', 'RTE_2025_nn', 'access_zone', 'ame_dist_log', 'amenity_count_within_1000m', 'amenity_count_within_500m', 'area_per_room', 'area_per_room_x_built_diff', 'balcony_area', 'balcony_area_log', 'basement_floor_count', 'building_area_kind_missing', 'building_category', 'building_id', 'building_room_floor_max', 'building_senyu_area_median', 'building_unit_count', 'built_diff', 'cert_score', 'cert_strong_flag', 'clinic_500m', 'convenience_distance', 'convenience_distance_log', 'count_neighbors_1000m']\n",
      "common_cat_cols: 6\n",
      "common_cat_cols head: ['access_zone', 'building_category', 'fireproof_x_structure', 'land_road_cond', 'structure_group', 'walk_distance_bin']\n",
      "low_rate: 0.11277760127898992\n"
     ]
    }
   ],
   "source": [
    "def detect_feature_cols(train_df, test_df, target_col, group_col, extra_drop=None):\n",
    "    extra_drop = extra_drop or []\n",
    "    drop_cols = set([target_col, group_col] + extra_drop)\n",
    "    pred_like = [c for c in train_df.columns if ('pred' in c) or ('oof' in c) or ('ho' in c)]\n",
    "    drop_cols.update(pred_like)\n",
    "    id_like = [c for c in train_df.columns if c.endswith('_id') or c in ['id', 'unit_id', 'property_id']]\n",
    "    drop_cols.update(id_like)\n",
    "    return [c for c in train_df.columns if (c in test_df.columns) and (c not in drop_cols)]\n",
    "\n",
    "common_cols = [c for c in fe_cols_union if (c in train_with_pred.columns) and (c in test_df.columns)]\n",
    "if len(common_cols) == 0:\n",
    "    common_cols = detect_feature_cols(train_with_pred, test_df, TARGET_COL, GROUP_COL, extra_drop=[MAIN_OOF_COL])\n",
    "\n",
    "print('common_cols:', len(common_cols))\n",
    "print('common_cols head:', common_cols[:30])\n",
    "\n",
    "common_cat_cols = [c for c in cat_cols_union if c in common_cols]\n",
    "if len(common_cat_cols) == 0:\n",
    "    common_cat_cols = [c for c in common_cols if train_with_pred[c].dtype == 'object']\n",
    "\n",
    "print('common_cat_cols:', len(common_cat_cols))\n",
    "print('common_cat_cols head:', common_cat_cols[:30])\n",
    "\n",
    "assert len(common_cols) > 0\n",
    "\n",
    "X_train = train_with_pred[common_cols]\n",
    "y_train = train_with_pred[TARGET_COL].astype(float)\n",
    "g_train = train_with_pred[GROUP_COL]\n",
    "X_test = test_df[common_cols]\n",
    "y_low = (y_train < LOW_THRESHOLD).astype('int8')\n",
    "print('low_rate:', float(y_low.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549765d",
   "metadata": {},
   "source": [
    "## 2. 評価関数（MAPE）と p のキャリブレーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred, eps=1e-9):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return np.mean(np.abs(y_true - y_pred) / denom)\n",
    "\n",
    "def calibrate_p_temperature(p, t=0.8):\n",
    "    eps = 1e-6\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "    logit = np.log(p / (1 - p))\n",
    "    return 1.0 / (1.0 + np.exp(-logit / t))\n",
    "\n",
    "def blend_pred(p_low, pred_low, pred_main, t=0.8, clip_min=0.02, clip_max=0.98):\n",
    "    p = calibrate_p_temperature(p_low, t=t)\n",
    "    p = np.clip(p, clip_min, clip_max)\n",
    "    return p * pred_low + (1 - p) * pred_main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ba246",
   "metadata": {},
   "source": [
    "## 3. OOF: low classifier（確率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27171736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _force_lgbm_train_categories(X: pd.DataFrame, cat_cols_use: list[str], na_token: str = 'NA') -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    for c in cat_cols_use:\n",
    "        if c not in X.columns:\n",
    "            continue\n",
    "        s = X[c].astype('string').fillna(na_token)\n",
    "        X[c] = s.astype('category')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c042c5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[clf] fold=1 best_iter=345 p_low_mean=0.1102\n",
      "[clf] fold=2 best_iter=429 p_low_mean=0.1077\n",
      "[clf] fold=3 best_iter=340 p_low_mean=0.1088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_params = dict(\n",
    "    objective='binary',\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=3000,\n",
    "    num_leaves=64,\n",
    "    min_data_in_leaf=300,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=2.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    forced_splits='',\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "p_low_oof = np.zeros(len(X_train), dtype=float)\n",
    "\n",
    "for fold, (tr_pos, va_pos) in enumerate(gkf.split(X_train, y_low, groups=g_train), 1):\n",
    "    X_tr, y_tr = X_train.iloc[tr_pos], y_low.iloc[tr_pos]\n",
    "    X_va, y_va = X_train.iloc[va_pos], y_low.iloc[va_pos]\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(**clf_params)\n",
    "    X_tr = _force_lgbm_train_categories(X_tr, common_cat_cols, na_token='NA')\n",
    "    X_va = _force_lgbm_train_categories(X_va, common_cat_cols, na_token='NA')\n",
    "    clf.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric='binary_logloss',\n",
    "        categorical_feature=common_cat_cols if len(common_cat_cols) > 0 else 'auto',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "    )\n",
    "    p_low_oof[va_pos] = clf.predict_proba(X_va)[:, 1]\n",
    "    print(f'[clf] fold={fold} best_iter={clf.best_iteration_} p_low_mean={p_low_oof[va_pos].mean():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b332b",
   "metadata": {},
   "source": [
    "## 4. OOF: low regressor（低価格帯専用モデル）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b29f8407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lowreg] fold=1 best_iter=5969 n_tr_low=14577\n",
      "[lowreg] fold=2 best_iter=5997 n_tr_low=14751\n",
      "[lowreg] fold=3 best_iter=5996 n_tr_low=14690\n"
     ]
    }
   ],
   "source": [
    "\n",
    "low_params = dict(\n",
    "    objective='regression_l1',\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=6000,\n",
    "    num_leaves=64,\n",
    "    min_data_in_leaf=300,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=3.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    forced_splits='',\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "pred_low_oof = np.zeros(len(X_train), dtype=float)\n",
    "\n",
    "X_tr, y_tr = X_train.iloc[tr_pos], y_low.iloc[tr_pos]\n",
    "X_va, y_va = X_train.iloc[va_pos], y_low.iloc[va_pos]\n",
    "\n",
    "for fold, (tr_pos, va_pos) in enumerate(gkf.split(X_train, y_train, groups=g_train), 1):\n",
    "    tr_idx = train_with_pred.index[tr_pos]\n",
    "    va_idx = train_with_pred.index[va_pos]\n",
    "    tr_low_idx = y_train.loc[tr_idx][y_train.loc[tr_idx] < LOW_THRESHOLD].index\n",
    "    X_tr, y_tr = X_train.loc[tr_low_idx], y_train.loc[tr_low_idx]\n",
    "    X_va, y_va = X_train.loc[va_idx], y_train.loc[va_idx]\n",
    "\n",
    "    reg = lgb.LGBMRegressor(**low_params)\n",
    "    X_tr = _force_lgbm_train_categories(X_tr, common_cat_cols, na_token='NA')\n",
    "    X_va = _force_lgbm_train_categories(X_va, common_cat_cols, na_token='NA')\n",
    "    reg.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric='l1',\n",
    "        categorical_feature=common_cat_cols if len(common_cat_cols) > 0 else 'auto',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=150, verbose=False)]\n",
    "    )\n",
    "    pred_low_oof[va_pos] = reg.predict(X_va)\n",
    "    print(f'[lowreg] fold={fold} best_iter={reg.best_iteration_} n_tr_low={len(tr_low_idx)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372db6a3",
   "metadata": {},
   "source": [
    "## 5. OOF: 既存 main OOF と blend（温度 t を探索）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b263814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18800000., 16900000., 16700000., ..., 18900000., 15900000.,\n",
       "       33900000.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78b64874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE(main oof) MAPE: 0.13833738495997044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.136144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.136155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.136171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.136197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.136233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.136275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.136328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t      mape\n",
       "6  1.2  0.136144\n",
       "5  1.1  0.136155\n",
       "4  1.0  0.136171\n",
       "3  0.9  0.136197\n",
       "2  0.8  0.136233\n",
       "1  0.7  0.136275\n",
       "0  0.6  0.136328"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_main_oof_log = train_with_pred[MAIN_OOF_COL].astype(float).values\n",
    "mask = ~np.isnan(pred_main_oof_log)\n",
    "\n",
    "# ★ 全部 mask に揃える\n",
    "y_true = y_train.values[mask]\n",
    "\n",
    "pred_main_oof = np.exp(pred_main_oof_log[mask])\n",
    "p_low_use = p_low_oof[mask]\n",
    "pred_low_use = pred_low_oof[mask]\n",
    "\n",
    "base_mape = mape(y_true, pred_main_oof)\n",
    "print('BASE(main oof) MAPE:', base_mape)\n",
    "\n",
    "ts = [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "rows = []\n",
    "for t in ts:\n",
    "    pred_bl = blend_pred(p_low_use, pred_low_use, pred_main_oof, t=t)\n",
    "    rows.append({'t': t, 'mape': mape(y_true, pred_bl)})\n",
    "\n",
    "score_df = pd.DataFrame(rows).sort_values('mape')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f23cfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_t = float(score_df.iloc[0]['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5df25c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE(main ho) MAPE: 0.1300691303572458\n",
      "BLEND(ho) MAPE: 0.13611610657757903\n"
     ]
    }
   ],
   "source": [
    "HO_COL = 'residential_lgb_ho_pred'  # 実際の列名に合わせる\n",
    "pred_main_ho = train_with_pred[HO_COL].astype(float).values\n",
    "mask_ho = ~np.isnan(pred_main_ho)\n",
    "\n",
    "# HO でも同じtを使う（OOFで選んだ best_t を固定）\n",
    "pred_bl_ho = blend_pred(p_low_oof, pred_low_oof, pred_main_ho, t=best_t)\n",
    "\n",
    "print('BASE(main ho) MAPE:', mape(y_train.values[mask_ho], pred_main_ho[mask_ho]))\n",
    "print('BLEND(ho) MAPE:', mape(y_train.values[mask_ho], pred_bl_ho[mask_ho]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff472365",
   "metadata": {},
   "source": [
    "## 6. 最終学習（full train）→ test 推論 → residential を blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb44f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full train で classifier 学習\n",
    "clf_final = lgb.LGBMClassifier(**clf_params)\n",
    "clf_final.fit(\n",
    "    X_train, y_low,\n",
    "    categorical_feature=common_cat_cols if len(common_cat_cols) > 0 else 'auto',\n",
    ")\n",
    "\n",
    "# full train (low subset) で low regressor 学習\n",
    "low_idx_full = train_with_pred.index[y_train < LOW_THRESHOLD]\n",
    "X_train_low_full = X_train.loc[low_idx_full]\n",
    "y_train_low_full = y_train.loc[low_idx_full]\n",
    "\n",
    "reg_low_final = lgb.LGBMRegressor(**low_params)\n",
    "reg_low_final.fit(\n",
    "    X_train_low_full, y_train_low_full,\n",
    "    categorical_feature=common_cat_cols if len(common_cat_cols) > 0 else 'auto',\n",
    ")\n",
    "\n",
    "# save artifacts\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "clf_path = f'{model_path}/lowclf_{target_model}_{alg}_thr{int(LOW_THRESHOLD)}_v{training_ver}_lbv{low_blend_ver}.pkl'\n",
    "reg_path = f'{model_path}/lowreg_{target_model}_{alg}_thr{int(LOW_THRESHOLD)}_v{training_ver}_lbv{low_blend_ver}.pkl'\n",
    "meta_path = f'{model_path}/lowblend_meta_{target_model}_{alg}_thr{int(LOW_THRESHOLD)}_v{training_ver}_lbv{low_blend_ver}.pkl'\n",
    "\n",
    "with open(clf_path, 'wb') as f:\n",
    "    pickle.dump(clf_final, f)\n",
    "with open(reg_path, 'wb') as f:\n",
    "    pickle.dump(reg_low_final, f)\n",
    "with open(meta_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'LOW_THRESHOLD': LOW_THRESHOLD,\n",
    "        'best_t': best_t,\n",
    "        'common_cols': common_cols,\n",
    "        'common_cat_cols': common_cat_cols,\n",
    "        'training_ver': training_ver,\n",
    "        'create_tbl_ver': create_tbl_ver,\n",
    "        'inference_ver': inference_ver,\n",
    "    }, f)\n",
    "\n",
    "print('saved:', clf_path)\n",
    "print('saved:', reg_path)\n",
    "print('saved:', meta_path)\n",
    "\n",
    "# test 推論\n",
    "p_low_test = clf_final.predict_proba(X_test)[:, 1]\n",
    "pred_low_test = reg_low_final.predict(X_test)\n",
    "\n",
    "pred_blend_test = blend_pred(\n",
    "    p_low=p_low_test,\n",
    "    pred_low=pred_low_test,\n",
    "    pred_main=pred_main_test,\n",
    "    t=best_t\n",
    ")\n",
    "\n",
    "print(pd.Series(pred_main_test).describe())\n",
    "print(pd.Series(pred_blend_test).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df_main を residential blend で置き換えて保存\n",
    "pred_df_blend = pred_df_main.copy()\n",
    "pred_df_blend['pred_main'] = pred_df_main['pred'].astype(float)\n",
    "pred_df_blend['p_low'] = p_low_test\n",
    "pred_df_blend['pred_low'] = pred_low_test\n",
    "pred_df_blend['pred'] = pred_blend_test\n",
    "\n",
    "out_pred_path = f'{intermediate_path}pred_df_{target_model}_v{inference_ver}_lowblend_v{low_blend_ver}.parquet'\n",
    "pred_df_blend.to_parquet(out_pred_path)\n",
    "print('saved:', out_pred_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973b941",
   "metadata": {},
   "source": [
    "## 7. 提出ファイル作成（04_02_post_revision_v1 を流用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 他ターゲットの pred_df は既存推論のまま読み込む\n",
    "test_df_house = pd.read_parquet(f'{intermediate_path}pred_df_house_v{inference_ver}.parquet')\n",
    "test_df_other = pd.read_parquet(f'{intermediate_path}pred_df_other_v{inference_ver}.parquet')\n",
    "\n",
    "# residential は lowblend を使う\n",
    "test_df_residential = pred_df_blend\n",
    "\n",
    "submit_df = pd.read_csv(submit_file_path, index_col=0)\n",
    "submit_df['pred'] = np.nan\n",
    "\n",
    "for df_part in [test_df_residential, test_df_house, test_df_other]:\n",
    "    idx = submit_df.index.intersection(df_part.index)\n",
    "    submit_df.loc[idx, 'pred'] = df_part.loc[idx, 'pred'].astype(float)\n",
    "\n",
    "assert submit_df['pred'].isna().sum() == 0, 'submit_df に欠損が残っています'\n",
    "print(submit_df['pred'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaca7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "os.makedirs(pred_path, exist_ok=True)\n",
    "\n",
    "out_submit_path = f'{pred_path}submit_v{submit_ver}_res_lowblend_thr{int(LOW_THRESHOLD)}_t{best_t}_lbv{low_blend_ver}_{today}.csv'\n",
    "submit_df.to_csv(out_submit_path)\n",
    "print('saved:', out_submit_path)\n",
    "\n",
    "out_submit_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
